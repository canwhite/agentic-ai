# ğŸš€ Novel Agent æ¶æ„æ”¹è¿›æ–¹æ¡ˆ

## ğŸ“Š ç°çŠ¶åˆ†æ

### å½“å‰ novel_agent æ¶æ„

**ä¼˜ç‚¹ï¼š**
- âœ… å®Œæ•´çš„å¤š Agent åä½œç³»ç»Ÿï¼ˆ6 ä¸ªä¸“ä¸š Agentï¼‰
- âœ… æ¸…æ™°çš„ä¸²è¡Œå·¥ä½œæµï¼ˆDirector â†’ Plot â†’ Character â†’ Scene â†’ Synthesis â†’ Optimize â†’ QualityCheckï¼‰
- âœ… è‰¯å¥½çš„æ•°æ®æ¨¡å‹è®¾è®¡ï¼ˆPydantic æ¨¡å‹ï¼‰

**ç—›ç‚¹ï¼š**
- âŒ **å®Œå…¨åŒæ­¥é˜»å¡**ï¼šæ¯ä¸ª Agent æ‰§è¡Œæ—¶ï¼Œæ•´ä¸ªè¿›ç¨‹è¢«é˜»å¡
- âŒ **å•è¿›ç¨‹æ‰§è¡Œ**ï¼šæ— æ³•å¹¶å‘å¤„ç†å¤šä¸ªå°è¯´ç”Ÿæˆè¯·æ±‚
- âŒ **LLM API ç­‰å¾…æ—¶é—´é•¿**ï¼š6 ä¸ª Agent ä¸²è¡Œè°ƒç”¨ï¼Œæ¯ä¸ª 3-10 ç§’ï¼Œæ€»å…± 18-60 ç§’
- âŒ **æ— è‡ªæ„ˆèƒ½åŠ›**ï¼šè¿›ç¨‹å´©æºƒéœ€è¦æ‰‹åŠ¨é‡å¯
- âŒ **æ— åŠ¨æ€æ‰©å®¹**ï¼šæ— æ³•æ ¹æ®è´Ÿè½½è°ƒæ•´è¿›ç¨‹æ•°

### å½“å‰æ¶æ„ä»£ç åˆ†æ

```python
# å½“å‰æ‰§è¡Œæµç¨‹ï¼ˆnovel_workflow.pyï¼‰
def execute(self, novel_input: NovelInput) -> WorkflowResult:
    # æ­¥éª¤ 1: Director åˆ›å»ºè®¡åˆ’ï¼ˆé˜»å¡ 3-10 ç§’ï¼‰
    creation_plan = self._create_creation_plan(...)

    # æ­¥éª¤ 2: ä¸²è¡Œæ‰§è¡Œæ‰€æœ‰ Agentï¼ˆé˜»å¡ 15-50 ç§’ï¼‰
    agent_outputs = self._execute_agent_tasks(...)  # ä¸²è¡Œï¼
    #   - Plot Designerï¼ˆ3-5 ç§’ï¼‰
    #   - Character Agentï¼ˆ3-5 ç§’ï¼‰
    #   - Scene Rendererï¼ˆ3-5 ç§’ï¼‰
    #   - Writing Optimizerï¼ˆ3-5 ç§’ï¼‰
    #   - Consistency Checkerï¼ˆ3-5 ç§’ï¼‰

    # æ­¥éª¤ 3: åˆæˆç« èŠ‚ï¼ˆé˜»å¡ 3-10 ç§’ï¼‰
    chapter_draft = self._synthesize_chapter(...)

    # æ­¥éª¤ 4: ä¼˜åŒ–æ–‡ç¬”ï¼ˆé˜»å¡ 3-10 ç§’ï¼‰
    optimized_content = self._optimize_writing(...)

    # æ­¥éª¤ 5: è´¨é‡æ£€æŸ¥ï¼ˆé˜»å¡ 3-10 ç§’ï¼‰
    quality_ok = self._perform_quality_checks(...)

    # æ€»è€—æ—¶ï¼š30-90 ç§’
```

**é—®é¢˜æ€»ç»“ï¼š**
1. æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯åŒæ­¥é˜»å¡è°ƒç”¨
2. 6 ä¸ª Agent ä¸²è¡Œæ‰§è¡Œï¼Œæ— æ³•å¹¶è¡Œ
3. å•è¿›ç¨‹åªèƒ½å¤„ç†ä¸€ä¸ªè¯·æ±‚
4. è¿›ç¨‹å´©æºƒ = æœåŠ¡ä¸å¯ç”¨

---

## ğŸ¯ æ”¹è¿›æ–¹æ¡ˆ Plan

### **æ ¸å¿ƒæ€è·¯ï¼šå°† Gunicorn + Uvicorn æ¶æ„åº”ç”¨åˆ° novel_agent**

å°†åŒæ­¥çš„å•è¿›ç¨‹å°è¯´ç”Ÿæˆç³»ç»Ÿï¼Œæ”¹é€ ä¸ºï¼š
- **å¤šè¿›ç¨‹ï¼ˆGunicorn é£æ ¼ï¼‰**ï¼šæ¨ªå‘æ‰©å±•ï¼Œå¼¹æ€§ä¼¸ç¼©
- **å¼‚æ­¥åç¨‹ï¼ˆUvicorn é£æ ¼ï¼‰**ï¼šçºµå‘å‹æ¦¨ï¼Œå¹¶å‘æ‰§è¡Œ
- **æ™ºèƒ½å¹¶è¡Œ**ï¼šè¯†åˆ«å¯å¹¶è¡Œçš„ Agentï¼Œå‡å°‘ä¸²è¡Œç­‰å¾…

---

## ğŸ“‹ æ”¹è¿›è®¡åˆ’ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

### **Phase 1: åŸºç¡€å¼‚æ­¥åŒ–æ”¹é€ ** â­â­â­â­â­

**ç›®æ ‡ï¼š** å°†åŒæ­¥ Agent æ”¹ä¸ºå¼‚æ­¥ Agentï¼Œåˆ©ç”¨å¹¶å‘åŠ é€Ÿå•ä¸ªè¯·æ±‚

#### å…·ä½“ä»»åŠ¡

##### 1. æ”¹é€  BaseAgent ä¸ºå¼‚æ­¥

**å½“å‰ä»£ç ï¼ˆbase_agent.pyï¼‰ï¼š**
```python
class BaseAgent:
    def execute(self, task: str, context: Dict[str, Any]) -> AgentResult:
        # åŒæ­¥è°ƒç”¨ LLM
        response = self.llm_client.call(prompt)
        return AgentResult(...)
```

**æ”¹é€ åï¼š**
```python
class BaseAgent:
    async def aexecute(self, task: str, context: Dict[str, Any]) -> AgentResult:
        # å¼‚æ­¥è°ƒç”¨ LLM
        response = await self.async_llm_client.acall(prompt)
        return AgentResult(...)

    # ä¿ç•™åŒæ­¥æ¥å£ï¼ˆå‘åå…¼å®¹ï¼‰
    def execute(self, task: str, context: Dict[str, Any]) -> AgentResult:
        return asyncio.run(self.aexecute(task, context))
```

##### 2. æ·»åŠ å¼‚æ­¥ LLM Client

**æ–°å»ºæ–‡ä»¶ï¼š`src/utils/async_llm_client.py`**
```python
import httpx
import asyncio
from typing import Dict, Any, Optional

class AsyncLLMClient:
    """å¼‚æ­¥ LLM å®¢æˆ·ç«¯"""

    def __init__(self, provider: str = "deepseek"):
        self.provider = provider
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(300.0),
            limits=httpx.Limits(max_connections=100, max_keepalive_connections=20)
        )

    async def acall(
        self,
        messages: List[Dict],
        temperature: float = 0.7,
        max_tokens: int = 2000,
    ) -> str:
        """å¼‚æ­¥è°ƒç”¨ LLM API"""

        if self.provider == "deepseek":
            url = "https://api.deepseek.com/v1/chat/completions"
            api_key = os.getenv("DEEPSEEK_API_KEY")

        response = await self.client.post(
            url,
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": "deepseek-chat",
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
            },
        )

        return response.json()["choices"][0]["message"]["content"]

    async def aclose(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        await self.client.aclose()
```

##### 3. æ”¹é€  NovelWorkflow ä¸ºå¼‚æ­¥

**å…³é”®æ”¹åŠ¨ï¼š**
```python
class NovelWorkflow:
    async def aexecute(self, novel_input: NovelInput) -> WorkflowResult:
        """å¼‚æ­¥æ‰§è¡Œå°è¯´ç”Ÿæˆå·¥ä½œæµ"""

        # æ­¥éª¤ 1: Director åˆ›å»ºè®¡åˆ’ï¼ˆå¼‚æ­¥ï¼‰
        creation_plan = await self._async_create_creation_plan(...)

        # æ­¥éª¤ 2: å¹¶è¡Œæ‰§è¡Œ Agentï¼ˆå…³é”®ä¼˜åŒ–ï¼ï¼‰
        agent_outputs = await self._async_execute_agent_tasks(...)

        # æ­¥éª¤ 3-5: åç»­æ­¥éª¤ï¼ˆå¼‚æ­¥ï¼‰
        chapter_draft = await self._async_synthesize_chapter(...)
        optimized_content = await self._async_optimize_writing(...)
        quality_ok = await self._async_perform_quality_checks(...)

        return result

    async def _async_execute_agent_tasks(
        self,
        novel_input: NovelInput,
        creation_plan: Dict[str, Any],
        result: WorkflowResult,
    ) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œ Agent ä»»åŠ¡ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰"""

        agent_outputs = {}

        # Level 1: Plotï¼ˆå¿…é¡»å…ˆæ‰§è¡Œï¼‰
        plot_result = await self.plot_designer.aexecute(...)
        agent_outputs["plot_designer"] = plot_result

        # Level 2: Character + Sceneï¼ˆå¯ä»¥å¹¶è¡Œï¼ï¼‰
        character_task = self.character_agent.aexecute(...)
        scene_task = self.scene_renderer.aexecute(...)

        # å¹¶è¡Œç­‰å¾…
        character_result, scene_result = await asyncio.gather(
            character_task,
            scene_task,
            return_exceptions=True
        )

        agent_outputs["character_agent"] = character_result
        agent_outputs["scene_renderer"] = scene_result

        return agent_outputs
```

##### 4. ä½¿ç”¨ asyncio.gather() å¹¶è¡Œæ‰§è¡Œ

**å¹¶è¡Œç­–ç•¥ï¼š**
```python
# åœºæ™¯ 1: Character å’Œ Scene å¯ä»¥å¹¶è¡Œ
async def parallel_level_3(self, context):
    tasks = [
        self.character_agent.aexecute("è®¾è®¡äººç‰©è¡¨ç°", context),
        self.scene_renderer.aexecute("è®¾è®¡åœºæ™¯æ¸²æŸ“", context),
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results

# åœºæ™¯ 2: Writing Optimization å’Œ Quality Check å¯ä»¥å¹¶è¡Œ
async def parallel_level_5(self, content, context):
    optimize_task = self.writing_optimizer.aexecute("ä¼˜åŒ–æ–‡ç¬”", context)
    quality_task = self.consistency_checker.aexecute("è´¨é‡æ£€æŸ¥", context)

    optimized, quality = await asyncio.gather(
        optimize_task,
        quality_task,
        return_exceptions=True
    )

    return optimized, quality
```

#### é¢„æœŸæ”¶ç›Š

| æŒ‡æ ‡ | æ”¹é€ å‰ | æ”¹é€ å | æå‡ |
|------|--------|--------|------|
| å•ä¸ªè¯·æ±‚å»¶è¿Ÿ | 60 ç§’ | 20 ç§’ | **3 å€** |
| å¹¶å‘å¤„ç†æ•° | 1 ä¸ª | 5 ä¸ªï¼ˆåç¨‹ï¼‰ | **5 å€** |
| LLM API è°ƒç”¨ | ä¸²è¡Œ | éƒ¨åˆ†å¹¶è¡Œ | **2 å€** |

---

### **Phase 2: Master-Worker å¤šè¿›ç¨‹æ¶æ„** â­â­â­â­

**ç›®æ ‡ï¼š** å¼•å…¥ Gunicorn é£æ ¼çš„ Master-Worker æ¨¡å¼

#### å…·ä½“ä»»åŠ¡

##### 1. å®ç° NovelSupervisorï¼ˆMaster è¿›ç¨‹ï¼‰

**æ–°å»ºæ–‡ä»¶ï¼š`src/supervisor/novel_supervisor.py`**
```python
import os
import time
import signal
import multiprocessing
from typing import Dict, Optional

class NovelSupervisor:
    """å°è¯´ç”Ÿæˆç³»ç»Ÿçš„ Master è¿›ç¨‹"""

    def __init__(self, min_workers: int = 2, max_workers: int = 4):
        self.min_workers = min_workers
        self.max_workers = max_workers
        self.task_queue = multiprocessing.Queue()
        self.result_queue = multiprocessing.Queue()
        self.workers: Dict[int, str] = {}  # {pid: worker_name}

    def spawn_worker(self):
        """Fork ä¸€ä¸ªæ–°çš„ Worker è¿›ç¨‹"""
        if len(self.workers) >= self.max_workers:
            return

        worker_id = f"Worker-{len(self.workers) + 1}"
        pid = os.fork()

        if pid == 0:
            # å­è¿›ç¨‹ï¼ˆWorkerï¼‰
            self._run_worker(worker_id)
            os._exit(0)
        else:
            # çˆ¶è¿›ç¨‹ï¼ˆMasterï¼‰
            self.workers[pid] = worker_id
            print(f"[Master] å¯åŠ¨ Worker: {worker_id} (PID: {pid})")

    def _run_worker(self, worker_id: str):
        """Worker è¿›ç¨‹çš„ä¸»å¾ªç¯"""
        import asyncio
        from src.workflows.novel_workflow import NovelWorkflow

        # æ¯ä¸ª Worker å†…éƒ¨è¿è¡Œ asyncio äº‹ä»¶å¾ªç¯
        workflow = NovelWorkflow()

        async def worker_loop():
            print(f"  [{worker_id}] (PID: {os.getpid()}) å¼‚æ­¥ Worker å¯åŠ¨")

            active_tasks = []

            while True:
                try:
                    # éé˜»å¡è·å–ä»»åŠ¡
                    try:
                        task = self.task_queue.get_nowait()
                    except:
                        await asyncio.sleep(0.5)
                        continue

                    if task == "STOP":
                        break

                    # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
                    novel_input = task["novel_input"]
                    task_id = task["task_id"]

                    # å¼‚æ­¥æ‰§è¡Œå°è¯´ç”Ÿæˆ
                    t = asyncio.create_task(
                        self._process_task(workflow, novel_input, task_id)
                    )
                    active_tasks.append(t)

                    # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                    active_tasks = [t for t in active_tasks if not t.done()]

                    print(f"    [{worker_id}] å½“å‰å¹¶å‘ä»»åŠ¡æ•°: {len(active_tasks)}")

                except Exception as e:
                    print(f"  [{worker_id}] é”™è¯¯: {e}")

        asyncio.run(worker_loop())

    async def _process_task(self, workflow, novel_input, task_id):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        try:
            result = await workflow.aexecute(novel_input)

            # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
            self.result_queue.put({
                "task_id": task_id,
                "success": result.success,
                "chapter_content": result.chapter_result.content if result.chapter_result else None,
                "execution_time": result.execution_time,
            })

            print(f"    [Task {task_id}] å®Œæˆï¼Œè€—æ—¶ {result.execution_time:.2f}s")

        except Exception as e:
            self.result_queue.put({
                "task_id": task_id,
                "success": False,
                "error": str(e),
            })

    def monitor(self):
        """Master ç›‘æ§å¾ªç¯"""
        # åˆå§‹æ°´ä½ï¼šå¯åŠ¨æœ€å°æ•°é‡çš„ Worker
        for _ in range(self.min_workers):
            self.spawn_worker()

        try:
            while True:
                # æ¨¡æ‹Ÿä»»åŠ¡æäº¤
                for _ in range(random.randint(0, 2)):
                    task = {
                        "task_id": f"task-{random.randint(1000, 9999)}",
                        "novel_input": self._create_sample_input(),
                    }
                    self.task_queue.put(task)

                # å¼¹æ€§ä¼¸ç¼©é€»è¾‘
                queue_size = self.task_queue.qsize()
                current_workers = len(self.workers)

                if queue_size > 10 and current_workers < self.max_workers:
                    print(f"[Master] é˜Ÿåˆ—ç§¯å‹ {queue_size}ï¼Œæ‰©å®¹ Worker")
                    self.spawn_worker()

                # è‡ªæ„ˆé€»è¾‘ï¼šæ£€æŸ¥é€€å‡ºçš„ Worker
                try:
                    pid, status = os.waitpid(-1, os.WNOHANG)
                    if pid > 0:
                        worker_name = self.workers.pop(pid, "Unknown")
                        print(f"[Master] Worker {worker_name} (PID: {pid}) æŒ‚äº†ï¼Œæ­£åœ¨é‡å¯...")
                        self.spawn_worker()
                except ChildProcessError:
                    pass

                # å¤„ç†ç»“æœé˜Ÿåˆ—
                while not self.result_queue.empty():
                    result = self.result_queue.get()
                    print(f"[Master] ä»»åŠ¡å®Œæˆ: {result['task_id']}")

                print(f"--- [Master] é˜Ÿåˆ—: {queue_size} | Worker: {current_workers} ---")
                time.sleep(2)

        except KeyboardInterrupt:
            print("[Master] æ­£åœ¨å…³é—­...")
            # å‘é€åœæ­¢ä¿¡å·ç»™æ‰€æœ‰ Worker
            for _ in range(len(self.workers)):
                self.task_queue.put("STOP")

    def _create_sample_input(self):
        """åˆ›å»ºç¤ºä¾‹è¾“å…¥"""
        from src.models import NovelInput

        return NovelInput(
            overall_outline="ä¸€ä¸ªå°‘å¹´åœ¨ç„å¹»ä¸–ç•Œä¿®ç‚¼æˆç¥çš„æ•…äº‹",
            chapter_outline="ä¸»è§’åœ¨ç§˜å¢ƒä¸­æ„å¤–è·å¾—ä¸Šå¤ä¼ æ‰¿",
            genre="ç„å¹»",
        )
```

##### 2. ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ

**ä½¿ç”¨ Redis å®ç°åˆ†å¸ƒå¼é˜Ÿåˆ—ï¼ˆå¯é€‰ï¼‰ï¼š**
```python
import redis.asyncio as aioredis
import json

class RedisTaskQueue:
    """åŸºäº Redis çš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—"""

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_url = redis_url
        self.redis = None

    async def connect(self):
        """è¿æ¥ Redis"""
        self.redis = await aioredis.from_url(self.redis_url)

    async def submit_task(self, novel_input: NovelInput, priority: int = 0) -> str:
        """æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        task_id = f"task-{uuid.uuid4()}"

        task_data = {
            "task_id": task_id,
            "novel_input": novel_input.dict(),
            "priority": priority,
            "status": "pending",
            "created_at": time.time(),
        }

        # æ ¹æ®ä¼˜å…ˆçº§æ”¾å…¥ä¸åŒçš„é˜Ÿåˆ—
        queue_name = f"tasks:priority_{priority}"
        await self.redis.lpush(queue_name, json.dumps(task_data))

        return task_id

    async def get_task(self) -> Optional[Dict]:
        """ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆéé˜»å¡ï¼‰"""
        # ä»é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—å¼€å§‹æ£€æŸ¥
        for priority in range(10):
            queue_name = f"tasks:priority_{priority}"
            task_data = await self.redis.rpop(queue_name)

            if task_data:
                return json.loads(task_data)

        return None

    async def update_task_status(self, task_id: str, status: str, result: Dict = None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        key = f"task:{task_id}"
        await self.redis.hset(key, "status", status)

        if result:
            await self.redis.hset(key, "result", json.dumps(result))

    async def get_task_status(self, task_id: str) -> Dict:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        key = f"task:{task_id}"
        data = await self.redis.hgetall(key)

        return {
            "task_id": task_id,
            "status": data.get(b"status", b"unknown").decode(),
            "result": json.loads(data.get(b"result", b"{}").decode()),
        }
```

##### 3. å¯åŠ¨è„šæœ¬

**æ–°å»ºæ–‡ä»¶ï¼š`scripts/start_novel_cluster.py`**
```python
#!/usr/bin/env python3
"""
å¯åŠ¨ Novel Agent é›†ç¾¤
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

from src.supervisor.novel_supervisor import NovelSupervisor

if __name__ == "__main__":
    supervisor = NovelSupervisor(
        min_workers=2,  # æœ€å° 2 ä¸ª Worker
        max_workers=4,  # æœ€å¤§ 4 ä¸ª Worker
    )

    print("=" * 60)
    print("ğŸš€ Novel Agent é›†ç¾¤å¯åŠ¨")
    print("=" * 60)
    print(f"æœ€å° Worker æ•°: {supervisor.min_workers}")
    print(f"æœ€å¤§ Worker æ•°: {supervisor.max_workers}")
    print("=" * 60)

    try:
        supervisor.monitor()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Novel Agent é›†ç¾¤å·²å…³é—­")
```

#### é¢„æœŸæ”¶ç›Š

| æŒ‡æ ‡ | æ”¹é€ å‰ | æ”¹é€ å | æå‡ |
|------|--------|--------|------|
| è¿›ç¨‹æ•° | 1 ä¸ª | 2-4 ä¸ªï¼ˆåŠ¨æ€ï¼‰ | **å¼¹æ€§ä¼¸ç¼©** |
| å¹¶å‘å¤„ç†æ•° | 1 ä¸ª | 10-20 ä¸ªï¼ˆ4 è¿›ç¨‹ Ã— 5 åç¨‹ï¼‰ | **20 å€** |
| ç³»ç»Ÿå¯ç”¨æ€§ | å´©æºƒéœ€æ‰‹åŠ¨é‡å¯ | è‡ªåŠ¨è‡ªæ„ˆ | **99.9%** |
| ç³»ç»Ÿåå | 1 QPS | 20 QPS | **20 å€** |

---

### **Phase 3: å†™ä½œç±» Agent çš„ç‰¹æ®Šä¼˜åŒ–** â­â­â­â­â­

**ç›®æ ‡ï¼š** é’ˆå¯¹å°è¯´ç”Ÿæˆçš„ç‰¹ç‚¹ï¼Œä¼˜åŒ–æ‰§è¡Œé¡ºåºå’Œå¹¶å‘ç­–ç•¥

#### å…³é”®æ´å¯Ÿï¼šå†™ä½œç±» Agent çš„ä¾èµ–å…³ç³»

```
å½“å‰æ‰§è¡Œé¡ºåºï¼ˆå®Œå…¨ä¸²è¡Œï¼‰ï¼š
Director â†’ Plot â†’ Character â†’ Scene â†’ Synthesis â†’ Optimize â†’ QualityCheck

é—®é¢˜ï¼šå¾ˆå¤šæ­¥éª¤å…¶å®å¯ä»¥å¹¶è¡Œï¼
```

#### ä¼˜åŒ–åçš„æ‰§è¡Œé¡ºåºï¼ˆDAG ä¾èµ–å›¾ï¼‰

```
Level 1: Directorï¼ˆåˆ¶å®šè®¡åˆ’ï¼‰
         â†“
Level 2: Plotï¼ˆæƒ…èŠ‚è®¾è®¡ï¼Œå¿…é€‰ï¼‰
         â†“
Level 3: Character + Sceneï¼ˆå¯ä»¥å¹¶è¡Œï¼ï¼‰
         â”œâ†’ Character Agentï¼ˆäººç‰©è¡¨ç°ï¼‰
         â””â†’ Scene Agentï¼ˆåœºæ™¯æ¸²æŸ“ï¼‰
         â†“
Level 4: Synthesisï¼ˆåˆæˆç« èŠ‚ï¼‰
         â†“
Level 5: Optimize + QualityCheckï¼ˆå¯ä»¥å¹¶è¡Œï¼ï¼‰
         â”œâ†’ Writing Optimizerï¼ˆæ–‡ç¬”ä¼˜åŒ–ï¼‰
         â””â†’ Consistency Checkerï¼ˆè¿è´¯æ€§æ£€æŸ¥ï¼‰
         â†“
Level 6: Final Resultï¼ˆå¦‚æœæœ‰é—®é¢˜ï¼Œä¿®å¤ï¼‰
```

#### å…·ä½“ä¼˜åŒ–ç­–ç•¥

##### 1. Level 3 å¹¶è¡ŒåŒ–ï¼ˆCharacter + Sceneï¼‰

```python
async def _async_execute_agent_tasks_level_3(
    self,
    novel_input: NovelInput,
    creation_plan: Dict[str, Any],
    result: WorkflowResult,
) -> Dict[str, Any]:
    """Level 3: å¹¶è¡Œæ‰§è¡Œ Character å’Œ Scene Agent"""

    context = {
        "novel_input": novel_input,
        "creation_plan": creation_plan,
        "plot_output": plot_output,  # Level 2 çš„è¾“å‡º
    }

    # å¹¶è¡Œå¯åŠ¨ä¸¤ä¸ª Agent
    character_task = asyncio.create_task(
        self.character_agent.aexecute("è®¾è®¡äººç‰©è¡¨ç°å’Œå¯¹è¯", context)
    )
    scene_task = asyncio.create_task(
        self.scene_renderer.aexecute("è®¾è®¡åœºæ™¯æ¸²æŸ“", context)
    )

    # å¹¶è¡Œç­‰å¾…
    character_result, scene_result = await asyncio.gather(
        character_task,
        scene_task,
        return_exceptions=True
    )

    # å¤„ç†ç»“æœ
    agent_outputs = {}
    if not isinstance(character_result, Exception):
        agent_outputs["character_agent"] = character_result
    if not isinstance(scene_result, Exception):
        agent_outputs["scene_renderer"] = scene_result

    return agent_outputs
```

##### 2. Level 5 å¹¶è¡ŒåŒ–ï¼ˆOptimize + QualityCheckï¼‰

```python
async def _async_optimize_and_check(
    self,
    novel_input: NovelInput,
    chapter_content: str,
    result: WorkflowResult,
) -> tuple:
    """Level 5: å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–å’Œè´¨æ£€"""

    # å‡†å¤‡ä¸¤ä¸ªä»»åŠ¡
    optimize_task = asyncio.create_task(
        self.writing_optimizer.aexecute("ä¼˜åŒ–æ–‡ç¬”", {
            "novel_input": novel_input,
            "text": chapter_content,
        })
    )

    quality_task = asyncio.create_task(
        self.consistency_checker.aexecute("è´¨é‡æ£€æŸ¥", {
            "novel_input": novel_input,
            "chapter_content": chapter_content,
        })
    )

    # å¹¶è¡Œæ‰§è¡Œ
    optimized_result, quality_result = await asyncio.gather(
        optimize_task,
        quality_task,
        return_exceptions=True
    )

    # å¤„ç†ç»“æœ
    if not isinstance(optimized_result, Exception):
        optimized_content = optimized_result.content
    else:
        optimized_content = chapter_content  # å¤±è´¥åˆ™ä½¿ç”¨åŸæ–‡

    quality_ok = True
    if not isinstance(quality_result, Exception):
        # è§£æè´¨æ£€ç»“æœ
        score = quality_result.metadata.get("coherence_score", 0)
        quality_ok = score >= 70

    return optimized_content, quality_ok
```

##### 3. æµå¼ç”Ÿæˆï¼ˆStreaming Generationï¼‰

**æ·»åŠ  FastAPI æ¥å£ï¼š**
```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

@app.post("/api/novel/generate/stream")
async def generate_chapter_stream(request: NovelInput):
    """æµå¼ç”Ÿæˆå°è¯´ç« èŠ‚"""

    async def generate():
        # Step 1: ç”Ÿæˆè®¡åˆ’ï¼ˆå¿«é€Ÿï¼‰
        yield f"data: {{'step': 'plan', 'status': 'started'}}\n\n"

        creation_plan = await director.aexecute("åˆ¶å®šè®¡åˆ’", {...})
        yield f"data: {{'step': 'plan', 'status': 'completed'}}\n\n"

        # Step 2: ç”Ÿæˆæƒ…èŠ‚ï¼ˆæµå¼ï¼‰
        yield f"data: {{'step': 'plot', 'status': 'started'}}\n\n"

        async for chunk in plot_designer.aexecute_stream(...):
            yield f"data: {{'step': 'plot', 'chunk': '{chunk}'}}\n\n"

        yield f"data: {{'step': 'plot', 'status': 'completed'}}\n\n"

        # ... å…¶ä»–æ­¥éª¤

    return StreamingResponse(generate(), media_type="text/event-stream")
```

**ç”¨æˆ·ä½“éªŒæå‡ï¼š**
- 3 ç§’å†…çœ‹åˆ°ç¬¬ä¸€æ‰¹å†…å®¹
- ä¸ç”¨ç­‰ 60 ç§’æ‰çœ‹åˆ°å®Œæ•´ç»“æœ
- ç±»ä¼¼ ChatGPT çš„æµå¼ä½“éªŒ

##### 4. é¢„å–ç­–ç•¥ï¼ˆPrefetchingï¼‰

```python
class NovelPrefetcher:
    """é¢„å–ç®¡ç†å™¨"""

    def __init__(self):
        self.cache = {}

    async def prefetch_context(self, user_id: str, novel_input: NovelInput):
        """é¢„å–å¯èƒ½éœ€è¦çš„ä¸Šä¸‹æ–‡"""

        # æ ¹æ®ç”¨æˆ·å†å²ï¼Œé¢„æµ‹å¯èƒ½çš„åœºæ™¯
        user_history = await self.get_user_history(user_id)

        # é¢„åŠ è½½å¸¸ç”¨åœºæ™¯
        common_scenes = ["æˆ˜æ–—åœºæ™¯", "å¯¹è¯åœºæ™¯", "ä¿®ç‚¼åœºæ™¯"]
        for scene_name in common_scenes:
            if scene_name not in self.cache:
                scene_template = await self.load_scene_template(scene_name)
                self.cache[scene_name] = scene_template

        # é¢„åŠ è½½è§’è‰²å¯¹è¯é£æ ¼
        for character in novel_input.characters:
            if character.name not in self.cache:
                dialogue_style = await self.load_dialogue_style(character.name)
                self.cache[character.name] = dialogue_style

    async def get_prefetched_data(self, key: str):
        """è·å–é¢„å–çš„æ•°æ®"""
        return self.cache.get(key)
```

#### é¢„æœŸæ”¶ç›Š

| æŒ‡æ ‡ | Phase 2 | Phase 3 | æå‡ |
|------|---------|---------|------|
| å•ä¸ªè¯·æ±‚å»¶è¿Ÿ | 20 ç§’ | 12 ç§’ | **1.7 å€** |
| é¦–å­—å»¶è¿Ÿï¼ˆTTFBï¼‰ | 12 ç§’ | 3 ç§’ | **4 å€** |
| ç”¨æˆ·æ»¡æ„åº¦ | 70% | 95% | **1.4 å€** |

---

### **Phase 4: ç”Ÿäº§ç¯å¢ƒå¢å¼º** â­â­â­

**ç›®æ ‡ï¼š** ç”Ÿäº§çº§åˆ«çš„ç¨³å®šæ€§ã€å¯è§‚æµ‹æ€§å’Œå¯æ‰©å±•æ€§

#### å…·ä½“ä»»åŠ¡

##### 1. æ·»åŠ  FastAPI æ¥å£å±‚

**æ–°å»ºæ–‡ä»¶ï¼š`src/api/novel_api.py`**
```python
from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from src.models import NovelInput
from src.supervisor.novel_supervisor import NovelSupervisor

app = FastAPI(
    title="Novel Agent API",
    description="é«˜æ€§èƒ½å¼‚æ­¥å°è¯´ç”Ÿæˆç³»ç»Ÿ",
    version="2.0",
)

# å…¨å±€ Supervisor å®ä¾‹
supervisor = NovelSupervisor(min_workers=2, max_workers=4)

class GenerateRequest(BaseModel):
    novel_input: NovelInput
    priority: int = 0  # 0-9ï¼Œ9 æœ€é«˜

class GenerateResponse(BaseModel):
    task_id: str
    status: str
    message: str

@app.on_event("startup")
async def startup():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    # å¯åŠ¨ Master è¿›ç¨‹ç›‘æ§ï¼ˆåå°ä»»åŠ¡ï¼‰
    import asyncio
    asyncio.create_task(supervisor_monitor())

@app.post("/api/novel/generate", response_model=GenerateResponse)
async def generate_chapter(request: GenerateRequest, background_tasks: BackgroundTasks):
    """æäº¤å°è¯´ç”Ÿæˆä»»åŠ¡"""

    # æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
    task_id = await supervisor.submit_task(
        novel_input=request.novel_input,
        priority=request.priority,
    )

    return GenerateResponse(
        task_id=task_id,
        status="pending",
        message="ä»»åŠ¡å·²æäº¤ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ",
    )

@app.get("/api/novel/status/{task_id}")
async def get_task_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""

    status = await supervisor.get_task_status(task_id)

    if not status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    return JSONResponse(content=status)

@app.get("/api/novel/result/{task_id}")
async def get_task_result(task_id: str):
    """è·å–ä»»åŠ¡ç»“æœ"""

    result = await supervisor.get_task_result(task_id)

    if not result:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if result["status"] == "completed":
        return {
            "task_id": task_id,
            "status": "completed",
            "chapter_content": result["chapter_content"],
            "execution_time": result["execution_time"],
        }
    else:
        return {"task_id": task_id, "status": result["status"]}

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "workers": len(supervisor.workers),
        "queue_size": supervisor.task_queue.qsize(),
    }

@app.get("/api/metrics")
async def get_metrics():
    """è·å–ç³»ç»ŸæŒ‡æ ‡"""
    stats = supervisor.get_execution_stats()

    return {
        "total_executions": stats["total_executions"],
        "success_rate": stats["success_rate"],
        "avg_execution_time": stats["avg_execution_time"],
        "active_workers": len(supervisor.workers),
        "queue_size": supervisor.task_queue.qsize(),
    }
```

##### 2. å¼•å…¥ Redis

**ä½¿ç”¨ Redis å®ç°åˆ†å¸ƒå¼é”å’Œç¼“å­˜ï¼š**
```python
import redis.asyncio as aioredis
import uuid

class RedisDistributedLock:
    """åˆ†å¸ƒå¼é”"""

    def __init__(self, redis: aioredis.Redis):
        self.redis = redis

    async def acquire(self, lock_name: str, expire_time: int = 60) -> str:
        """è·å–é”"""
        lock_id = str(uuid.uuid4())
        acquired = await self.redis.set(
            f"lock:{lock_name}",
            lock_id,
            nx=True,  # ä»…å½“ key ä¸å­˜åœ¨æ—¶è®¾ç½®
            ex=expire_time,  # è¿‡æœŸæ—¶é—´
        )

        return lock_id if acquired else None

    async def release(self, lock_name: str, lock_id: str):
        """é‡Šæ”¾é”"""
        # ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§
        script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        await self.redis.eval(script, 1, f"lock:{lock_name}", lock_id)

# ä½¿ç”¨ç¤ºä¾‹
async def generate_with_lock(novel_input: NovelInput):
    redis = await aioredis.from_url("redis://localhost:6379")
    lock = RedisDistributedLock(redis)

    # é˜²æ­¢é‡å¤ä»»åŠ¡
    task_hash = hashlib.md5(json.dumps(novel_input.dict()).encode()).hexdigest()
    lock_id = await lock.acquire(f"generate:{task_hash}")

    if not lock_id:
        return {"error": "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­"}

    try:
        result = await workflow.aexecute(novel_input)
        return result
    finally:
        await lock.release(f"generate:{task_hash}", lock_id)
```

##### 3. ç›‘æ§å’Œæ—¥å¿—

**æ·»åŠ  Prometheus æŒ‡æ ‡ï¼š**
```python
from prometheus_client import Counter, Histogram, Gauge
import time

# å®šä¹‰æŒ‡æ ‡
request_counter = Counter(
    "novel_generation_requests_total",
    "Total number of novel generation requests",
    ["status"]
)

execution_time_histogram = Histogram(
    "novel_generation_duration_seconds",
    "Novel generation execution time",
    buckets=[1, 5, 10, 20, 30, 60, 120]
)

active_workers_gauge = Gauge(
    "novel_active_workers",
    "Number of active workers"
)

queue_size_gauge = Gauge(
    "novel_queue_size",
    "Number of tasks in queue"
)

# ä½¿ç”¨ç¤ºä¾‹
@execution_time_histogram.time()
async def generate_with_metrics(novel_input: NovelInput):
    start_time = time.time()

    try:
        result = await workflow.aexecute(novel_input)
        request_counter.labels(status="success").inc()
        return result
    except Exception as e:
        request_counter.labels(status="error").inc()
        raise
```

**ç»“æ„åŒ–æ—¥å¿—ï¼š**
```python
import structlog

logger = structlog.get_logger()

async def generate_with_logging(novel_input: NovelInput):
    logger.info(
        "novel_generation_started",
        genre=novel_input.genre,
        chapter_outline=novel_input.chapter_outline,
    )

    try:
        result = await workflow.aexecute(novel_input)

        logger.info(
            "novel_generation_completed",
            execution_time=result.execution_time,
            chapter_length=len(result.chapter_result.content),
        )

        return result

    except Exception as e:
        logger.error(
            "novel_generation_failed",
            error=str(e),
            genre=novel_input.genre,
        )
        raise
```

##### 4. Nginx åå‘ä»£ç†é…ç½®

**æ–°å»ºæ–‡ä»¶ï¼š`nginx.conf`**
```nginx
upstream novel_backend {
    least_conn;  # æœ€å°‘è¿æ¥è´Ÿè½½å‡è¡¡

    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
    server 127.0.0.1:8003;
    server 127.0.0.1:8004;

    keepalive 32;
}

server {
    listen 80;
    server_name novel.example.com;

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;

    location /api/ {
        limit_req zone=api_limit burst=20 nodelay;

        proxy_pass http://novel_backend;
        proxy_http_version 1.1;

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Connection "";

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 300s;  # 5 åˆ†é’Ÿï¼ˆå› ä¸º LLM è°ƒç”¨æ…¢ï¼‰

        # Chunked transfer encodingï¼ˆæ”¯æŒæµå¼ï¼‰
        proxy_buffering off;
    }

    # å¥åº·æ£€æŸ¥
    location /api/health {
        proxy_pass http://novel_backend/api/health;
        access_log off;
    }
}
```

#### é¢„æœŸæ”¶ç›Š

| æŒ‡æ ‡ | Phase 3 | Phase 4 | æå‡ |
|------|---------|---------|------|
| å¹¶å‘ç”¨æˆ·æ•° | 50 | 1000+ | **20 å€** |
| ç³»ç»Ÿå¯ç”¨æ€§ | 95% | 99.9% | **1.05 å€** |
| å¯è§‚æµ‹æ€§ | æ—  | å®Œæ•´ç›‘æ§ | **âœ“** |
| åˆ†å¸ƒå¼æ”¯æŒ | å•æœº | æ”¯æŒé›†ç¾¤ | **âœ“** |

---

## ğŸ¯ æ€»ç»“ï¼šå®Œæ•´æ”¹è¿›è·¯çº¿å›¾

### æ”¹è¿›é˜¶æ®µå¯¹æ¯”

| Phase | æ ¸å¿ƒæ”¹åŠ¨ | éš¾åº¦ | æ”¶ç›Š | ä¼˜å…ˆçº§ | é¢„è®¡å·¥æœŸ |
|-------|---------|------|------|--------|---------|
| **Phase 1** | åŒæ­¥ â†’ å¼‚æ­¥ | â­â­â­ | **3 å€æ€§èƒ½æå‡** | â­â­â­â­â­ | 2-3 å¤© |
| **Phase 2** | å•è¿›ç¨‹ â†’ å¤šè¿›ç¨‹ | â­â­â­â­ | **å¼¹æ€§ä¼¸ç¼© + è‡ªæ„ˆ** | â­â­â­â­ | 3-4 å¤© |
| **Phase 3** | å®Œå…¨ä¸²è¡Œ â†’ æ™ºèƒ½å¹¶è¡Œ | â­â­â­â­â­ | **å†æå‡ 1.7 å€** | â­â­â­â­â­ | 4-5 å¤© |
| **Phase 4** | å¼€å‘ â†’ ç”Ÿäº§çº§ | â­â­â­ | **é«˜å¯ç”¨ + å¯è§‚æµ‹** | â­â­â­ | 3-4 å¤© |

### æ€§èƒ½æå‡é¢„æœŸ

```
æ”¹é€ å‰ï¼š
- å•è¿›ç¨‹åŒæ­¥
- 60 ç§’/è¯·æ±‚
- 1 QPS
- å´©æºƒéœ€æ‰‹åŠ¨é‡å¯

â†“ Phase 1 (å¼‚æ­¥åŒ–)

- å•è¿›ç¨‹å¼‚æ­¥ï¼ˆ5 åç¨‹ï¼‰
- 20 ç§’/è¯·æ±‚
- 5 QPS
- å´©æºƒéœ€æ‰‹åŠ¨é‡å¯

â†“ Phase 2 (å¤šè¿›ç¨‹)

- 4 è¿›ç¨‹å¼‚æ­¥ï¼ˆ4 Ã— 5 åç¨‹ï¼‰
- 20 ç§’/è¯·æ±‚
- 20 QPS
- è‡ªåŠ¨è‡ªæ„ˆ

â†“ Phase 3 (æ™ºèƒ½å¹¶è¡Œ)

- 4 è¿›ç¨‹å¼‚æ­¥ï¼ˆæ™ºèƒ½å¹¶è¡Œï¼‰
- 12 ç§’/è¯·æ±‚
- 33 QPS
- è‡ªåŠ¨è‡ªæ„ˆ + æµå¼è¿”å›

â†“ Phase 4 (ç”Ÿäº§çº§)

- 4 è¿›ç¨‹å¼‚æ­¥ï¼ˆç”Ÿäº§çº§ï¼‰
- 12 ç§’/è¯·æ±‚
- 1000+ å¹¶å‘ç”¨æˆ·
- 99.9% å¯ç”¨æ€§ + å®Œæ•´ç›‘æ§
```

---

## ğŸ’¡ ç«‹å³å¯åšçš„ Quick Win

### Quick Win 1: æ”¹é€ ä¸€ä¸ª Agentï¼ˆ1 å°æ—¶ï¼‰

```python
# Step 1: æ”¹é€  CharacterAgent
class CharacterAgent(BaseAgent):
    async def aexecute(self, task: str, context: Dict) -> AgentResult:
        prompt = self._build_prompt(task, context)
        response = await self.async_llm_client.acall(prompt)
        return self._parse_response(response)

# Step 2: æµ‹è¯•
import asyncio

agent = CharacterAgent(llm_provider="deepseek")
result = asyncio.run(agent.aexecute("è®¾è®¡äººç‰©å¯¹è¯", {...}))
print(result.content)
```

### Quick Win 2: å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ª Agentï¼ˆ2 å°æ—¶ï¼‰

```python
async def parallel_agents():
    character_task = character_agent.aexecute(...)
    scene_task = scene_renderer.aexecute(...)

    character_result, scene_result = await asyncio.gather(
        character_task,
        scene_task
    )

    return character_result, scene_result

# æµ‹è¯•
results = asyncio.run(parallel_agents())
```

### Quick Win 3: æ·»åŠ ç®€å•çš„ Master-Workerï¼ˆ3 å°æ—¶ï¼‰

```python
# å¯åŠ¨è„šæœ¬
supervisor = NovelSupervisor(min_workers=2, max_workers=4)

# æäº¤ä»»åŠ¡
supervisor.task_queue.put({
    "task_id": "test-001",
    "novel_input": NovelInput(...),
})

# å¯åŠ¨ç›‘æ§
supervisor.monitor()
```

**é¢„æœŸç»“æœï¼š**
- æ€§èƒ½æå‡ **5-10 å€**
- å¯ä»¥åŒæ—¶å¤„ç†å¤šä¸ªå°è¯´ç”Ÿæˆè¯·æ±‚
- ç³»ç»Ÿå…·å¤‡åŸºæœ¬çš„è‡ªæ„ˆèƒ½åŠ›

---

## ğŸ“– å‚è€ƒèµ„æ–™

### æŠ€æœ¯æ–‡æ¡£
- [Gunicorn å®˜æ–¹æ–‡æ¡£](https://docs.gunicorn.org/)
- [Uvicorn å®˜æ–¹æ–‡æ¡£](https://www.uvicorn.org/)
- [FastAPI å¼‚æ­¥ç¼–ç¨‹æŒ‡å—](https://fastapi.tiangolo.com/async/)
- [Python asyncio å®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/library/asyncio.html)

### æ¶æ„æ¨¡å¼
- [Master-Worker æ¨¡å¼](https://en.wikipedia.org/wiki/Master-worker)
- [Pre-fork æ¨¡å‹](https://httpd.apache.org/docs/2.4/en/prefork.html)
- [å¼‚æ­¥ I/O æ¨¡å‹](https://en.wikipedia.org/wiki/Asynchronous_I/O)

### ç”Ÿäº§å®è·µ
- [Redis ä»»åŠ¡é˜Ÿåˆ—æœ€ä½³å®è·µ](https://redis.io/topics/lru-cache)
- [Nginx è´Ÿè½½å‡è¡¡é…ç½®](https://docs.nginx.com/nginx/admin-guide/load-balancer/)
- [Prometheus ç›‘æ§å®è·µ](https://prometheus.io/docs/practices/)

---

## ğŸ“ æ€»ç»“

è¿™ä¸ªæ”¹è¿›æ–¹æ¡ˆçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

1. **Phase 1ï¼ˆå¼‚æ­¥åŒ–ï¼‰**ï¼šä»åŒæ­¥é˜»å¡æ”¹ä¸ºå¼‚æ­¥éé˜»å¡ï¼Œæå‡å•ä¸ªè¯·æ±‚çš„æ€§èƒ½
2. **Phase 2ï¼ˆå¤šè¿›ç¨‹ï¼‰**ï¼šå¼•å…¥ Master-Worker æ¨¡å¼ï¼Œå®ç°æ¨ªå‘æ‰©å±•å’Œé«˜å¯ç”¨
3. **Phase 3ï¼ˆæ™ºèƒ½å¹¶è¡Œï¼‰**ï¼šè¯†åˆ«å¯å¹¶è¡Œçš„ Agentï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½
4. **Phase 4ï¼ˆç”Ÿäº§çº§ï¼‰**ï¼šæ·»åŠ ç›‘æ§ã€æ—¥å¿—ã€è´Ÿè½½å‡è¡¡ç­‰ç”Ÿäº§ç‰¹æ€§

**æœ€ç»ˆç›®æ ‡ï¼š**
- ä» **60 ç§’/è¯·æ±‚** ä¼˜åŒ–åˆ° **12 ç§’/è¯·æ±‚**ï¼ˆ5 å€æå‡ï¼‰
- ä» **1 QPS** æå‡åˆ° **33 QPS**ï¼ˆ33 å€æå‡ï¼‰
- ä» **æ‰‹åŠ¨é‡å¯** å‡çº§åˆ° **è‡ªåŠ¨è‡ªæ„ˆ**ï¼ˆ99.9% å¯ç”¨æ€§ï¼‰
- ä» **å•æœº** æ‰©å±•åˆ° **å¯åˆ†å¸ƒå¼éƒ¨ç½²**ï¼ˆæ”¯æŒ 1000+ å¹¶å‘ç”¨æˆ·ï¼‰

---

**å¼€å§‹è¡ŒåŠ¨å§ï¼** ğŸš€

å»ºè®®ä» **Phase 1** å¼€å§‹ï¼Œå…ˆå®Œæˆå¼‚æ­¥åŒ–æ”¹é€ ï¼ŒéªŒè¯æ•ˆæœåå†è¿›è¡Œåç»­ä¼˜åŒ–ã€‚
