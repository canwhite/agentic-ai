# ç¬¬3ç« å­¦ä¹ æŒ‡å—ï¼šå·¥å…·ä½¿ç”¨å®æˆ˜

> **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡å·¥å…·ä½¿ç”¨ï¼ˆTool Useï¼‰çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå­¦ä¼šè®© LLM è°ƒç”¨å¤–éƒ¨å‡½æ•°å’ŒAPI
>
> **å‰ç½®çŸ¥è¯†**ï¼šå®Œæˆç¬¬1-2ç« ï¼Œç†Ÿæ‚‰ Python å‡½æ•°å’Œ API è°ƒç”¨
>
> **é¢„è®¡æ—¶é—´**ï¼š90-120 åˆ†é’Ÿ

---

## ç›®å½•

1. [ä»€ä¹ˆæ˜¯å·¥å…·ä½¿ç”¨ï¼Ÿ](#1-ä»€ä¹ˆæ˜¯å·¥å…·ä½¿ç”¨)
2. [åŸºç¡€å·¥å…·è°ƒç”¨å®ç°](#2-åŸºç¡€å·¥å…·è°ƒç”¨å®ç°)
3. [å®æˆ˜é¡¹ç›®1ï¼šæ™ºèƒ½åŠ©ç†å·¥å…·é›†æˆ](#3-å®æˆ˜é¡¹ç›®1æ™ºèƒ½åŠ©ç†å·¥å…·é›†æˆ)
4. [å®æˆ˜é¡¹ç›®2ï¼šä»£ç æ‰§è¡Œæ²™ç›’](#4-å®æˆ˜é¡¹ç›®2ä»£ç æ‰§è¡Œæ²™ç›’)
5. [MCPåè®®ç®€ä»‹](#5-mcpåè®®ç®€ä»‹)
6. [æœ€ä½³å®è·µä¸å®‰å…¨](#6-æœ€ä½³å®è·µä¸å®‰å…¨)

---

## 1. ä»€ä¹ˆæ˜¯å·¥å…·ä½¿ç”¨ï¼Ÿ

### 1.1 æ ¸å¿ƒæ¦‚å¿µ

**å·¥å…·ä½¿ç”¨ï¼ˆTool Useï¼‰** = èµ‹äºˆ LLM è°ƒç”¨å¤–éƒ¨å‡½æ•°çš„èƒ½åŠ›

**ç±»æ¯”ç†è§£**ï¼š
- æ²¡æœ‰ Tool Use çš„ LLM = åªèƒ½è¯´è¯çš„äºº
- æœ‰ Tool Use çš„ LLM = èƒ½ç”¨å·¥å…·çš„äººï¼ˆå¯ä»¥ç”¨è®¡ç®—å™¨ã€æŸ¥åœ°å›¾ã€å‘é‚®ä»¶ï¼‰

### 1.2 å·¥ä½œæµç¨‹

```
ç”¨æˆ·æé—® "ç°åœ¨å‡ ç‚¹ï¼Ÿ"
    â†“
LLM å†³ç­–ï¼šéœ€è¦è°ƒç”¨ get_current_time() å·¥å…·
    â†“
LLM è¾“å‡ºï¼šFUNCTION_CALL get_current_time()
    â†“
å¼€å‘è€…ä»£ç ï¼šè§£æå¹¶æ‰§è¡Œè¯¥å‡½æ•°
    â†“
å‡½æ•°è¿”å›ï¼š"15:20:45"
    â†“
LLM åŸºäºç»“æœç”Ÿæˆæœ€ç»ˆå›å¤ï¼š"ç°åœ¨æ˜¯ä¸‹åˆ3ç‚¹20åˆ†"
```

### 1.3 å…³é”®è¦ç‚¹

| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| **å·¥å…·** | å°±æ˜¯ Python å‡½æ•° |
| **LLM ä¸ä¼šç›´æ¥è°ƒç”¨** | LLM åª"è¯·æ±‚"è°ƒç”¨ï¼Œå¼€å‘è€…å®é™…æ‰§è¡Œ |
| **è‡ªä¸»å†³ç­–** | LLM è‡ªå·±å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå·¥å…· |

---

## 2. åŸºç¡€å·¥å…·è°ƒç”¨å®ç°

### 2.1 ç¯å¢ƒå‡†å¤‡

```bash
pip install openai python-dotenv aisuite
```

### 2.2 æœ€ç®€å•çš„å·¥å…·ï¼šè·å–å½“å‰æ—¶é—´

åˆ›å»ºæ–‡ä»¶ `simple_tool.py`ï¼š

```python
import os
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# å®šä¹‰å·¥å…·å‡½æ•°
def get_current_time():
    """
    è·å–å½“å‰æ—¶é—´
    """
    return datetime.now().strftime("%H:%M:%S")

# æ‰‹åŠ¨å·¥å…·è°ƒç”¨ï¼ˆä¸ä½¿ç”¨æ¡†æ¶ï¼‰
def manual_tool_use():
    """
    æ‰‹åŠ¨å®ç°å·¥å…·è°ƒç”¨
    """
    user_question = "ç°åœ¨å‡ ç‚¹ï¼Ÿ"

    # ç¬¬1æ­¥ï¼šè®© LLM å†³å®šæ˜¯å¦éœ€è¦å·¥å…·
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": """
å¦‚æœç”¨æˆ·è¯¢é—®æ—¶é—´ï¼Œè¯·è¾“å‡ºï¼šCALL_TOOL get_current_time
å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å›ç­”é—®é¢˜ã€‚
                """
            },
            {"role": "user", "content": user_question}
        ]
    )

    llm_output = response.choices[0].message.content
    print(f"LLM è¾“å‡ºï¼š{llm_output}")

    # ç¬¬2æ­¥ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    if "CALL_TOOL" in llm_output:
        # æå–å·¥å…·åç§°
        tool_name = llm_output.replace("CALL_TOOL", "").strip()

        # ç¬¬3æ­¥ï¼šæ‰§è¡Œå·¥å…·
        if tool_name == "get_current_time":
            result = get_current_time()

        # ç¬¬4æ­¥ï¼šåŸºäºç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        final_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": user_question},
                {"role": "assistant", "content": llm_output},
                {
                    "role": "user",
                    "content": f"å·¥å…·è¿”å›ç»“æœï¼š{result}ï¼Œè¯·å›ç­”ç”¨æˆ·é—®é¢˜"
                }
            ]
        )

        return final_response.choices[0].message.content
    else:
        return llm_output

# æµ‹è¯•
if __name__ == "__main__":
    answer = manual_tool_use()
    print(f"\næœ€ç»ˆç­”æ¡ˆï¼š{answer}")
```

### 2.3 ä½¿ç”¨ AI Suite æ¡†æ¶ï¼ˆæ¨èï¼‰

AI Suite æ˜¯ Andrew Ng å›¢é˜Ÿå¼€å‘çš„åº“ï¼Œç®€åŒ–å·¥å…·è°ƒç”¨ã€‚

åˆ›å»ºæ–‡ä»¶ `aisuite_example.py`ï¼š

```python
import aisuite as ai
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

# å®šä¹‰å·¥å…·
def get_current_time():
    """è·å–å½“å‰æ—¶é—´"""
    return datetime.now().strftime("%H:%M:%S")

def get_weather(location):
    """è·å–å¤©æ°”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    mock_weather = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œ25Â°C",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œ28Â°C",
        "æ·±åœ³": "é˜µé›¨ï¼Œ30Â°C"
    }
    return mock_weather.get(location, f"{location}çš„å¤©æ°”ä¿¡æ¯æš‚æ— ")

# ä½¿ç”¨ AI Suite
def use_aisuite():
    """
    ä½¿ç”¨ AI Suite æ¡†æ¶
    """
    client = ai.Client()

    user_message = "åŒ—äº¬ç°åœ¨å‡ ç‚¹ï¼Ÿå¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"

    response = client.chat.completions.create(
        model="openai:gpt-4o",  # æˆ– "gpt-3.5-turbo"
        messages=[{"role": "user", "content": user_message}],
        tools=[get_current_time, get_weather],  # è‡ªåŠ¨ç”Ÿæˆå·¥å…·æè¿°
        max_turns=5  # æœ€å¤š5è½®å·¥å…·è°ƒç”¨
    )

    print(response.choices[0].message.content)

if __name__ == "__main__":
    use_aisuite()
```

**è¿è¡Œ**ï¼š
```bash
python aisuite_example.py
```

### 2.4 å¸¦å‚æ•°çš„å·¥å…·

```python
def get_current_time(timezone):
    """
    è·å–æŒ‡å®šæ—¶åŒºçš„å½“å‰æ—¶é—´

    Args:
        timezone: IANA æ—¶åŒºå­—ç¬¦ä¸²ï¼Œå¦‚ 'Asia/Shanghai'
    """
    from zoneinfo import ZoneInfo
    from datetime import datetime

    tz = ZoneInfo(timezone)
    return datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

# AI Suite ä¼šè‡ªåŠ¨ä» docstring æå–å‚æ•°è¯´æ˜
```

---

## 3. å®æˆ˜é¡¹ç›®1ï¼šæ™ºèƒ½åŠ©ç†å·¥å…·é›†æˆ

æ„å»ºä¸€ä¸ªèƒ½æŸ¥è¯¢æ—¥å†ã€å‘é€é‚®ä»¶ã€æŸ¥è¯¢è®¢å•çš„æ™ºèƒ½åŠ©ç†ã€‚

### 3.1 é¡¹ç›®ç»“æ„

```
smart_assistant/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ calendar.py    # æ—¥å†å·¥å…·
â”‚   â”œâ”€â”€ email.py       # é‚®ä»¶å·¥å…·
â”‚   â””â”€â”€ database.py    # æ•°æ®åº“å·¥å…·
â”œâ”€â”€ config.py
â””â”€â”€ assistant.py       # ä¸»ç¨‹åº
```

### 3.2 å®Œæ•´å®ç°

#### tools/calendar.py

```python
# tools/calendar.py
from datetime import datetime, timedelta

# æ¨¡æ‹Ÿæ—¥å†æ•°æ®
CALENDAR = {
    "2025-01-15": [
        {"time": "09:00", "event": "å›¢é˜Ÿä¼šè®®", "duration": 60}
    ],
    "2025-01-16": [
        {"time": "14:00", "event": "é¡¹ç›®è¯„å®¡", "duration": 120},
        {"time": "16:00", "event": "å®¢æˆ·ç”µè¯", "duration": 30}
    ]
}

def check_calendar(date):
    """
    æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ—¥ç¨‹å®‰æ’

    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ï¼šYYYY-MM-DD
    """
    events = CALENDAR.get(date, [])
    if events:
        result = f"{date} çš„æ—¥ç¨‹ï¼š\n"
        for event in events:
            result += f"- {event['time']}: {event['event']} ({event['duration']}åˆ†é’Ÿ)\n"
        return result
    else:
        return f"{date} æ²¡æœ‰å®‰æ’æ—¥ç¨‹"

def find_free_slots(date, duration_minutes=60):
    """
    æŸ¥æ‰¾æŒ‡å®šæ—¥æœŸçš„ç©ºé—²æ—¶æ®µ

    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸²
        duration_minutes: éœ€è¦çš„æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
    """
    busy_times = [e['time'] for e in CALENDAR.get(date, [])]

    # ç®€åŒ–é€»è¾‘ï¼šå‡è®¾å·¥ä½œæ—¶é—´ 9:00-18:00
    all_slots = ["09:00", "10:00", "11:00", "14:00", "15:00", "16:00", "17:00"]

    free_slots = [slot for slot in all_slots if slot not in busy_times]

    if free_slots:
        return f"{date} çš„ç©ºé—²æ—¶æ®µï¼ˆ{duration_minutes}åˆ†é’Ÿï¼‰ï¼š{', '.join(free_slots)}"
    else:
        return f"{date} æ²¡æœ‰åˆé€‚çš„ç©ºé—²æ—¶æ®µ"
```

#### tools/email.py

```python
# tools/email.py
import os

SENT_EMAILS = []

def send_email(to, subject, body):
    """
    å‘é€é‚®ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰

    Args:
        to: æ”¶ä»¶äººé‚®ç®±
        subject: é‚®ä»¶ä¸»é¢˜
        body: é‚®ä»¶æ­£æ–‡
    """
    email = {
        "to": to,
        "subject": subject,
        "body": body,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    SENT_EMAILS.append(email)

    return f"é‚®ä»¶å·²å‘é€åˆ° {to}ï¼Œä¸»é¢˜ï¼š{subject}"

def list_sent_emails():
    """
    åˆ—å‡ºå·²å‘é€çš„é‚®ä»¶
    """
    if not SENT_EMAILS:
        return "æš‚æ— å·²å‘é€é‚®ä»¶"

    result = "å·²å‘é€é‚®ä»¶åˆ—è¡¨ï¼š\n"
    for email in SENT_EMAILS:
        result += f"- {email['timestamp']}: {email['subject']} -> {email['to']}\n"

    return result
```

#### tools/database.py

```python
# tools/database.py

# æ¨¡æ‹Ÿè®¢å•æ•°æ®åº“
ORDERS = {
    "#8847": {
        "customer": "å¼ ä¸‰",
        "email": "zhangsan@example.com",
        "product": "KitchenPro æ…æ‹Œæœº",
        "color": "è“è‰²",
        "price": 299,
        "status": "å·²å‘è´§"
    },
    "#8848": {
        "customer": "æå››",
        "email": "lisi@example.com",
        "product": "çƒ¤é¢åŒ…æœº",
        "color": "çº¢è‰²",
        "price": 199,
        "status": "å¾…å‘è´§"
    }
}

def query_order(order_id):
    """
    æŸ¥è¯¢è®¢å•ä¿¡æ¯

    Args:
        order_id: è®¢å•å·ï¼Œå¦‚ #8847
    """
    order = ORDERS.get(order_id)
    if order:
        return f"""
è®¢å•å·ï¼š{order_id}
å®¢æˆ·ï¼š{order['customer']}
é‚®ç®±ï¼š{order['email']}
å•†å“ï¼š{order['product']}ï¼ˆ{order['color']}ï¼‰
ä»·æ ¼ï¼šÂ¥{order['price']}
çŠ¶æ€ï¼š{order['status']}
        """.strip()
    else:
        return f"è®¢å• {order_id} ä¸å­˜åœ¨"

def update_order_status(order_id, new_status):
    """
    æ›´æ–°è®¢å•çŠ¶æ€

    Args:
        order_id: è®¢å•å·
        new_status: æ–°çŠ¶æ€
    """
    if order_id in ORDERS:
        ORDERS[order_id]['status'] = new_status
        return f"è®¢å• {order_id} çŠ¶æ€å·²æ›´æ–°ä¸ºï¼š{new_status}"
    else:
        return f"è®¢å• {order_id} ä¸å­˜åœ¨"
```

#### assistant.py

```python
# assistant.py
import aisuite as ai
from tools.calendar import check_calendar, find_free_slots
from tools.email import send_email, list_sent_emails
from tools.database import query_order, update_order_status

def create_assistant():
    """
    åˆ›å»ºæ™ºèƒ½åŠ©ç†
    """
    client = ai.Client()

    # æ‰€æœ‰å¯ç”¨å·¥å…·
    tools = [
        check_calendar,
        find_free_slots,
        send_email,
        list_sent_emails,
        query_order,
        update_order_status
    ]

    return client, tools

def run_assistant():
    """
    è¿è¡Œæ™ºèƒ½åŠ©ç†
    """
    client, tools = create_assistant()

    print("="*60)
    print("ğŸ¤– æ™ºèƒ½åŠ©ç†å·²å¯åŠ¨ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰")
    print("="*60)
    print("å¯ç”¨åŠŸèƒ½ï¼šæŸ¥è¯¢æ—¥å†ã€å‘é€é‚®ä»¶ã€æŸ¥è¯¢è®¢å•ã€æ›´æ–°è®¢å•çŠ¶æ€")
    print("-"*60)

    while True:
        user_input = input("\næ‚¨ï¼š")

        if user_input.lower() == 'quit':
            print("å†è§ï¼")
            break

        print("\nåŠ©ç†æ€è€ƒä¸­...")

        response = client.chat.completions.create(
            model="openai:gpt-4o",
            messages=[{"role": "user", "content": user_input}],
            tools=tools,
            max_turns=10
        )

        answer = response.choices[0].message.content
        print(f"\nåŠ©ç†ï¼š{answer}")

if __name__ == "__main__":
    run_assistant()
```

### 3.3 è¿è¡Œæµ‹è¯•

```bash
python assistant.py
```

**æµ‹è¯•å¯¹è¯**ï¼š
```
æ‚¨ï¼šæŸ¥è¯¢ä¸€ä¸‹2025-01-16çš„æ—¥ç¨‹
åŠ©ç†ï¼š2025-01-16 çš„æ—¥ç¨‹ï¼š
- 14:00: é¡¹ç›®è¯„å®¡ (120åˆ†é’Ÿ)
- 16:00: å®¢æˆ·ç”µè¯ (30åˆ†é’Ÿ)

æ‚¨ï¼šå¸®æˆ‘åœ¨é‚£å¤©æ‰¾ä¸ª60åˆ†é’Ÿçš„ç©ºé—²æ—¶æ®µ
åŠ©ç†ï¼š2025-01-16 çš„ç©ºé—²æ—¶æ®µï¼ˆ60åˆ†é’Ÿï¼‰ï¼š09:00, 10:00, 11:00, 17:00

æ‚¨ï¼šæŸ¥è¯¢è®¢å•#8847
åŠ©ç†ï¼šè®¢å•å·ï¼š#8847
å®¢æˆ·ï¼šå¼ ä¸‰
é‚®ç®±ï¼šzhangsan@example.com
å•†å“ï¼šKitchenPro æ…æ‹Œæœºï¼ˆè“è‰²ï¼‰
ä»·æ ¼ï¼šÂ¥299
çŠ¶æ€ï¼šå·²å‘è´§

æ‚¨ï¼šç»™zhangsan@example.comå‘é‚®ä»¶ï¼Œå‘Šè¯‰ä»–è®¢å•å·²å‘è´§
åŠ©ç†ï¼š[è‡ªåŠ¨è°ƒç”¨ send_email å·¥å…·]
é‚®ä»¶å·²å‘é€åˆ° zhangsan@example.comï¼Œä¸»é¢˜ï¼šå…³äºæ‚¨çš„è®¢å• #8847
```

---

## 4. å®æˆ˜é¡¹ç›®2ï¼šä»£ç æ‰§è¡Œæ²™ç›’

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦ä»£ç æ‰§è¡Œï¼Ÿ

**åœºæ™¯**ï¼šç”¨æˆ·é—®"2çš„å¹³æ–¹æ ¹æ˜¯å¤šå°‘ï¼Ÿ"
- æ–¹æ¡ˆAï¼šä¸ºæ¯ä¸ªæ•°å­¦å‡½æ•°åˆ›å»ºå·¥å…·ï¼ˆsqrt, pow, log...ï¼‰â†’ æ— ç©·æ— å°½
- æ–¹æ¡ˆBï¼šè®© LLM å†™ä»£ç å¹¶æ‰§è¡Œ â†’ çµæ´»å¼ºå¤§

### 4.2 å®‰å…¨çš„ä»£ç æ‰§è¡Œ

åˆ›å»ºæ–‡ä»¶ `code_executor.py`ï¼š

```python
import os
import sys
from io import StringIO
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class SafeCodeExecutor:
    """
    å®‰å…¨çš„ä»£ç æ‰§è¡Œå™¨
    """
    def __init__(self):
        self.client = client

    def execute_code(self, code):
        """
        å®‰å…¨æ‰§è¡Œ Python ä»£ç 

        Args:
            code: è¦æ‰§è¡Œçš„ Python ä»£ç 
        """
        # é‡å®šå‘è¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()

        try:
            # é™åˆ¶å¯ç”¨çš„å†…ç½®å‡½æ•°ï¼ˆåŸºç¡€å®‰å…¨ï¼‰
            safe_globals = {
                "__builtins__": {
                    "print": print,
                    "len": len,
                    "range": range,
                    "str": str,
                    "int": int,
                    "float": float,
                    "list": list,
                    "dict": dict,
                    "sum": sum,
                    "max": max,
                    "min": min,
                    "abs": abs,
                    "round": round,
                }
            }

            # æ‰§è¡Œä»£ç 
            exec(code, safe_globals, {})

            # è·å–è¾“å‡º
            output = captured_output.getvalue()

            return {
                "success": True,
                "output": output,
                "error": None
            }

        except Exception as e:
            return {
                "success": False,
                "output": None,
                "error": str(e)
            }

        finally:
            sys.stdout = old_stdout

    def solve_with_code(self, question):
        """
        ç”¨ä»£ç è§£å†³é—®é¢˜

        Args:
            question: ç”¨æˆ·é—®é¢˜
        """
        # ç¬¬1æ­¥ï¼šç”Ÿæˆä»£ç 
        print("ğŸ“ ç”Ÿæˆä»£ç ...")
        code_response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """
ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹ä¸“å®¶ã€‚è¯·ç”¨ Python ä»£ç è§£å†³ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. ä»£ç è¦å®Œæ•´å¯è¿è¡Œ
2. ç”¨ print() è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
3. ä»£ç ç”¨ ```python ... ``` åŒ…è£¹
                    """
                },
                {"role": "user", "content": question}
            ]
        )

        code_text = code_response.choices[0].message.content

        # æå–ä»£ç ï¼ˆå»é™¤ ```python æ ‡è®°ï¼‰
        if "```python" in code_text:
            code = code_text.split("```python")[1].split("```")[0].strip()
        else:
            code = code_text

        print(f"ä»£ç ï¼š\n{code}\n")

        # ç¬¬2æ­¥ï¼šæ‰§è¡Œä»£ç 
        print("âš¡ æ‰§è¡Œä»£ç ...")
        result = self.execute_code(code)

        # ç¬¬3æ­¥ï¼šå¤„ç†ç»“æœ
        if result["success"]:
            print(f"âœ… æ‰§è¡ŒæˆåŠŸï¼\nè¾“å‡ºï¼š{result['output']}")

            # æ ¼å¼åŒ–è¾“å‡º
            formatted = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "user",
                        "content": f"""
ç”¨æˆ·é—®é¢˜ï¼š{question}

ä»£ç è¾“å‡ºï¼š{result['output']}

è¯·åŸºäºä»£ç è¾“å‡ºï¼Œç»™å‡ºä¸€ä¸ªå‹å¥½çš„ç­”æ¡ˆã€‚
                    """
                    }
                ]
            )
            return formatted.choices[0].message.content
        else:
            print(f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{result['error']}")

            # å°è¯•ä¿®å¤
            print("\nğŸ”§ å°è¯•ä¿®å¤...")
            fixed_code = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "user",
                        "content": f"""
åŸå§‹ä»£ç ï¼š
{code}

é”™è¯¯ä¿¡æ¯ï¼š{result['error']}

è¯·ä¿®å¤ä»£ç å¹¶é‡æ–°ç”Ÿæˆã€‚
                    """
                }
            )
            # é€’å½’é‡è¯•ï¼ˆæœ€å¤š1æ¬¡ï¼‰
            return self.solve_with_code(question)

# æµ‹è¯•
if __name__ == "__main__":
    executor = SafeCodeExecutor()

    test_questions = [
        "2çš„å¹³æ–¹æ ¹æ˜¯å¤šå°‘ï¼Ÿ",
        "1åˆ°100ä¹‹é—´æ‰€æœ‰å¶æ•°çš„å’Œ",
        "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‰10é¡¹"
    ]

    for question in test_questions:
        print("="*60)
        print(f"é—®é¢˜ï¼š{question}")
        print("="*60)
        answer = executor.solve_with_code(question)
        print(f"\nç­”æ¡ˆï¼š{answer}\n")
```

### 4.3 æ›´å®‰å…¨çš„æ–¹æ¡ˆï¼šä½¿ç”¨ E2B

**ç”Ÿäº§ç¯å¢ƒæ¨è**ï¼šä½¿ç”¨ä¸“ä¸šçš„ä»£ç æ‰§è¡Œæ²™ç›’ E2B

```bash
pip install e2b
```

```python
from e2b import Sandbox

async def execute_with_e2b(code):
    """
    ä½¿ç”¨ E2B æ²™ç›’æ‰§è¡Œä»£ç 
    """
    sandbox = await Sandbox.create()

    try:
        result = await sandbox.run_code(code)
        return result
    finally:
        await sandbox.kill()
```

---

## 5. MCPåè®®ç®€ä»‹

### 5.1 ä»€ä¹ˆæ˜¯ MCPï¼Ÿ

**MCP (Model Context Protocol)** = å·¥å…·ä½¿ç”¨çš„æ ‡å‡†åè®®

**è§£å†³çš„é—®é¢˜**ï¼š
- ä¹‹å‰ï¼šæ¯ä¸ªåº”ç”¨éƒ½è¦è‡ªå·±é›†æˆ Slackã€GitHub ç­‰å·¥å…·ï¼ˆå·¥ä½œé‡ mÃ—nï¼‰
- ç°åœ¨ï¼šåªéœ€è¿æ¥ MCP æœåŠ¡å™¨ï¼ˆå·¥ä½œé‡ m+nï¼‰

### 5.2 ä½¿ç”¨ç¤ºä¾‹

```python
# ä¼ªä»£ç ç¤ºä¾‹
from mcp import Client

# è¿æ¥åˆ° GitHub MCP æœåŠ¡å™¨
github_client = Client("github-mcp-server")

# è°ƒç”¨å·¥å…·
repo_info = github_client.call("get_repo", {
    "owner": "andrewng",
    "repo": "aisuite"
})

print(repo_info)
```

### 5.3 å¸¸è§ MCP æœåŠ¡å™¨

| æœåŠ¡å™¨ | åŠŸèƒ½ |
|--------|------|
| GitHub | æŸ¥è¯¢ä»“åº“ã€PRã€Issue |
| Slack | å‘é€æ¶ˆæ¯ã€è¯»å–é¢‘é“ |
| Google Drive | è¯»å–ã€ç¼–è¾‘æ–‡ä»¶ |
| PostgreSQL | æŸ¥è¯¢æ•°æ®åº“ |

---

## 6. æœ€ä½³å®è·µä¸å®‰å…¨

### 6.1 å·¥å…·è®¾è®¡åŸåˆ™

**åŸåˆ™1ï¼šå•ä¸€èŒè´£**
```python
# âŒ ä¸å¥½ï¼šä¸€ä¸ªå‡½æ•°åšå¤ªå¤šäº‹
def handle_user_request(request):
    # æŸ¥è¯¢æ•°æ®åº“
    # å‘é€é‚®ä»¶
    # æ›´æ–°æ—¥å†
    # ...

# âœ… å¥½ï¼šæ¯ä¸ªå‡½æ•°åªåšä¸€ä»¶äº‹
def query_database(table, conditions):
    ...

def send_email(to, subject, body):
    ...

def update_calendar(date, event):
    ...
```

**åŸåˆ™2ï¼šæ¸…æ™°çš„æ–‡æ¡£**
```python
def calculate_loan(principal, rate, years):
    """
    è®¡ç®—è´·æ¬¾æœˆä¾›

    Args:
        principal: è´·æ¬¾æœ¬é‡‘ï¼ˆå…ƒï¼‰
        rate: å¹´åˆ©ç‡ï¼ˆç™¾åˆ†æ¯”ï¼Œå¦‚ 5.5 è¡¨ç¤º 5.5%ï¼‰
        years: è´·æ¬¾å¹´é™

    Returns:
        float: æœˆä¾›é‡‘é¢ï¼ˆå…ƒï¼‰

    Example:
        >>> calculate_loan(100000, 5.5, 20)
        682.55
    """
    ...
```

### 6.2 å®‰å…¨æ£€æŸ¥æ¸…å•

åœ¨å…è®¸ LLM è°ƒç”¨å·¥å…·å‰ï¼Œæ£€æŸ¥ï¼š

- [ ] **è¾“å…¥éªŒè¯**ï¼šå‚æ•°ç±»å‹ã€èŒƒå›´æ£€æŸ¥
- [ ] **æƒé™æ§åˆ¶**ï¼šæ˜¯å¦å…è®¸è¯¥æ“ä½œ
- [ ] **èµ„æºé™åˆ¶**ï¼šé˜²æ­¢æ— é™å¾ªç¯
- [ ] **æ²™ç›’æ‰§è¡Œ**ï¼šä»£ç æ‰§è¡Œå¿…é¡»åœ¨éš”ç¦»ç¯å¢ƒ
- [ ] **æ—¥å¿—è®°å½•**ï¼šè®°å½•æ‰€æœ‰å·¥å…·è°ƒç”¨

### 6.3 å¸¸è§é™·é˜±

**é™·é˜±1ï¼šè¿‡åº¦ä½¿ç”¨å·¥å…·**
```python
# âŒ ä¸å¥½ï¼šç®€å•é—®é¢˜ä¸éœ€è¦å·¥å…·
user: "2+2ç­‰äºå‡ ï¼Ÿ"
tool: calculator.calculate(2, 2)

# âœ… å¥½ï¼šç›´æ¥å›ç­”
user: "2+2ç­‰äºå‡ ï¼Ÿ"
llm: "2+2ç­‰äº4"
```

**é™·é˜±2ï¼šå·¥å…·å†²çª**
```python
# âŒ ä¸å¥½ï¼šä¸¤ä¸ªå·¥å…·åŠŸèƒ½é‡å 
def get_time():
    ...

def get_current_time():
    ...

# âœ… å¥½ï¼šåŠŸèƒ½æ¸…æ™°
def get_current_time():
    """è·å–å½“å‰æ—¶é—´"""
    ...

def convert_time_zone(time, from_tz, to_tz):
    """è½¬æ¢æ—¶åŒº"""
    ...
```

### 6.4 å·¥å…·ä½¿ç”¨å®‰å…¨æ£€æŸ¥æ¸…å•

åœ¨éƒ¨ç½²å·¥å…·ä½¿ç”¨å‰ï¼ŒåŠ¡å¿…æ£€æŸ¥ï¼š

- [ ] **è¾“å…¥éªŒè¯**ï¼šéªŒè¯æ‰€æœ‰å‚æ•°ç±»å‹å’ŒèŒƒå›´
- [ ] **æƒé™æ§åˆ¶**ï¼šç¡®ä¿ç”¨æˆ·åªèƒ½æ‰§è¡Œæˆæƒæ“ä½œ
- [ ] **é”™è¯¯å¤„ç†**ï¼šä¼˜é›…å¤„ç†å·¥å…·æ‰§è¡Œå¤±è´¥
- [ ] **æ—¥å¿—è®°å½•**ï¼šè®°å½•æ‰€æœ‰å·¥å…·è°ƒç”¨ç”¨äºå®¡è®¡
- [ ] **èµ„æºé™åˆ¶**ï¼šé™åˆ¶æ‰§è¡Œæ—¶é—´å’Œå†…å­˜ä½¿ç”¨
- [ ] **ä»£ç æ‰§è¡Œå®‰å…¨**ï¼šç»ä¸ç›´æ¥æ‰§è¡Œç”¨æˆ·ä»£ç ï¼ˆç”¨æ²™ç›’ï¼‰

### 6.5 å·¥å…·è¯­æ³•è¯¦ç»†è§„èŒƒ

**AI Suiteè‡ªåŠ¨åŒ–å·¥å…·å®šä¹‰**ï¼š

```python
from aisuite import AISuite

# å®šä¹‰å·¥å…·å‡½æ•°
def get_weather(location: str, unit: str = "celsius") -> dict:
    """è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯

    Args:
        location: åŸå¸‚åç§°ï¼Œå¦‚ "åŒ—äº¬"
        unit: æ¸©åº¦å•ä½ï¼Œå¯é€‰ "celsius" æˆ– "fahrenheit"

    Returns:
        dict: åŒ…å«æ¸©åº¦ã€æ¹¿åº¦ã€å¤©æ°”çŠ¶å†µçš„å­—å…¸
    """
    # å®é™…APIè°ƒç”¨é€»è¾‘
    return {"temperature": 25, "humidity": 60, "condition": "æ™´"}

# AI Suiteè‡ªåŠ¨è½¬æ¢å·¥å…·å®šä¹‰
client = AISuite()
client.add_tool(get_weather)  # è‡ªåŠ¨ä»docstringç”ŸæˆJSON Schema

# ä½¿ç”¨å·¥å…·
response = client.chat(
    model="gpt-4o",
    messages=[{"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ"}],
    tools=[get_weather]  # ä¼ å…¥å·¥å…·å‡½æ•°åˆ—è¡¨
)
```

**æ‰‹åŠ¨vsè‡ªåŠ¨å·¥å…·è°ƒç”¨å¯¹æ¯”**ï¼š

```python
# æ‰‹åŠ¨å·¥å…·è°ƒç”¨ï¼ˆå¤æ‚ï¼‰
def manual_tool_call():
    # ç¬¬1æ­¥ï¼šè®©LLMå†³å®šæ˜¯å¦éœ€è¦å·¥å…·
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ç”¨ï¼š..."},
            {"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}
        ],
        tools=[{
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "è·å–å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {"type": "string", "description": "åŸå¸‚åç§°"},
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                    },
                    "required": ["location"]
                }
            }
        }]
    )

    # ç¬¬2æ­¥ï¼šè§£æå·¥å…·è°ƒç”¨è¯·æ±‚
    if response.choices[0].message.tool_calls:
        tool_call = response.choices[0].message.tool_calls[0]
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)

        # ç¬¬3æ­¥ï¼šæ‰§è¡Œå·¥å…·å‡½æ•°
        if function_name == "get_weather":
            result = get_weather(**function_args)

        # ç¬¬4æ­¥ï¼šå°†ç»“æœè¿”å›ç»™LLM
        final_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"},
                response.choices[0].message,
                {"role": "tool", "tool_call_id": tool_call.id, "content": str(result)}
            ]
        )

# è‡ªåŠ¨å·¥å…·è°ƒç”¨ï¼ˆç®€æ´ï¼‰
def auto_tool_call():
    response = client.chat(
        model="gpt-4o",
        messages=[{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}],
        tools=[get_weather]
    )
    return response.choices[0].message.content
```

### 6.6 MCPåè®®å®ç°ç»†èŠ‚

**åè®®æ ¸å¿ƒæ¦‚å¿µ**ï¼š

```python
# MCPå®¢æˆ·ç«¯-æœåŠ¡å™¨æ¶æ„
class MCPClient:
    def __init__(self, server_url):
        self.server_url = server_url
        self.capabilities = self.get_server_capabilities()

    def get_server_capabilities(self):
        """è·å–æœåŠ¡å™¨èƒ½åŠ›"""
        response = requests.get(f"{self.server_url}/capabilities")
        return response.json()

    def execute_tool(self, tool_name, parameters):
        """æ‰§è¡Œè¿œç¨‹å·¥å…·"""
        response = requests.post(
            f"{self.server_url}/tools/{tool_name}",
            json=parameters
        )
        return response.json()

# GitHub MCPæœåŠ¡å™¨ç¤ºä¾‹
class GitHubMCPServer:
    def __init__(self, github_token):
        self.github_token = github_token
        self.tools = {
            'get_repo_info': self.get_repository_info,
            'create_issue': self.create_issue,
            'get_file_contents': self.get_file_contents
        }

    def get_repository_info(self, owner, repo):
        """è·å–ä»“åº“ä¿¡æ¯"""
        headers = {'Authorization': f'token {self.github_token}'}
        response = requests.get(
            f"https://api.github.com/repos/{owner}/{repo}",
            headers=headers
        )
        return response.json()
```

**å·¥ä½œæµç¨‹ç¤ºä¾‹**ï¼š

```python
# Claude Desktop + GitHub MCPå·¥ä½œæµ
def github_workflow_example():
    """GitHub MCPåè®®å·¥ä½œæµç¤ºä¾‹"""
    # 1. ç”¨æˆ·æé—®ï¼š"å¸®æˆ‘æŸ¥çœ‹agentic-aiä»“åº“çš„æœ€æ–°æäº¤"
    user_query = "å¸®æˆ‘æŸ¥çœ‹agentic-aiä»“åº“çš„æœ€æ–°æäº¤"

    # 2. Claudeè¯†åˆ«éœ€è¦è°ƒç”¨GitHubå·¥å…·
    # 3. é€šè¿‡MCPåè®®è°ƒç”¨GitHubæœåŠ¡å™¨
    github_client = MCPClient("http://localhost:8080")

    # 4. è·å–ä»“åº“ä¿¡æ¯
    repo_info = github_client.execute_tool(
        "get_repo_info",
        {"owner": "your-username", "repo": "agentic-ai"}
    )

    # 5. è·å–æœ€æ–°æäº¤
    commits = github_client.execute_tool(
        "get_commits",
        {"owner": "your-username", "repo": "agentic-ai", "per_page": 5}
    )

    # 6. ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
    return f"ä»“åº“agentic-aiçš„æœ€æ–°5æ¬¡æäº¤æ˜¯ï¼š{commits}"
```

### 6.7 ä»£ç æ‰§è¡Œæ·±åº¦å®ç°

**å®‰å…¨çš„ä»£ç æ‰§è¡Œå™¨**ï¼š

```python
class SafeCodeExecutor:
    def __init__(self):
        self.safe_builtins = {
            "print": print,
            "len": len, "range": range, "str": str,
            "int": int, "float": float, "list": list,
            "dict": dict, "sum": sum, "max": max, "min": min,
            "sorted": sorted, "enumerate": enumerate, "zip": zip
        }
        self.execution_history = []

    def execute_code(self, code, timeout=5):
        """å®‰å…¨æ‰§è¡ŒPythonä»£ç """
        import sys
        from io import StringIO

        # æ•è·è¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()

        try:
            # åˆ›å»ºå®‰å…¨çš„æ‰§è¡Œç¯å¢ƒ
            safe_globals = {
                "__builtins__": self.safe_builtins,
                "__name__": "__main__"
            }

            # æ‰§è¡Œä»£ç ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
            start_time = time.time()
            exec(code, safe_globals)
            execution_time = time.time() - start_time

            # è·å–è¾“å‡ºç»“æœ
            output = captured_output.getvalue()

            # è®°å½•æ‰§è¡Œå†å²
            self.execution_history.append({
                "code": code,
                "output": output,
                "execution_time": execution_time,
                "success": True
            })

            return {
                "success": True,
                "output": output,
                "execution_time": execution_time
            }

        except Exception as e:
            error_msg = str(e)
            self.execution_history.append({
                "code": code,
                "error": error_msg,
                "success": False
            })
            return {
                "success": False,
                "error": error_msg
            }
        finally:
            sys.stdout = old_stdout

    def reflect_and_fix(self, code, error_msg):
        """åŸºäºé”™è¯¯ä¿¡æ¯åæ€å¹¶ä¿®å¤ä»£ç """
        reflection_prompt = f"""
        ä»¥ä¸‹Pythonä»£ç æ‰§è¡Œå‡ºé”™ï¼š

        ä»£ç ï¼š{code}
        é”™è¯¯ä¿¡æ¯ï¼š{error_msg}

        è¯·åˆ†æé”™è¯¯åŸå› å¹¶æä¾›ä¿®æ­£åçš„ä»£ç ã€‚
        åªè¿”å›ä¿®æ­£åçš„å®Œæ•´ä»£ç ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€‚
        """

        fixed_code = llm_call(reflection_prompt)
        return fixed_code.strip()
```

**åæ€æœºåˆ¶é›†æˆ**ï¼š

```python
def code_execution_with_reflection(task, max_attempts=3):
    """å¸¦åæ€çš„ä»£ç æ‰§è¡Œå·¥ä½œæµ"""
    executor = SafeCodeExecutor()

    for attempt in range(max_attempts):
        print(f"å°è¯• {attempt + 1}...")

        # ç”Ÿæˆä»£ç 
        if attempt == 0:
            code = generate_code(task)
        else:
            # åŸºäºä¹‹å‰çš„é”™è¯¯åæ€æ”¹è¿›
            code = executor.reflect_and_fix(last_code, last_error)

        # æ‰§è¡Œä»£ç 
        result = executor.execute_code(code)

        if result["success"]:
            print(f"âœ… æ‰§è¡ŒæˆåŠŸï¼")
            return result["output"]
        else:
            print(f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{result['error']}")
            last_code = code
            last_error = result["error"]

    return "è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œæ— æ³•ç”Ÿæˆæ­£ç¡®ä»£ç "
```

### 6.8 é‚®ä»¶åŠ©ç†å·¥ä½œæµå®Œæ•´å®ç°

**å®Œæ•´é¡¹ç›®ç»“æ„**ï¼š

```python
# email_assistant/main.py
from tools.email_tools import (
    search_emails, list_sent_emails, get_email_by_id,
    send_email, mark_as_read, delete_email
)
from tools.analysis_tools import analyze_email_content
from tools.response_tools import generate_follow_up

def email_assistant_workflow(user_request):
    """é‚®ä»¶åŠ©ç†å®Œæ•´å·¥ä½œæµ"""
    print("ğŸš€ å¼€å§‹å¤„ç†é‚®ä»¶è¯·æ±‚...")

    # ç¬¬1æ­¥ï¼šç†è§£ç”¨æˆ·æ„å›¾
    intent = understand_intent(user_request)

    if intent["action"] == "search":
        # æœç´¢é‚®ä»¶
        results = search_emails(intent["criteria"])
        return format_search_results(results)

    elif intent["action"] == "send_follow_up":
        # å‘é€è·Ÿè¿›é‚®ä»¶å·¥ä½œæµ
        return send_follow_up_workflow(intent["context"])

    elif intent["action"] == "analyze":
        # åˆ†æé‚®ä»¶å†…å®¹
        emails = search_emails(intent["criteria"])
        analysis = analyze_email_content(emails)
        return format_analysis_report(analysis)

def send_follow_up_workflow(context):
    """å‘é€è·Ÿè¿›é‚®ä»¶çš„å®Œæ•´å·¥ä½œæµ"""
    # 1. æœç´¢ç›¸å…³é‚®ä»¶
    original_emails = search_emails({
        "from": context["recipient"],
        "subject_contains": context["subject_keyword"],
        "unread": True
    })

    if not original_emails:
        return "æœªæ‰¾åˆ°éœ€è¦è·Ÿè¿›çš„é‚®ä»¶"

    # 2. åˆ†æé‚®ä»¶å†…å®¹
    email_analysis = analyze_email_content(original_emails)

    # 3. ç”Ÿæˆè·Ÿè¿›å†…å®¹
    follow_up_content = generate_follow_up(email_analysis)

    # 4. å‘é€è·Ÿè¿›é‚®ä»¶
    result = send_email(
        to=context["recipient"],
        subject=f"è·Ÿè¿›ï¼š{email_analysis['subject']}",
        body=follow_up_content
    )

    # 5. æ ‡è®°åŸé‚®ä»¶ä¸ºå·²è¯»
    for email in original_emails:
        mark_as_read(email["id"])

    return f"è·Ÿè¿›é‚®ä»¶å·²å‘é€ï¼Œæ ‡è®°äº†{len(original_emails)}å°é‚®ä»¶ä¸ºå·²è¯»"
```

### 6.9 å…³é”®æ´å¯Ÿå’Œæœ€ä½³å®è·µ

**å·¥å…·è®¾è®¡åŸåˆ™**ï¼š
1. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªå·¥å…·åªåšä¸€ä»¶äº‹
2. **æ¸…æ™°æ–‡æ¡£**ï¼šdocstringå†³å®šLLMçš„ç†è§£
3. **ä¸€è‡´æ€§**ï¼šè¿”å›æ ¼å¼ç»Ÿä¸€çš„JSONæ•°æ®
4. **æ¸è¿›å¼**ï¼šä»ç®€å•å·¥å…·å¼€å§‹é€æ­¥å¤æ‚åŒ–

**å®‰å…¨æœ€ä½³å®è·µ**ï¼š
1. **è¾“å…¥éªŒè¯**ï¼šå‚æ•°ç±»å‹å’ŒèŒƒå›´æ£€æŸ¥
2. **æƒé™æ§åˆ¶**ï¼šæ“ä½œå‰çš„æƒé™éªŒè¯
3. **èµ„æºé™åˆ¶**ï¼šé˜²æ­¢æ— é™å¾ªç¯å’Œèµ„æºè€—å°½
4. **æ²™ç›’æ‰§è¡Œ**ï¼šä»£ç æ‰§è¡Œå¿…é¡»éš”ç¦»
5. **æ—¥å¿—è®°å½•**ï¼šå®Œæ•´çš„æ“ä½œå®¡è®¡è½¨è¿¹

**æ¨¡å‹é€‰æ‹©ç­–ç•¥**ï¼š
- **GPT-3.5-turbo**ï¼šç®€å•ä»»åŠ¡å’Œå¿«é€ŸåŸå‹
- **GPT-4o**ï¼šå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬çš„é€šç”¨é€‰æ‹©
- **GPT-4.1**ï¼šå¤æ‚æ¨ç†å’Œå¤šæ­¥éª¤ç¼–æ’
- **æ¨¡å‹åˆ‡æ¢**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€é€‰æ‹©

---

## æœ¬ç« å°ç»“

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **å·¥å…·ä½¿ç”¨çš„æœ¬è´¨**
   - å·¥å…· = Python å‡½æ•°
   - LLM å†³å®šä½•æ—¶è°ƒç”¨
   - å¼€å‘è€…å®é™…æ‰§è¡Œ

2. **AI Suite æ¡†æ¶**
   - è‡ªåŠ¨ç”Ÿæˆå·¥å…·æè¿°
   - ç®€åŒ–å·¥å…·è°ƒç”¨æµç¨‹
   - æ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢

3. **ä»£ç æ‰§è¡Œå·¥å…·**
   - æå¤§æ‰©å±• LLM èƒ½åŠ›
   - å¿…é¡»ä½¿ç”¨æ²™ç›’ç¯å¢ƒ
   - E2B æ˜¯ç”Ÿäº§ç¯å¢ƒæ¨èæ–¹æ¡ˆ

4. **å®‰å…¨ç¬¬ä¸€**
   - è¾“å…¥éªŒè¯
   - æƒé™æ§åˆ¶
   - æ²™ç›’æ‰§è¡Œ
   - æ—¥å¿—è®°å½•

### å®è·µå»ºè®®

1. **ä»ç®€å•å·¥å…·å¼€å§‹**ï¼šæ—¶é—´ã€å¤©æ°”ã€è®¡ç®—å™¨
2. **é€æ­¥å¢åŠ å¤æ‚åº¦**ï¼šæ•°æ®åº“ã€APIã€ä»£ç æ‰§è¡Œ
3. **æ³¨æ„æ–‡æ¡£æ¸…æ™°**ï¼šLLM ä¾èµ– docstring ç†è§£å·¥å…·
4. **æµ‹è¯•å·¥å…·ç»„åˆ**ï¼šç¡®ä¿å¤šä¸ªå·¥å…·èƒ½ååŒå·¥ä½œ

### ä¸‹ä¸€æ­¥

- ç¬¬4ç« ï¼šå­¦ä¹ è¯„ä¼°å’Œé”™è¯¯åˆ†æ
- ç¬¬5ç« ï¼šæ„å»ºé«˜åº¦è‡ªæ²»çš„ Agent

---

## 7. å¦‚ä½•å°†å·¥å…·ä½¿ç”¨é›†æˆåˆ°å®Œæ•´ Agent

åŸºäºç¬¬1-3ç« æ‰€å­¦ï¼Œä»¥ä¸‹æ˜¯æ„å»ºå¸¦å·¥å…·ä½¿ç”¨åŠŸèƒ½çš„å®Œæ•´ Agent çš„å®è·µæŒ‡å—ï¼š

### 7.1 å·¥å…·ä½¿ç”¨æ¨¡å¼çš„é€‰æ‹©æ¡†æ¶

```python
# æ ¹æ®ä»»åŠ¡ç‰¹æ€§é€‰æ‹©å·¥å…·ä½¿ç”¨ç­–ç•¥
def select_tool_use_strategy(task_characteristics):
    """
    ä»»åŠ¡ç‰¹æ€§åŒ…æ‹¬ï¼š
    - requires_external_data: æ˜¯å¦éœ€è¦å¤–éƒ¨æ•°æ®
    - requires_computation: æ˜¯å¦éœ€è¦å¤æ‚è®¡ç®—
    - requires_automation: æ˜¯å¦éœ€è¦è‡ªåŠ¨åŒ–æ“ä½œ
    - complexity: å¤æ‚åº¦ï¼ˆ1-5ï¼‰
    """

    if task_characteristics["requires_external_data"]:
        # éœ€è¦å¤–éƒ¨æ•°æ®ï¼šAPIè°ƒç”¨å·¥å…·
        return "api_integration"

    elif task_characteristics["requires_computation"]:
        # éœ€è¦å¤æ‚è®¡ç®—ï¼šä»£ç æ‰§è¡Œå·¥å…·
        return "code_execution"

    elif task_characteristics["requires_automation"]:
        # éœ€è¦è‡ªåŠ¨åŒ–ï¼šæ“ä½œè‡ªåŠ¨åŒ–å·¥å…·
        return "automation_tools"

    elif task_characteristics["complexity"] > 3:
        # å¤æ‚ä»»åŠ¡ï¼šå·¥å…·ç»„åˆ
        return "tool_orchestration"

    else:
        # ç®€å•ä»»åŠ¡ï¼šåŸºç¡€å·¥å…·
        return "basic_tools"
```

### 7.2 å°†å·¥å…·ä½¿ç”¨é›†æˆåˆ°ç¬¬1-2ç« çš„å®¢æˆ·é‚®ä»¶ Agent

```python
# æ‰©å±•ç¬¬1-2ç« çš„å®¢æˆ·é‚®ä»¶ Agentï¼Œæ·»åŠ å·¥å…·ä½¿ç”¨åŠŸèƒ½
class ToolUsingCustomerServiceAgent:
    def __init__(self):
        self.workflow_steps = [
            "extract_info",
            "query_database",      # å·¥å…·ï¼šæ•°æ®åº“æŸ¥è¯¢
            "search_knowledge_base", # å·¥å…·ï¼šçŸ¥è¯†åº“æœç´¢
            "classify_problem",
            "generate_response",
            "reflect_on_response",  # åæ€æ¨¡å¼
            "improve_response",
            "send_email"           # å·¥å…·ï¼šé‚®ä»¶å‘é€
        ]

        # å·¥å…·é›†åˆ
        self.tools = {
            "database_query": self.query_database_tool,
            "knowledge_base_search": self.search_knowledge_base_tool,
            "email_sender": self.send_email_tool,
            "calendar_check": self.check_calendar_tool,
            "code_executor": self.execute_code_tool
        }

    def query_database_tool(self, query_type, **params):
        """
        æ•°æ®åº“æŸ¥è¯¢å·¥å…·
        """
        if query_type == "order":
            return self._query_order_database(params.get("order_id"))
        elif query_type == "customer":
            return self._query_customer_database(params.get("customer_id"))
        elif query_type == "product":
            return self._query_product_database(params.get("product_id"))
        else:
            return {"error": f"æœªçŸ¥æŸ¥è¯¢ç±»å‹: {query_type}"}

    def search_knowledge_base_tool(self, query, max_results=5):
        """
        çŸ¥è¯†åº“æœç´¢å·¥å…·
        """
        # æ¨¡æ‹ŸçŸ¥è¯†åº“æœç´¢
        knowledge_base = {
            "é€€è´§æ”¿ç­–": "7å¤©æ— ç†ç”±é€€è´§ï¼Œå•†å“éœ€ä¿æŒåŸæ ·",
            "æ¢è´§æµç¨‹": "è”ç³»å®¢æœï¼Œæä¾›è®¢å•å·å’Œé—®é¢˜ç…§ç‰‡",
            "é€€æ¬¾æ—¶é—´": "é€€æ¬¾å°†åœ¨3-5ä¸ªå·¥ä½œæ—¥å†…å¤„ç†",
            "ç‰©æµæŸ¥è¯¢": "ä½¿ç”¨è®¢å•å·åœ¨å®˜ç½‘æŸ¥è¯¢ç‰©æµçŠ¶æ€"
        }

        results = []
        for key, value in knowledge_base.items():
            if query.lower() in key.lower() or query.lower() in value.lower():
                results.append({"title": key, "content": value})

        return results[:max_results]

    def send_email_tool(self, to, subject, body, cc=None, bcc=None):
        """
        é‚®ä»¶å‘é€å·¥å…·
        """
        # å®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨é‚®ä»¶API
        email_data = {
            "to": to,
            "subject": subject,
            "body": body,
            "cc": cc or [],
            "bcc": bcc or [],
            "timestamp": datetime.now().isoformat()
        }

        # æ¨¡æ‹Ÿå‘é€
        print(f"ğŸ“§ å‘é€é‚®ä»¶åˆ°: {to}")
        print(f"ä¸»é¢˜: {subject}")
        print(f"å†…å®¹: {body[:100]}...")

        return {"success": True, "email_id": f"email_{int(time.time())}"}

    def enhanced_workflow_with_tools(self, email_text):
        """
        å¢å¼ºç‰ˆå·¥ä½œæµï¼ˆå¸¦å·¥å…·ä½¿ç”¨ï¼‰
        """
        # æ­¥éª¤1ï¼šæå–ä¿¡æ¯ï¼ˆå¯èƒ½ä½¿ç”¨å·¥å…·ï¼‰
        info = self.extract_key_info(email_text)

        # æ­¥éª¤2ï¼šæŸ¥è¯¢æ•°æ®åº“ï¼ˆå·¥å…·è°ƒç”¨ï¼‰
        order_info = self.tools["database_query"]("order", order_id=info["order_id"])
        customer_info = self.tools["database_query"]("customer", customer_id=info["customer_id"])

        # æ­¥éª¤3ï¼šæœç´¢çŸ¥è¯†åº“ï¼ˆå·¥å…·è°ƒç”¨ï¼‰
        if "é€€è´§" in email_text or "é€€æ¬¾" in email_text:
            kb_results = self.tools["knowledge_base_search"]("é€€è´§æ”¿ç­–")
            info["knowledge_base"] = kb_results

        # æ­¥éª¤4ï¼šåˆ†ç±»é—®é¢˜
        problem_type = self.classify_problem(info, order_info)

        # æ­¥éª¤5ï¼šç”Ÿæˆå›å¤
        draft = self.generate_response(info, order_info, customer_info, problem_type)

        # æ­¥éª¤6ï¼šåæ€ä¸æ”¹è¿›
        reflection = self.reflect_on_response(draft, info, problem_type)
        improved = self.improve_response(draft, reflection)

        # æ­¥éª¤7ï¼šå‘é€é‚®ä»¶ï¼ˆå·¥å…·è°ƒç”¨ï¼‰
        email_result = self.tools["email_sender"](
            to=customer_info["email"],
            subject=f"å…³äºæ‚¨çš„è®¢å• {info['order_id']}",
            body=improved
        )

        return {
            "response": improved,
            "email_sent": email_result["success"],
            "tools_used": ["database_query", "knowledge_base_search", "email_sender"]
        }
```

### 7.3 å·¥å…·é€‰æ‹©ä¸ç¼–æ’ç­–ç•¥

```python
# æ™ºèƒ½å·¥å…·é€‰æ‹©ä¸ç¼–æ’
class ToolOrchestrator:
    def __init__(self):
        self.tool_registry = {}
        self.tool_usage_stats = {}

    def register_tool(self, tool_name, tool_function, description, categories):
        """æ³¨å†Œå·¥å…·"""
        self.tool_registry[tool_name] = {
            "function": tool_function,
            "description": description,
            "categories": categories,
            "usage_count": 0
        }

    def select_tools_for_task(self, task_description, max_tools=3):
        """ä¸ºä»»åŠ¡é€‰æ‹©åˆé€‚çš„å·¥å…·"""
        # åˆ†æä»»åŠ¡éœ€æ±‚
        task_analysis = self.analyze_task_requirements(task_description)

        # æ ¹æ®ç±»åˆ«åŒ¹é…å·¥å…·
        candidate_tools = []
        for tool_name, tool_info in self.tool_registry.items():
            category_match = any(
                category in tool_info["categories"]
                for category in task_analysis["required_categories"]
            )

            if category_match:
                candidate_tools.append((tool_name, tool_info))

        # æ ¹æ®ä½¿ç”¨é¢‘ç‡å’Œç›¸å…³æ€§æ’åº
        candidate_tools.sort(
            key=lambda x: (
                self.calculate_relevance_score(x[1], task_analysis),
                -x[1]["usage_count"]  # ä¼˜å…ˆä½¿ç”¨æ¬¡æ•°å°‘çš„ï¼ˆæ¢ç´¢æ–°å·¥å…·ï¼‰
            ),
            reverse=True
        )

        return [tool[0] for tool in candidate_tools[:max_tools]]

    def orchestrate_tool_execution(self, task_description, selected_tools):
        """ç¼–æ’å·¥å…·æ‰§è¡Œé¡ºåº"""
        # åˆ†æå·¥å…·ä¾èµ–å…³ç³»
        dependency_graph = self.build_dependency_graph(selected_tools)

        # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        execution_plan = self.generate_execution_plan(dependency_graph)

        # æ‰§è¡Œå·¥å…·
        results = {}
        for step in execution_plan:
            tool_name = step["tool"]
            tool_info = self.tool_registry[tool_name]

            # å‡†å¤‡å‚æ•°
            params = self.prepare_tool_parameters(
                tool_name, task_description, results
            )

            # æ‰§è¡Œå·¥å…·
            try:
                result = tool_info["function"](**params)
                results[tool_name] = result

                # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
                tool_info["usage_count"] += 1

            except Exception as e:
                results[tool_name] = {"error": str(e)}

        return results

    def analyze_task_requirements(self, task_description):
        """åˆ†æä»»åŠ¡éœ€æ±‚"""
        # ä½¿ç”¨LLMåˆ†æä»»åŠ¡éœ€è¦å“ªäº›ç±»åˆ«çš„å·¥å…·
        analysis_prompt = f"""
        åˆ†æä»¥ä¸‹ä»»åŠ¡éœ€è¦å“ªäº›ç±»å‹çš„å·¥å…·ï¼š

        ä»»åŠ¡ï¼š{task_description}

        å·¥å…·ç±»åˆ«åŒ…æ‹¬ï¼š
        - data_query: æ•°æ®æŸ¥è¯¢
        - computation: è®¡ç®—
        - communication: é€šä¿¡
        - automation: è‡ªåŠ¨åŒ–
        - analysis: åˆ†æ
        - visualization: å¯è§†åŒ–

        è¯·è¿”å›JSONæ ¼å¼ï¼š
        {{
            "required_categories": ["category1", "category2"],
            "complexity": 1-5,
            "requires_external_data": true/false
        }}
        """

        # è°ƒç”¨LLMåˆ†æ
        analysis_result = self._call_llm(analysis_prompt)
        return json.loads(analysis_result)
```

### 7.4 å·¥å…·ä½¿ç”¨ä¸åæ€æ¨¡å¼çš„ç»“åˆ

```python
# å·¥å…·ä½¿ç”¨ + åæ€æ¨¡å¼
class ReflectiveToolUsingAgent:
    def __init__(self):
        self.tool_orchestrator = ToolOrchestrator()
        self.reflection_enabled = True

    def process_with_reflective_tools(self, task):
        """å¸¦åæ€çš„å·¥å…·ä½¿ç”¨å·¥ä½œæµ"""
        results = []

        # ç¬¬1è½®ï¼šåˆå§‹å·¥å…·é€‰æ‹©å’Œæ‰§è¡Œ
        print("ğŸ”„ ç¬¬1è½®ï¼šåˆå§‹å·¥å…·æ‰§è¡Œ...")
        round1_tools = self.tool_orchestrator.select_tools_for_task(task)
        round1_results = self.tool_orchestrator.orchestrate_tool_execution(
            task, round1_tools
        )

        results.append({
            "round": 1,
            "tools_used": round1_tools,
            "results": round1_results
        })

        if self.reflection_enabled:
            # åæ€å·¥å…·é€‰æ‹©å’Œæ‰§è¡Œæ•ˆæœ
            print("ğŸ¤” åæ€å·¥å…·ä½¿ç”¨æ•ˆæœ...")
            reflection = self.reflect_on_tool_usage(task, round1_tools, round1_results)

            # ç¬¬2è½®ï¼šåŸºäºåæ€æ”¹è¿›
            print("ğŸ”„ ç¬¬2è½®ï¼šæ”¹è¿›å·¥å…·æ‰§è¡Œ...")
            round2_tools = self.adjust_tool_selection_based_on_reflection(
                round1_tools, reflection
            )

            if round2_tools != round1_tools:
                round2_results = self.tool_orchestrator.orchestrate_tool_execution(
                    task, round2_tools
                )

                results.append({
                    "round": 2,
                    "tools_used": round2_tools,
                    "results": round2_results,
                    "reflection_used": True
                })

        # ç»¼åˆæ‰€æœ‰è½®æ¬¡çš„ç»“æœ
        final_result = self.synthesize_results(results)
        return final_result

    def reflect_on_tool_usage(self, task, tools_used, results):
        """åæ€å·¥å…·ä½¿ç”¨æ•ˆæœ"""
        reflection_prompt = f"""
        åˆ†æä»¥ä¸‹å·¥å…·ä½¿ç”¨æ•ˆæœï¼š

        ä»»åŠ¡ï¼š{task}
        ä½¿ç”¨çš„å·¥å…·ï¼š{tools_used}
        å·¥å…·ç»“æœï¼š{results}

        è¯·è¯„ä¼°ï¼š
        1. å·¥å…·é€‰æ‹©æ˜¯å¦åˆé€‚ï¼Ÿ
        2. æ˜¯å¦æœ‰æ›´å¥½çš„å·¥å…·ç»„åˆï¼Ÿ
        3. å·¥å…·æ‰§è¡Œé¡ºåºæ˜¯å¦åˆç†ï¼Ÿ
        4. ç»“æœæ˜¯å¦æ»¡è¶³ä»»åŠ¡éœ€æ±‚ï¼Ÿ

        æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
        """

        return self._call_llm(reflection_prompt)
```

### 7.5 å®Œæ•´ Agent æ¨¡æ¿ï¼šå¸¦å·¥å…·ä½¿ç”¨çš„å®¢æˆ·æœåŠ¡ç³»ç»Ÿ

```python
# tool_using_customer_agent.py
import json
from datetime import datetime
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class ToolConfig:
    """å·¥å…·é…ç½®"""
    enabled: bool = True
    max_tools_per_task: int = 3
    allow_code_execution: bool = False
    require_confirmation: bool = False  # éœ€è¦ç”¨æˆ·ç¡®è®¤çš„å·¥å…·è°ƒç”¨

class ToolUsingCustomerAgent:
    """å¸¦å·¥å…·ä½¿ç”¨åŠŸèƒ½çš„å®¢æˆ·æœåŠ¡ Agent"""

    def __init__(self, config: ToolConfig):
        self.config = config
        self.tool_registry = self._initialize_tools()
        self.execution_history = []

    def _initialize_tools(self) -> Dict[str, Dict[str, Any]]:
        """åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨"""
        tools = {
            "order_query": {
                "function": self._query_order,
                "description": "æŸ¥è¯¢è®¢å•ä¿¡æ¯",
                "categories": ["data_query"],
                "requires_params": ["order_id"]
            },
            "customer_query": {
                "function": self._query_customer,
                "description": "æŸ¥è¯¢å®¢æˆ·ä¿¡æ¯",
                "categories": ["data_query"],
                "requires_params": ["customer_id"]
            },
            "knowledge_base_search": {
                "function": self._search_knowledge_base,
                "description": "æœç´¢çŸ¥è¯†åº“",
                "categories": ["data_query", "analysis"],
                "requires_params": ["query"]
            },
            "email_sender": {
                "function": self._send_email,
                "description": "å‘é€é‚®ä»¶",
                "categories": ["communication"],
                "requires_params": ["to", "subject", "body"]
            },
            "calendar_check": {
                "function": self._check_calendar,
                "description": "æ£€æŸ¥æ—¥å†å¯ç”¨æ€§",
                "categories": ["automation"],
                "requires_params": ["date", "duration_minutes"]
            }
        }

        if self.config.allow_code_execution:
            tools["code_executor"] = {
                "function": self._execute_code,
                "description": "æ‰§è¡ŒPythonä»£ç ",
                "categories": ["computation"],
                "requires_params": ["code"],
                "requires_confirmation": True
            }

        return tools

    def process_customer_request(self, request: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¤„ç†å®¢æˆ·è¯·æ±‚ï¼ˆå¸¦å·¥å…·ä½¿ç”¨ï¼‰"""

        print(f"ğŸ“‹ å¤„ç†è¯·æ±‚: {request[:50]}...")

        # æ­¥éª¤1ï¼šåˆ†æè¯·æ±‚ï¼Œé€‰æ‹©å·¥å…·
        tool_selection = self._select_tools_for_request(request, context)

        if not tool_selection["tools"]:
            # æ— éœ€å·¥å…·ï¼Œç›´æ¥å›ç­”
            return self._generate_direct_response(request)

        # æ­¥éª¤2ï¼šæ‰§è¡Œå·¥å…·
        tool_results = {}
        tools_used = []

        for tool_name in tool_selection["tools"]:
            tool_info = self.tool_registry[tool_name]

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
            if tool_info.get("requires_confirmation", False) and self.config.require_confirmation:
                confirmed = self._request_confirmation(tool_name, request)
                if not confirmed:
                    continue

            # å‡†å¤‡å‚æ•°
            params = self._prepare_tool_parameters(
                tool_name, request, context, tool_results
            )

            # æ‰§è¡Œå·¥å…·
            print(f"  ğŸ› ï¸  æ‰§è¡Œå·¥å…·: {tool_name}")
            try:
                result = tool_info["function"](**params)
                tool_results[tool_name] = result
                tools_used.append(tool_name)

                # è®°å½•æ‰§è¡Œå†å²
                self.execution_history.append({
                    "timestamp": datetime.now().isoformat(),
                    "tool": tool_name,
                    "params": params,
                    "result": result,
                    "success": True
                })

            except Exception as e:
                error_msg = f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}"
                print(f"  âŒ {error_msg}")
                tool_results[tool_name] = {"error": error_msg}

                self.execution_history.append({
                    "timestamp": datetime.now().isoformat(),
                    "tool": tool_name,
                    "params": params,
                    "error": str(e),
                    "success": False
                })

        # æ­¥éª¤3ï¼šåŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤
        final_response = self._generate_response_based_on_tools(
            request, tool_results, context
        )

        # æ­¥éª¤4ï¼šåæ€ä¸æ”¹è¿›ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config.enabled and tools_used:
            reflection = self._reflect_on_tool_usage(
                request, tools_used, tool_results, final_response
            )

            if reflection.get("needs_improvement", False):
                improved_response = self._improve_based_on_reflection(
                    final_response, reflection
                )
                final_response = improved_response

        return {
            "response": final_response,
            "tools_used": tools_used,
            "tool_results": tool_results,
            "execution_id": f"exec_{int(datetime.now().timestamp())}"
        }

    def _select_tools_for_request(self, request: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸ºè¯·æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·"""
        # ä½¿ç”¨LLMåˆ†æè¯·æ±‚éœ€è¦å“ªäº›å·¥å…·
        analysis_prompt = f"""
        åˆ†æä»¥ä¸‹å®¢æˆ·è¯·æ±‚éœ€è¦å“ªäº›å·¥å…·ï¼š

        è¯·æ±‚ï¼š{request}
        ä¸Šä¸‹æ–‡ï¼š{context or 'æ— '}

        å¯ç”¨å·¥å…·ï¼š
        {json.dumps({k: v['description'] for k, v in self.tool_registry.items()}, indent=2, ensure_ascii=False)}

        è¯·è¿”å›JSONæ ¼å¼ï¼š
        {{
            "tools": ["tool1", "tool2"],
            "reasoning": "é€‰æ‹©è¿™äº›å·¥å…·çš„åŸå› ",
            "confidence": 0.0-1.0
        }}
        """

        try:
            analysis_result = self._call_llm(analysis_prompt)
            selection = json.loads(analysis_result)

            # é™åˆ¶å·¥å…·æ•°é‡
            selection["tools"] = selection["tools"][:self.config.max_tools_per_task]

            return selection

        except Exception as e:
            print(f"å·¥å…·é€‰æ‹©å¤±è´¥: {e}")
            return {"tools": [], "reasoning": "å·¥å…·é€‰æ‹©å¤±è´¥", "confidence": 0.0}

    def _prepare_tool_parameters(self, tool_name: str, request: str,
                                context: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡å·¥å…·å‚æ•°"""
        tool_info = self.tool_registry[tool_name]

        # ä½¿ç”¨LLMä»è¯·æ±‚å’Œä¸Šä¸‹æ–‡ä¸­æå–å‚æ•°
        param_prompt = f"""
        ä»ä»¥ä¸‹ä¿¡æ¯ä¸­æå–å·¥å…· {tool_name} æ‰€éœ€çš„å‚æ•°ï¼š

        å·¥å…·æè¿°ï¼š{tool_info['description']}
        å¿…éœ€å‚æ•°ï¼š{tool_info.get('requires_params', [])}

        å®¢æˆ·è¯·æ±‚ï¼š{request}
        ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context or 'æ— '}
        ä¹‹å‰å·¥å…·çš„ç»“æœï¼š{previous_results or 'æ— '}

        è¯·è¿”å›JSONæ ¼å¼çš„å‚æ•°å¯¹è±¡ã€‚
        """

        try:
            param_result = self._call_llm(param_prompt)
            params = json.loads(param_result)

            # éªŒè¯å¿…éœ€å‚æ•°
            required_params = tool_info.get("requires_params", [])
            missing_params = [p for p in required_params if p not in params]

            if missing_params:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_params}")

            return params

        except Exception as e:
            print(f"å‚æ•°æå–å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤å‚æ•°æˆ–æŠ›å‡ºå¼‚å¸¸
            raise

    def _generate_response_based_on_tools(self, request: str,
                                         tool_results: Dict[str, Any],
                                         context: Dict[str, Any]) -> str:
        """åŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤"""
        response_prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå›å¤ï¼š

        å®¢æˆ·è¯·æ±‚ï¼š{request}
        ä¸Šä¸‹æ–‡ï¼š{context or 'æ— '}
        å·¥å…·æ‰§è¡Œç»“æœï¼š{json.dumps(tool_results, indent=2, ensure_ascii=False)}

        è¯·ç”Ÿæˆä¸“ä¸šã€å‡†ç¡®çš„å›å¤ã€‚
        """

        return self._call_llm(response_prompt)

    def _reflect_on_tool_usage(self, request: str, tools_used: List[str],
                              tool_results: Dict[str, Any], response: str) -> Dict[str, Any]:
        """åæ€å·¥å…·ä½¿ç”¨æ•ˆæœ"""
        reflection_prompt = f"""
        åˆ†æä»¥ä¸‹å·¥å…·ä½¿ç”¨æ•ˆæœï¼š

        è¯·æ±‚ï¼š{request}
        ä½¿ç”¨çš„å·¥å…·ï¼š{tools_used}
        å·¥å…·ç»“æœï¼š{tool_results}
        ç”Ÿæˆçš„å›å¤ï¼š{response}

        è¯·è¯„ä¼°ï¼š
        1. å·¥å…·é€‰æ‹©æ˜¯å¦åˆé€‚ï¼Ÿ
        2. å·¥å…·æ‰§è¡Œæ˜¯å¦æˆåŠŸï¼Ÿ
        3. å›å¤æ˜¯å¦åŸºäºå·¥å…·ç»“æœï¼Ÿ
        4. æ˜¯å¦æœ‰æ”¹è¿›ç©ºé—´ï¼Ÿ

        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "needs_improvement": true/false,
            "issues": ["é—®é¢˜åˆ—è¡¨"],
            "suggestions": ["æ”¹è¿›å»ºè®®"],
            "alternative_tools": ["å¯èƒ½çš„æ›¿ä»£å·¥å…·"]
        }}
        """

        try:
            reflection_result = self._call_llm(reflection_prompt)
            return json.loads(reflection_result)
        except:
            return {"needs_improvement": False, "issues": [], "suggestions": []}

    # å·¥å…·å‡½æ•°å®ç°
    def _query_order(self, order_id: str) -> Dict[str, Any]:
        """æŸ¥è¯¢è®¢å•"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        orders = {
            "#8847": {
                "customer": "å¼ ä¸‰",
                "product": "æ…æ‹Œæœº",
                "status": "å·²å‘è´§",
                "price": 299
            }
        }
        return orders.get(order_id, {"error": "è®¢å•ä¸å­˜åœ¨"})

    def _query_customer(self, customer_id: str) -> Dict[str, Any]:
        """æŸ¥è¯¢å®¢æˆ·"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        customers = {
            "C001": {
                "name": "å¼ ä¸‰",
                "email": "zhangsan@example.com",
                "phone": "13800138000"
            }
        }
        return customers.get(customer_id, {"error": "å®¢æˆ·ä¸å­˜åœ¨"})

    def _search_knowledge_base(self, query: str) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†åº“"""
        kb = {
            "é€€è´§": "7å¤©æ— ç†ç”±é€€è´§",
            "é€€æ¬¾": "3-5ä¸ªå·¥ä½œæ—¥å¤„ç†",
            "ç‰©æµ": "ä½¿ç”¨è®¢å•å·æŸ¥è¯¢ç‰©æµ"
        }
        return [{"title": k, "content": v} for k, v in kb.items() if query in k]

    def _send_email(self, to: str, subject: str, body: str) -> Dict[str, Any]:
        """å‘é€é‚®ä»¶"""
        print(f"ğŸ“§ å‘é€é‚®ä»¶åˆ° {to}")
        return {"success": True, "message_id": f"msg_{int(datetime.now().timestamp())}"}

    def _check_calendar(self, date: str, duration_minutes: int) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¥å†"""
        return {"available": True, "suggested_times": ["09:00", "14:00"]}

    def _execute_code(self, code: str) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç ï¼ˆå¦‚æœå…è®¸ï¼‰"""
        if not self.config.allow_code_execution:
            return {"error": "ä»£ç æ‰§è¡Œè¢«ç¦ç”¨"}

        # å®‰å…¨æ‰§è¡Œä»£ç 
        try:
            # ä½¿ç”¨å®‰å…¨æ²™ç›’æ‰§è¡Œä»£ç 
            result = self._safe_execute_code(code)
            return {"success": True, "output": result}
        except Exception as e:
            return {"error": str(e)}

    def _safe_execute_code(self, code: str) -> str:
        """å®‰å…¨æ‰§è¡Œä»£ç """
        # å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ²™ç›’ç¯å¢ƒ
        import sys
        from io import StringIO

        old_stdout = sys.stdout
        sys.stdout = captured = StringIO()

        try:
            # é™åˆ¶å¯ç”¨çš„å†…ç½®å‡½æ•°
            safe_builtins = {
                "print": print,
                "len": len, "range": range, "str": str,
                "int": int, "float": float, "list": list,
                "dict": dict, "sum": sum, "max": max, "min": min
            }

            exec(code, {"__builtins__": safe_builtins})
            return captured.getvalue()
        finally:
            sys.stdout = old_stdout

    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # å®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨çœŸå®çš„LLM API
        return f"LLMå“åº”: {prompt[:50]}..."

    def _generate_direct_response(self, request: str) -> str:
        """ç”Ÿæˆç›´æ¥å›å¤ï¼ˆæ— éœ€å·¥å…·ï¼‰"""
        return f"ç›´æ¥å›å¤: {request}"

    def _request_confirmation(self, tool_name: str, request: str) -> bool:
        """è¯·æ±‚ç”¨æˆ·ç¡®è®¤"""
        print(f"âš ï¸  éœ€è¦ç¡®è®¤: å·¥å…· {tool_name} å°†ç”¨äºå¤„ç†è¯·æ±‚")
        # å®é™…åº”ç”¨ä¸­ä¼šæœ‰ç”¨æˆ·äº¤äº’
        return True

    def _improve_based_on_reflection(self, response: str, reflection: Dict[str, Any]) -> str:
        """åŸºäºåæ€æ”¹è¿›å›å¤"""
        improvement_prompt = f"""
        åŸå§‹å›å¤ï¼š{response}
        åæ€åé¦ˆï¼š{reflection}

        è¯·ç”Ÿæˆæ”¹è¿›åçš„å›å¤ã€‚
        """
        return self._call_llm(improvement_prompt)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®å·¥å…·ä½¿ç”¨
    config = ToolConfig(
        enabled=True,
        max_tools_per_task=3,
        allow_code_execution=False,
        require_confirmation=True
    )

    # åˆ›å»º Agent
    agent = ToolUsingCustomerAgent(config)

    # æµ‹è¯•è¯·æ±‚
    test_requests = [
        "æŸ¥è¯¢è®¢å• #8847 çš„çŠ¶æ€",
        "æˆ‘æƒ³é€€è´§ï¼Œæµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç»™å¼ ä¸‰å‘é‚®ä»¶å‘Šè¯‰ä»–è®¢å•å·²å‘è´§"
    ]

    for request in test_requests:
        print("\n" + "="*60)
        print(f"è¯·æ±‚: {request}")
        print("="*60)

        result = agent.process_customer_request(request)

        print(f"\nå›å¤: {result['response'][:100]}...")
        print(f"ä½¿ç”¨çš„å·¥å…·: {result['tools_used']}")
        print(f"æ‰§è¡ŒID: {result['execution_id']}")
```

### 7.6 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

```python
# å·¥å…·ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–
class OptimizedToolAgent:
    def __init__(self):
        self.tool_cache = {}  # å·¥å…·ç»“æœç¼“å­˜
        self.tool_timeout = 10  # å·¥å…·æ‰§è¡Œè¶…æ—¶ï¼ˆç§’ï¼‰
        self.concurrent_tools = 3  # å¹¶å‘å·¥å…·æ•°é‡

    def optimized_tool_execution(self, tools_to_execute):
        """ä¼˜åŒ–çš„å·¥å…·æ‰§è¡Œ"""
        results = {}

        # å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹å·¥å…·
        independent_tools = self._identify_independent_tools(tools_to_execute)

        for tool_group in independent_tools:
            # å¹¶è¡Œæ‰§è¡Œç»„å†…å·¥å…·
            group_results = self._execute_tools_concurrently(tool_group)
            results.update(group_results)

        return results

    def _identify_independent_tools(self, tools):
        """è¯†åˆ«å¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„å·¥å…·"""
        # åˆ†æå·¥å…·ä¾èµ–å…³ç³»
        dependency_graph = self._build_dependency_graph(tools)

        # åˆ†ç»„ï¼šæ— ä¾èµ–å…³ç³»çš„å·¥å…·å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        independent_groups = []
        remaining_tools = set(tools)

        while remaining_tools:
            # æ‰¾åˆ°å½“å‰å¯ä»¥æ‰§è¡Œçš„å·¥å…·ï¼ˆæ²¡æœ‰æœªå®Œæˆçš„å‰ç½®ä¾èµ–ï¼‰
            executable = self._find_executable_tools(
                remaining_tools, dependency_graph
            )

            if executable:
                independent_groups.append(list(executable))
                remaining_tools -= executable
            else:
                # æœ‰å¾ªç¯ä¾èµ–ï¼Œå¼ºåˆ¶é€‰æ‹©ä¸€ä¸ª
                tool = next(iter(remaining_tools))
                independent_groups.append([tool])
                remaining_tools.remove(tool)

        return independent_groups
```

### 7.7 å¿«é€Ÿé›†æˆæŒ‡å—

```python
# 4æ­¥å°†å·¥å…·ä½¿ç”¨é›†æˆåˆ°ç°æœ‰ Agent
def integrate_tool_use_4_steps(existing_agent):
    """
    æ­¥éª¤1ï¼šè¯†åˆ«éœ€è¦å·¥å…·çš„ä»»åŠ¡ç±»å‹
    æ­¥éª¤2ï¼šåˆ›å»ºæˆ–é›†æˆå·¥å…·å‡½æ•°
    æ­¥éª¤3ï¼šæ·»åŠ å·¥å…·é€‰æ‹©é€»è¾‘
    æ­¥éª¤4ï¼šä¿®æ”¹å·¥ä½œæµè°ƒç”¨å·¥å…·
    """

    # æ­¥éª¤1ï¼šåˆ†æä»»åŠ¡ç±»å‹
    task_types_needing_tools = analyze_task_types(existing_agent)

    # æ­¥éª¤2ï¼šä¸ºæ¯ç§ä»»åŠ¡ç±»å‹åˆ›å»ºå·¥å…·
    tools = create_tools_for_task_types(task_types_needing_tools)

    # æ­¥éª¤3ï¼šæ·»åŠ å·¥å…·é€‰æ‹©å™¨
    existing_agent.add_tool_selector(tools)

    # æ­¥éª¤4ï¼šä¿®æ”¹å·¥ä½œæµ
    existing_agent.modify_workflow_to_use_tools()

    return existing_agent
```

**æ­å–œä½ å®Œæˆç¬¬3ç« å­¦ä¹ ï¼** ğŸ‰

ä½ å·²ç»æŒæ¡äº†å·¥å…·ä½¿ç”¨çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œå¯ä»¥è®© LLM è°ƒç”¨å¤–éƒ¨ä¸–ç•Œäº†ã€‚

**è®°ä½**ï¼šå·¥å…·ä½¿ç”¨æå¤§æ‰©å±•äº† AI çš„èƒ½åŠ›è¾¹ç•Œï¼Œä½†å®‰å…¨æ°¸è¿œæ˜¯ç¬¬ä¸€ä¼˜å…ˆçº§ã€‚

**ç°åœ¨ä½ å¯ä»¥**ï¼š
1. å°†å·¥å…·ä½¿ç”¨æ¨¡å¼é›†æˆåˆ°ç¬¬1-2ç« æ„å»ºçš„ Agent ä¸­
2. æ ¹æ®ä»»åŠ¡ç‰¹æ€§é€‰æ‹©åˆé€‚çš„å·¥å…·ç­–ç•¥
3. ä½¿ç”¨ç¬¬7èŠ‚çš„æ¨¡æ¿æ„å»ºå¸¦å·¥å…·ä½¿ç”¨åŠŸèƒ½çš„å®Œæ•´ Agent
4. å®ç°å·¥å…·ç¼–æ’å’Œæ€§èƒ½ä¼˜åŒ–
