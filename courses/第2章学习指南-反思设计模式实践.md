# ç¬¬2ç« å­¦ä¹ æŒ‡å—ï¼šåæ€è®¾è®¡æ¨¡å¼å®è·µ

> **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡åæ€æ¨¡å¼çš„æ ¸å¿ƒåŸç†ï¼Œå­¦ä¼šå®ç°è‡ªæˆ‘æ”¹è¿›çš„ AI ç³»ç»Ÿ
>
> **å‰ç½®çŸ¥è¯†**ï¼šå®Œæˆç¬¬1ç« å­¦ä¹ ï¼Œäº†è§£åŸºç¡€çš„ Agentic å·¥ä½œæµ
>
> **é¢„è®¡æ—¶é—´**ï¼š75-100 åˆ†é’Ÿ

---

## ç›®å½•

1. [åæ€æ¨¡å¼æ˜¯ä»€ä¹ˆï¼Ÿ](#1-åæ€æ¨¡å¼æ˜¯ä»€ä¹ˆ)
2. [åŸºç¡€åæ€æ¨¡å¼å®ç°](#2-åŸºç¡€åæ€æ¨¡å¼å®ç°)
3. [è¿›é˜¶ï¼šç»“åˆå¤–éƒ¨åé¦ˆçš„åæ€](#3-è¿›é˜¶ç»“åˆå¤–éƒ¨åé¦ˆçš„åæ€)
4. [å®æˆ˜é¡¹ç›®1ï¼šæ™ºèƒ½ä»£ç å®¡æŸ¥åŠ©æ‰‹](#4-å®æˆ˜é¡¹ç›®1æ™ºèƒ½ä»£ç å®¡æŸ¥åŠ©æ‰‹)
5. [å®æˆ˜é¡¹ç›®2ï¼šæ•°æ®å¯è§†åŒ–æ”¹è¿›ç³»ç»Ÿ](#5-å®æˆ˜é¡¹ç›®2æ•°æ®å¯è§†åŒ–æ”¹è¿›ç³»ç»Ÿ)
6. [å¦‚ä½•è¯„ä¼°åæ€çš„æ•ˆæœï¼Ÿ](#6-å¦‚ä½•è¯„ä¼°åæ€çš„æ•ˆæœ)
7. [åæ€æ¨¡å¼æœ€ä½³å®è·µ](#7-åæ€æ¨¡å¼æœ€ä½³å®è·µ)

---

## 1. åæ€æ¨¡å¼æ˜¯ä»€ä¹ˆï¼Ÿ

### 1.1 æ ¸å¿ƒæ¦‚å¿µ

**åæ€æ¨¡å¼** = è®© AI æ¨¡å‹æ£€æŸ¥ã€è¯„ä¼°å¹¶æ”¹è¿›è‡ªå·±çš„è¾“å‡º

**äººç±»ç±»æ¯”**ï¼š
```
äººç±»å†™ä½œæµç¨‹ï¼š
å†™åˆç¨¿ â†’ å›å¤´è¯» â†’ å‘ç°é—®é¢˜ â†’ ä¿®æ”¹ â†’ å®šç¨¿

AI åæ€æµç¨‹ï¼š
ç”Ÿæˆåˆç¨¿ â†’ LLM å®¡æŸ¥ â†’ å‘ç°é—®é¢˜ â†’ æ”¹è¿› â†’ æœ€ç»ˆè¾“å‡º
```

### 1.2 åæ€çš„ä¸‰ä¸ªå±‚æ¬¡

| å±‚æ¬¡ | ç‰¹ç‚¹ | å¤æ‚åº¦ | æ•ˆæœ |
|------|------|--------|------|
| **åŸºç¡€åæ€** | åŒä¸€ä¸ªæ¨¡å‹è‡ªçœ | ç®€å• | é€‚åº¦æå‡ |
| **åŒæ¨¡å‹åæ€** | ä¸“é—¨æ¨¡å‹å®¡æŸ¥ | ä¸­ç­‰ | æ˜¾è‘—æå‡ |
| **å¤–éƒ¨åé¦ˆåæ€** | ç»“åˆçœŸå®æ‰§è¡Œç»“æœ | å¤æ‚ | è´¨çš„é£è·ƒ |

### 1.3 ä¸ºä»€ä¹ˆåæ€æ¯”ç›´æ¥ç”Ÿæˆå¥½ï¼Ÿ

**ç ”ç©¶æ•°æ®**ï¼šåœ¨ 7 ä¸ªä»»åŠ¡ã€4 ä¸ªæ¨¡å‹ä¸Šï¼Œåæ€æ¨¡å¼**å…¨é¢ç¢¾å‹**é›¶æ ·æœ¬ç›´æ¥ç”Ÿæˆã€‚

**åŸå› **ï¼š
1. **æ•æ‰é”™è¯¯**ï¼šåˆç¨¿å¸¸è§é”™è¯¯å¯ä»¥è¢«è¯†åˆ«å’Œä¿®æ­£
2. **æ”¹è¿›è´¨é‡**ï¼šä»"èƒ½å·¥ä½œ"åˆ°"é«˜è´¨é‡"
3. **ç¬¦åˆä¹ æƒ¯**ï¼šæ¨¡æ‹Ÿäººç±»çš„å·¥ä½œæ–¹å¼

---

## 2. åŸºç¡€åæ€æ¨¡å¼å®ç°

è®©æˆ‘ä»¬ä»æœ€ç®€å•çš„ä¾‹å­å¼€å§‹ã€‚

### 2.1 ç¯å¢ƒå‡†å¤‡

```bash
pip install openai python-dotenv
```

### 2.2 æœ€ç®€å•çš„åæ€ç¤ºä¾‹ï¼šé‚®ä»¶æ”¹è¿›

åˆ›å»ºæ–‡ä»¶ `basic_reflection.py`ï¼š

```python
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def write_email_draft(topic):
    """
    ç¬¬1æ­¥ï¼šç”Ÿæˆé‚®ä»¶åˆç¨¿
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"å†™ä¸€å°å…³äº'{topic}'çš„é‚®ä»¶"}
        ]
    )
    return response.choices[0].message.content

def reflect_on_email(draft):
    """
    ç¬¬2æ­¥ï¼šåæ€é‚®ä»¶åˆç¨¿
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‚®ä»¶å®¡æŸ¥ä¸“å®¶ã€‚"},
            {"role": "user", "content": f"""
è¯·æ£€æŸ¥ä»¥ä¸‹é‚®ä»¶åˆç¨¿ï¼ŒæŒ‡å‡ºéœ€è¦æ”¹è¿›çš„åœ°æ–¹ï¼š
1. è¯­æ°”æ˜¯å¦ä¸“ä¸šï¼Ÿ
2. æ˜¯å¦æœ‰æ‹¼å†™æˆ–è¯­æ³•é”™è¯¯ï¼Ÿ
3. ä¿¡æ¯æ˜¯å¦å®Œæ•´ï¼Ÿ
4. æ˜¯å¦æœ‰æ¨¡ç³Šä¸æ¸…çš„è¡¨è¾¾ï¼Ÿ

é‚®ä»¶è‰ç¨¿ï¼š
{draft}

è¯·åˆ—å‡ºæ‰€æœ‰é—®é¢˜å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚
            """}
        ]
    )
    return response.choices[0].message.content

def improve_email(draft, feedback):
    """
    ç¬¬3æ­¥ï¼šæ ¹æ®åé¦ˆæ”¹è¿›é‚®ä»¶
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‚®ä»¶å†™ä½œä¸“å®¶ã€‚"},
            {"role": "user", "content": f"""
åŸå§‹é‚®ä»¶ï¼š
{draft}

åé¦ˆæ„è§ï¼š
{feedback}

è¯·æ ¹æ®åé¦ˆæ„è§å†™ä¸€å°æ”¹è¿›åçš„é‚®ä»¶ã€‚
            """}
        ]
    )
    return response.choices[0].message.content

def reflection_workflow(topic):
    """
    å®Œæ•´çš„åæ€å·¥ä½œæµ
    """
    print("="*60)
    print(f"ğŸ“§ ä»»åŠ¡ï¼šå†™ä¸€å°å…³äº'{topic}'çš„é‚®ä»¶")
    print("="*60)

    # ç¬¬1æ­¥ï¼šç”Ÿæˆåˆç¨¿
    print("\nğŸ“ ç¬¬1æ­¥ï¼šç”Ÿæˆåˆç¨¿...")
    draft = write_email_draft(topic)
    print(f"åˆç¨¿å†…å®¹ï¼š\n{'-'*60}\n{draft}\n{'-'*60}")

    # ç¬¬2æ­¥ï¼šåæ€
    print("\nğŸ” ç¬¬2æ­¥ï¼šåæ€åˆç¨¿...")
    feedback = reflect_on_email(draft)
    print(f"åé¦ˆæ„è§ï¼š\n{'-'*60}\n{feedback}\n{'-'*60}")

    # ç¬¬3æ­¥ï¼šæ”¹è¿›
    print("\nâœ¨ ç¬¬3æ­¥ï¼šæ”¹è¿›é‚®ä»¶...")
    improved = improve_email(draft, feedback)
    print(f"æ”¹è¿›ç‰ˆæœ¬ï¼š\n{'-'*60}\n{improved}\n{'-'*60}")

    print("\nâœ… å®Œæˆï¼")
    return improved

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    final_email = reflection_workflow("è¯·æ±‚ä¸‹å‘¨å¼€ä¼šè®¨è®ºé¡¹ç›®è¿›åº¦")
```

### 2.3 è¿è¡Œå¹¶è§‚å¯Ÿ

```bash
python basic_reflection.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
============================================================
ğŸ“§ ä»»åŠ¡ï¼šå†™ä¸€å°å…³äº'è¯·æ±‚ä¸‹å‘¨å¼€ä¼šè®¨è®ºé¡¹ç›®è¿›åº¦'çš„é‚®ä»¶
============================================================

ğŸ“ ç¬¬1æ­¥ï¼šç”Ÿæˆåˆç¨¿...
åˆç¨¿å†…å®¹ï¼š
------------------------------------------------------------
ä¸»é¢˜ï¼šä¼šè®®

ä¸‹å‘¨å¼€ä¼šï¼Œè®¨è®ºé¡¹ç›®ã€‚

------------------------------------------------------------

ğŸ” ç¬¬2æ­¥ï¼šåæ€åˆç¨¿...
åé¦ˆæ„è§ï¼š
------------------------------------------------------------
å‘ç°ä»¥ä¸‹é—®é¢˜ï¼š
1. ä¸»é¢˜ä¸å¤Ÿå…·ä½“ï¼Œåº”è¯¥åŒ…å«ä¼šè®®ç›®çš„
2. ç¼ºå°‘å…·ä½“çš„æ—¥æœŸå’Œæ—¶é—´å»ºè®®
3. æ²¡æœ‰è¯´æ˜ä¼šè®®çš„é‡è¦æ€§
4. è¯­æ°”è¿‡äºéšæ„ï¼Œä¸å¤Ÿä¸“ä¸š
5. ç¼ºå°‘ç¤¼è²Œç”¨è¯­

æ”¹è¿›å»ºè®®ï¼š
- æ·»åŠ å…·ä½“çš„æ—¶é—´é€‰é¡¹
- è¯´æ˜ä¼šè®®è®®ç¨‹
- ä½¿ç”¨æ›´ä¸“ä¸šçš„è¯­æ°”
------------------------------------------------------------

âœ¨ ç¬¬3æ­¥ï¼šæ”¹è¿›é‚®ä»¶...
æ”¹è¿›ç‰ˆæœ¬ï¼š
------------------------------------------------------------
ä¸»é¢˜ï¼šå…³äºé¡¹ç›®è¿›åº¦è®¨è®ºä¼šè®®çš„è¯·æ±‚

æ‚¨å¥½ï¼Œ

æˆ‘å¸Œæœ›èƒ½åœ¨ä¸‹å‘¨å®‰æ’ä¸€æ¬¡ä¼šè®®ï¼Œè®¨è®ºæˆ‘ä»¬å½“å‰é¡¹ç›®çš„è¿›å±•æƒ…å†µã€‚

å»ºè®®æ—¶é—´ï¼š
- å‘¨äºŒä¸‹åˆ2ç‚¹
- å‘¨ä¸‰ä¸Šåˆ10ç‚¹
- å‘¨å››ä¸‹åˆ3ç‚¹

ä¼šè®®è®®ç¨‹ï¼š
1. å›é¡¾ä¸Šå‘¨å®Œæˆçš„å·¥ä½œ
2. è®¨è®ºå½“å‰é‡åˆ°çš„æŒ‘æˆ˜
3. è§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨

è¯·é—®å“ªä¸ªæ—¶é—´å¯¹æ‚¨æ–¹ä¾¿ï¼Ÿ

è°¢è°¢ï¼
------------------------------------------------------------

âœ… å®Œæˆï¼
```

### 2.4 ä»£ç è®²è§£

**å…³é”®è¦ç‚¹**ï¼š

1. **ä¸‰ä¸ªç‹¬ç«‹å‡½æ•°**ï¼šæ¯ä¸ªæ­¥éª¤æ¸…æ™°åˆ†ç¦»
2. **ä¿¡æ¯ä¼ é€’**ï¼šåˆç¨¿ â†’ åé¦ˆ â†’ æ”¹è¿›ç‰ˆ
3. **å¯æ‰©å±•**ï¼šå®¹æ˜“æ·»åŠ æ›´å¤šåæ€è½®æ¬¡

**æ‰©å±•ç»ƒä¹ **ï¼š
- æ·»åŠ ç¬¬4æ­¥ï¼šå†æ¬¡åæ€æ”¹è¿›ç‰ˆ
- æ·»åŠ ç¬¬5æ­¥ï¼šæœ€ç»ˆæ¶¦è‰²
- å°è¯•ä¸åŒçš„ä¸»é¢˜

---

## 3. è¿›é˜¶ï¼šç»“åˆå¤–éƒ¨åé¦ˆçš„åæ€

åŸºç¡€åæ€åªç”¨ LLM çš„"æƒ³æ³•"ï¼Œä½†**å¤–éƒ¨åé¦ˆ**èƒ½è®©åæ€è·å¾—è´¨çš„é£è·ƒã€‚

### 3.1 ä»€ä¹ˆæ˜¯å¤–éƒ¨åé¦ˆï¼Ÿ

| åé¦ˆç±»å‹ | æ¥æº | ç¤ºä¾‹ |
|---------|------|------|
| **è‡ªæˆ‘åæ€** | LLM è‡ªèº« | "æ£€æŸ¥è¿™ä¸ªä»£ç æ˜¯å¦æœ‰é”™è¯¯" |
| **å¤–éƒ¨åé¦ˆ** | çœŸå®æ‰§è¡Œç»“æœ | è¿è¡Œä»£ç  â†’ å¾—åˆ°é”™è¯¯ä¿¡æ¯ |

### 3.2 å®æˆ˜ï¼šä»£ç ç¼–å†™ + å¤–éƒ¨åé¦ˆ

åˆ›å»ºæ–‡ä»¶ `code_reflection.py`ï¼š

```python
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_code(task):
    """
    ç¬¬1æ­¥ï¼šç”Ÿæˆä»£ç 
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"""
è¯·ç¼–å†™ Python ä»£ç å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
{task}

è¦æ±‚ï¼š
- ä»£ç è¦å®Œæ•´å¯è¿è¡Œ
- åŒ…å«å¿…è¦çš„æ³¨é‡Š
- å¤„ç†å¯èƒ½çš„é”™è¯¯æƒ…å†µ
            """}
        ]
    )
    return response.choices[0].message.content

def execute_code_safely(code):
    """
    ç¬¬2æ­¥ï¼šå®‰å…¨æ‰§è¡Œä»£ç ï¼ˆæ²™ç›’ï¼‰
    è¿”å›ï¼šæ‰§è¡Œç»“æœæˆ–é”™è¯¯ä¿¡æ¯
    """
    import sys
    from io import StringIO

    # æ•è·è¾“å‡º
    old_stdout = sys.stdout
    sys.stdout = captured_output = StringIO()

    try:
        # æ‰§è¡Œä»£ç ï¼ˆæ³¨æ„ï¼šå®é™…åº”ç”¨åº”è¯¥ç”¨æ›´å®‰å…¨çš„æ²™ç›’ï¼‰
        exec(code, {'__name__': '__main__'})
        output = captured_output.getvalue()
        error = None
    except Exception as e:
        output = None
        error = str(e)
    finally:
        sys.stdout = old_stdout

    return {
        "output": output,
        "error": error
    }

def reflect_with_feedback(code, execution_result):
    """
    ç¬¬3æ­¥ï¼šåŸºäºå¤–éƒ¨åé¦ˆåæ€
    """
    # æ„å»ºåé¦ˆä¿¡æ¯
    if execution_result["error"]:
        feedback = f"""
ä»£ç æ‰§è¡Œå¤±è´¥ï¼
é”™è¯¯ä¿¡æ¯ï¼š{execution_result['error']}

è¯·åˆ†æé”™è¯¯åŸå› å¹¶ç”Ÿæˆä¿®æ­£åçš„ä»£ç ã€‚
        """
    else:
        feedback = f"""
ä»£ç æ‰§è¡ŒæˆåŠŸï¼
è¾“å‡ºç»“æœï¼š{execution_result['output']}

è¯·æ£€æŸ¥è¾“å‡ºæ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœç»“æœä¸ç¬¦åˆé¢„æœŸï¼Œè¯·æ”¹è¿›ä»£ç ã€‚
        """

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"""
åŸå§‹ä»£ç ï¼š
{code}

{feedback}

è¯·æä¾›ä¿®æ­£åçš„ä»£ç ã€‚
            """}
        ]
    )
    return response.choices[0].message.content

def coding_reflection_workflow(task, max_iterations=3):
    """
    å®Œæ•´çš„ä»£ç åæ€å·¥ä½œæµ
    """
    print("="*60)
    print(f"ğŸ’» ä»»åŠ¡ï¼š{task}")
    print("="*60)

    code = None
    for iteration in range(1, max_iterations + 1):
        print(f"\nğŸ”„ ç¬¬{iteration}è½®è¿­ä»£ï¼š")

        if code is None:
            # ç¬¬1è½®ï¼šç”Ÿæˆä»£ç 
            print("  ğŸ“ ç”Ÿæˆä»£ç ...")
            code = generate_code(task)
        else:
            # åç»­è½®ï¼šåŸºäºåé¦ˆæ”¹è¿›
            print("  ğŸ” æ‰§è¡Œä»£ç ...")
            execution_result = execute_code_safely(code)

            if execution_result["error"]:
                print(f"  âŒ æ‰§è¡Œå¤±è´¥ï¼š{execution_result['error'][:100]}...")
            else:
                print(f"  âœ… æ‰§è¡ŒæˆåŠŸï¼š{execution_result['output'][:100]}...")
                # å¦‚æœæˆåŠŸï¼Œå¯ä»¥é€‰æ‹©ç»§ç»­æˆ–ç»“æŸ
                break

            print("  ğŸ› ï¸  æ”¹è¿›ä»£ç ...")
            code = reflect_with_feedback(code, execution_result)

        # æ˜¾ç¤ºå½“å‰ä»£ç ï¼ˆå‰200å­—ç¬¦ï¼‰
        print(f"  ğŸ“„ ä»£ç é¢„è§ˆï¼š{code[:200]}...")

    print("\n" + "="*60)
    print("æœ€ç»ˆä»£ç ï¼š")
    print("="*60)
    print(code)
    print("="*60)

    return code

# æµ‹è¯•ä»»åŠ¡
test_tasks = [
    "è®¡ç®—1åˆ°100ä¹‹é—´æ‰€æœ‰å¶æ•°çš„å’Œ",
    "ç¼–å†™ä¸€ä¸ªå‡½æ•°åˆ¤æ–­ä¸€ä¸ªæ•°å­—æ˜¯å¦ä¸ºè´¨æ•°",
    "è¯»å–ç”¨æˆ·è¾“å…¥çš„åå­—å¹¶æ‰“å°é—®å€™è¯­"
]

if __name__ == "__main__":
    # é€‰æ‹©ä¸€ä¸ªä»»åŠ¡è¿è¡Œ
    task = test_tasks[0]
    final_code = coding_reflection_workflow(task)
```

### 3.3 è¿è¡Œå¹¶è§‚å¯Ÿ

```bash
python code_reflection.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
============================================================
ğŸ’» ä»»åŠ¡ï¼šè®¡ç®—1åˆ°100ä¹‹é—´æ‰€æœ‰å¶æ•°çš„å’Œ
============================================================

ğŸ”„ ç¬¬1è½®è¿­ä»£ï¼š
  ğŸ“ ç”Ÿæˆä»£ç ...
  ğŸ“„ ä»£ç é¢„è§ˆï¼š```python
# è®¡ç®—1åˆ°100ä¹‹é—´æ‰€æœ‰å¶æ•°çš„å’Œ

total = 0
for i in range(1, 101):
    if i % 2 == 0:
        total += i
print(total)
```

ğŸ”„ ç¬¬2è½®è¿­ä»£ï¼š
  ğŸ” æ‰§è¡Œä»£ç ...
  âœ… æ‰§è¡ŒæˆåŠŸï¼š2550

============================================================
æœ€ç»ˆä»£ç ï¼š
============================================================
```python
# è®¡ç®—1åˆ°100ä¹‹é—´æ‰€æœ‰å¶æ•°çš„å’Œ

total = 0
for i in range(1, 101):
    if i % 2 == 0:
        total += i
print(total)
```
============================================================
```

### 3.4 ä»£ç è®²è§£

**å…³é”®è¦ç‚¹**ï¼š

1. **å¤–éƒ¨åé¦ˆæ¥æº**ï¼šçœŸå®æ‰§è¡Œä»£ç çš„é”™è¯¯ä¿¡æ¯
2. **è¿­ä»£æ”¹è¿›**ï¼šæœ€å¤šå°è¯•3æ¬¡ï¼Œç›´åˆ°æˆåŠŸ
3. **å®‰å…¨æ‰§è¡Œ**ï¼šç”¨ `StringIO` æ•è·è¾“å‡ºï¼ˆå®é™…åº”ç”¨åº”è¯¥ç”¨æ²™ç›’ï¼‰

**å®‰å…¨è­¦å‘Š**ï¼š
- âš ï¸ ç”Ÿäº§ç¯å¢ƒå¿…é¡»ä½¿ç”¨æ²™ç›’ï¼ˆDockerã€E2Bï¼‰
- âš ï¸ ä¸è¦ç›´æ¥æ‰§è¡Œä¸å¯ä¿¡çš„ä»£ç 
- âš ï¸ é™åˆ¶æ‰§è¡Œæ—¶é—´å’Œèµ„æº

---

## 4. å®æˆ˜é¡¹ç›®1ï¼šæ™ºèƒ½ä»£ç å®¡æŸ¥åŠ©æ‰‹

è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå®ç”¨çš„ä»£ç å®¡æŸ¥å·¥å…·ã€‚

### 4.1 é¡¹ç›®ç»“æ„

```
code_reviewer/
â”œâ”€â”€ config.py          # é…ç½®
â”œâ”€â”€ reviewer.py        # æ ¸å¿ƒå®¡æŸ¥é€»è¾‘
â”œâ”€â”€ evaluator.py       # è¯„ä¼°å·¥å…·
â””â”€â”€ main.py           # å…¥å£
```

### 4.2 å®Œæ•´å®ç°

#### config.py

```python
# config.py
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = "gpt-3.5-turbo"

# å®¡æŸ¥æ ‡å‡†
REVIEW_STANDARDS = {
    "readability": "ä»£ç æ˜¯å¦æ˜“äºé˜…è¯»å’Œç†è§£",
    "correctness": "ä»£ç é€»è¾‘æ˜¯å¦æ­£ç¡®",
    "efficiency": "ä»£ç æ•ˆç‡æ˜¯å¦åˆç†",
    "security": "æ˜¯å¦å­˜åœ¨å®‰å…¨éšæ‚£",
    "style": "ä»£ç é£æ ¼æ˜¯å¦ä¸€è‡´"
}
```

#### reviewer.py

```python
# reviewer.py
from openai import OpenAI
from config import OPENAI_API_KEY, MODEL, REVIEW_STANDARDS

client = OpenAI(api_key=OPENAI_API_KEY)

class CodeReviewer:
    def __init__(self):
        self.client = client

    def review_code(self, code, language="python"):
        """
        å®¡æŸ¥ä»£ç å¹¶ç”ŸæˆæŠ¥å‘Š
        """
        # ç¬¬1æ­¥ï¼šç”Ÿæˆåˆç¨¿å®¡æŸ¥
        print("ğŸ” ç¬¬1æ­¥ï¼šåˆæ­¥å®¡æŸ¥...")
        initial_review = self._generate_review(code, language)

        # ç¬¬2æ­¥ï¼šåæ€å®¡æŸ¥è´¨é‡
        print("ğŸ¤” ç¬¬2æ­¥ï¼šåæ€å®¡æŸ¥è´¨é‡...")
        reflection = self._reflect_on_review(initial_review, code)

        # ç¬¬3æ­¥ï¼šæ”¹è¿›å®¡æŸ¥
        print("âœ¨ ç¬¬3æ­¥ï¼šæ”¹è¿›å®¡æŸ¥...")
        final_review = self._improve_review(initial_review, reflection)

        return final_review

    def _generate_review(self, code, language):
        """
        ç”Ÿæˆåˆæ­¥å®¡æŸ¥æ„è§
        """
        standards_text = "\n".join([
            f"- {k}: {v}" for k, v in REVIEW_STANDARDS.items()
        ])

        response = self.client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚"},
                {"role": "user", "content": f"""
è¯·å®¡æŸ¥ä»¥ä¸‹ {language} ä»£ç ï¼š

å®¡æŸ¥æ ‡å‡†ï¼š
{standards_text}

ä»£ç ï¼š
```{language}
{code}
```

è¯·æä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ï¼ŒåŒ…æ‹¬ï¼š
1. æ•´ä½“è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
2. å‘ç°çš„é—®é¢˜ï¼ˆæŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼‰
3. æ”¹è¿›å»ºè®®
4. æ­£é¢åé¦ˆï¼ˆåšå¾—å¥½çš„åœ°æ–¹ï¼‰
                """}
            ]
        )
        return response.choices[0].message.content

    def _reflect_on_review(self, review, original_code):
        """
        åæ€å®¡æŸ¥çš„è´¨é‡
        """
        response = self.client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå®¡æŸ¥è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚"},
                {"role": "user", "content": f"""
è¯·è¯„ä¼°ä»¥ä¸‹ä»£ç å®¡æŸ¥çš„è´¨é‡ï¼š

åŸå§‹ä»£ç ï¼š
```python
{original_code}
```

å®¡æŸ¥æ„è§ï¼š
{review}

è¯·è¯„ä¼°ï¼š
1. å®¡æŸ¥æ˜¯å¦å…¨é¢ï¼Ÿ
2. å»ºè®®æ˜¯å¦å…·ä½“å¯è¡Œï¼Ÿ
3. æ˜¯å¦é—æ¼äº†é‡è¦é—®é¢˜ï¼Ÿ
4. è¯„åˆ†æ˜¯å¦åˆç†ï¼Ÿ

è¯·æä¾›æ”¹è¿›å»ºè®®ã€‚
                """}
            ]
        )
        return response.choices[0].message.content

    def _improve_review(self, initial_review, reflection):
        """
        æ ¹æ®åæ€æ”¹è¿›å®¡æŸ¥
        """
        response = self.client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚"},
                {"role": "user", "content": f"""
åŸå§‹å®¡æŸ¥ï¼š
{initial_review}

è‡ªæˆ‘åæ€ï¼š
{reflection}

è¯·æ ¹æ®åæ€æ„è§ï¼Œç”Ÿæˆä¸€ä¸ªæ”¹è¿›åçš„ã€æ›´å…¨é¢çš„ä»£ç å®¡æŸ¥æŠ¥å‘Šã€‚
                """}
            ]
        )
        return response.choices[0].message.content
```

#### evaluator.py

```python
# evaluator.py

def evaluate_review_quality(review):
    """
    è¯„ä¼°å®¡æŸ¥æŠ¥å‘Šçš„è´¨é‡
    """
    # æ£€æŸ¥å¿…è¦å…ƒç´ 
    has_score = any(char.isdigit() for char in review[:200])
    has_issues = "é—®é¢˜" in review or "issue" in review.lower()
    has_suggestions = "å»ºè®®" in review or "suggest" in review.lower()
    has_positive = "å¥½" in review or "excellent" in review.lower()

    # è®¡ç®—å®Œæ•´æ€§å¾—åˆ†
    completeness = sum([
        has_score,
        has_issues,
        has_suggestions,
        has_positive
    ]) / 4

    # æ£€æŸ¥é•¿åº¦ï¼ˆå¤ªçŸ­è¯´æ˜ä¸å¤Ÿè¯¦ç»†ï¼‰
    length_score = min(len(review) / 500, 1.0)

    # ç»¼åˆå¾—åˆ†
    overall_score = (completeness * 0.7 + length_score * 0.3)

    return {
        "completeness": completeness,
        "length_score": length_score,
        "overall_score": overall_score,
        "details": {
            "has_score": has_score,
            "has_issues": has_issues,
            "has_suggestions": has_suggestions,
            "has_positive": has_positive
        }
    }
```

#### main.py

```python
# main.py
from reviewer import CodeReviewer

# æµ‹è¯•ä»£ç 
test_code = """
def calculate_sum(numbers):
    result = 0
    for num in numbers:
        result = result + num
    return result

data = [1, 2, 3, 4, 5]
print(calculate_sum(data))
"""

def main():
    print("="*60)
    print("ğŸ” æ™ºèƒ½ä»£ç å®¡æŸ¥åŠ©æ‰‹")
    print("="*60)

    # åˆ›å»ºå®¡æŸ¥å™¨
    reviewer = CodeReviewer()

    # æ‰§è¡Œå®¡æŸ¥
    review = reviewer.review_code(test_code)

    # æ˜¾ç¤ºç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š å®¡æŸ¥æŠ¥å‘Š")
    print("="*60)
    print(review)

    # è¯„ä¼°è´¨é‡
    from evaluator import evaluate_review_quality
    score = evaluate_review_quality(review)

    print("\n" + "="*60)
    print("ğŸ“ˆ å®¡æŸ¥è´¨é‡è¯„åˆ†")
    print("="*60)
    print(f"å®Œæ•´æ€§ï¼š{score['completeness']:.2%}")
    print(f"é•¿åº¦å¾—åˆ†ï¼š{score['length_score']:.2%}")
    print(f"ç»¼åˆå¾—åˆ†ï¼š{score['overall_score']:.2%}")

if __name__ == "__main__":
    main()
```

### 4.3 è¿è¡Œé¡¹ç›®

```bash
python main.py
```

---

## 5. å®æˆ˜é¡¹ç›®2ï¼šæ•°æ®å¯è§†åŒ–æ”¹è¿›ç³»ç»Ÿ

è¿™ä¸ªé¡¹ç›®å±•ç¤ºå¦‚ä½•ç”¨**å¤šæ¨¡æ€åæ€**æ”¹è¿›å›¾è¡¨ç”Ÿæˆã€‚

### 5.1 é¡¹ç›®æ¦‚è¿°

**ä»»åŠ¡**ï¼šæ ¹æ®æ•°æ®ç”Ÿæˆå›¾è¡¨ï¼Œç„¶åè®© LLM"çœ‹"å›¾å¹¶æ”¹è¿›ã€‚

### 5.2 å®Œæ•´å®ç°

åˆ›å»ºæ–‡ä»¶ `chart_reflection.py`ï¼š

```python
import os
import matplotlib.pyplot as plt
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_chart_code(data_description):
    """
    ç¬¬1æ­¥ï¼šç”Ÿæˆå›¾è¡¨ä»£ç 
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"""
è¯·ç¼–å†™ Python ä»£ç åˆ›å»ºå›¾è¡¨ï¼š{data_description}

è¦æ±‚ï¼š
- ä½¿ç”¨ matplotlib
- ä»£ç å®Œæ•´å¯è¿è¡Œ
- åŒ…å«æ ‡é¢˜å’Œæ ‡ç­¾
            """}
        ]
    )
    return response.choices[0].message.content

def execute_chart_code(code):
    """
    ç¬¬2æ­¥ï¼šæ‰§è¡Œä»£ç ç”Ÿæˆå›¾è¡¨
    """
    try:
        exec(code, {'plt': plt, '__name__': '__main__'})
        plt.savefig('chart_v1.png')
        plt.close()
        return {'success': True, 'error': None}
    except Exception as e:
        return {'success': False, 'error': str(e)}

def reflect_on_chart(image_path, original_code):
    """
    ç¬¬3æ­¥ï¼šåæ€å›¾è¡¨è´¨é‡ï¼ˆå¤šæ¨¡æ€ï¼‰
    """
    import base64

    # è¯»å–å›¾ç‰‡
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o",  # ä½¿ç”¨æ”¯æŒè§†è§‰çš„æ¨¡å‹
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·è¯„ä¼°è¿™å¼ å›¾è¡¨çš„è´¨é‡ï¼ŒåŒ…æ‹¬ï¼š1. å¯è¯»æ€§ 2. æ¸…æ™°åº¦ 3. å®Œæ•´æ€§ 4. æ˜¯å¦æœ‰æ”¹è¿›ç©ºé—´"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_data}"
                        }
                    }
                ]
            }
        ]
    )
    return response.choices[0].message.content

def improve_chart_code(original_code, reflection):
    """
    ç¬¬4æ­¥ï¼šæ”¹è¿›å›¾è¡¨ä»£ç 
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"""
åŸå§‹ä»£ç ï¼š
{original_code}

å›¾è¡¨è¯„ä¼°åé¦ˆï¼š
{reflection}

è¯·æ ¹æ®åé¦ˆç”Ÿæˆæ”¹è¿›åçš„å›¾è¡¨ä»£ç ã€‚
            """}
        ]
    )
    return response.choices[0].message.content

def chart_reflection_workflow(data_description):
    """
    å®Œæ•´çš„å›¾è¡¨åæ€å·¥ä½œæµ
    """
    print("="*60)
    print(f"ğŸ“Š ä»»åŠ¡ï¼š{data_description}")
    print("="*60)

    # ç¬¬1æ­¥ï¼šç”Ÿæˆä»£ç 
    print("\nğŸ“ ç¬¬1æ­¥ï¼šç”Ÿæˆå›¾è¡¨ä»£ç ...")
    code_v1 = generate_chart_code(data_description)
    print(f"ä»£ç ï¼š\n{code_v1}")

    # ç¬¬2æ­¥ï¼šæ‰§è¡Œä»£ç 
    print("\nğŸ¨ ç¬¬2æ­¥ï¼šç”Ÿæˆå›¾è¡¨...")
    result = execute_chart_code(code_v1)
    if not result['success']:
        print(f"âŒ é”™è¯¯ï¼š{result['error']}")
        return None

    # ç¬¬3æ­¥ï¼šåæ€å›¾è¡¨
    print("\nğŸ” ç¬¬3æ­¥ï¼šè¯„ä¼°å›¾è¡¨è´¨é‡...")
    reflection = reflect_on_chart('chart_v1.png', code_v1)
    print(f"è¯„ä¼°ç»“æœï¼š\n{reflection}")

    # ç¬¬4æ­¥ï¼šæ”¹è¿›ä»£ç 
    print("\nâœ¨ ç¬¬4æ­¥ï¼šæ”¹è¿›å›¾è¡¨...")
    code_v2 = improve_chart_code(code_v1, reflection)
    print(f"æ”¹è¿›ä»£ç ï¼š\n{code_v2}")

    # ç¬¬5æ­¥ï¼šç”Ÿæˆæ”¹è¿›å›¾è¡¨
    print("\nğŸ¨ ç¬¬5æ­¥ï¼šç”Ÿæˆæ”¹è¿›å›¾è¡¨...")
    result = execute_chart_code(code_v2)
    if result['success']:
        print("âœ… å›¾è¡¨å·²ä¿å­˜ä¸º chart_v2.png")

    return code_v2

# æµ‹è¯•
if __name__ == "__main__":
    task = "åˆ›å»ºä¸€ä¸ªå¯¹æ¯”2024å¹´å’Œ2025å¹´Q1å’–å•¡é”€é‡çš„æŸ±çŠ¶å›¾"
    final_code = chart_reflection_workflow(task)
```

### 5.3 æ³¨æ„äº‹é¡¹

**å¤šæ¨¡æ€åæ€éœ€è¦**ï¼š
- æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼ˆå¦‚ GPT-4oï¼‰
- å›¾ç‰‡è½¬ base64 ç¼–ç 
- æ›´å¤šçš„ API è°ƒç”¨æˆæœ¬

---

## 6. å¦‚ä½•è¯„ä¼°åæ€çš„æ•ˆæœï¼Ÿ

### 6.1 å®¢è§‚ä»»åŠ¡è¯„ä¼°

å¯¹äºæœ‰æ˜ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ï¼ˆå¦‚ä»£ç æ‰§è¡Œï¼‰ï¼š

```python
def evaluate_code_reflection():
    """
    è¯„ä¼°ä»£ç åæ€çš„æ•ˆæœ
    """
    test_cases = [
        {"task": "è®¡ç®—1+1", "expected_output": "2"},
        {"task": "åè½¬å­—ç¬¦ä¸²'hello'", "expected_output": "olleh"},
    ]

    results = {
        "without_reflection": [],
        "with_reflection": []
    }

    for case in test_cases:
        # æ— åæ€
        code = generate_code(case["task"])
        result = execute_code_safely(code)
        results["without_reflection"].append(
            result["output"] == case["expected_output"]
        )

        # æœ‰åæ€
        code = reflection_workflow(case["task"])
        result = execute_code_safely(code)
        results["with_reflection"].append(
            result["output"] == case["expected_output"]
        )

    # è®¡ç®—å‡†ç¡®ç‡
    acc_without = sum(results["without_reflection"]) / len(test_cases)
    acc_with = sum(results["with_reflection"]) / len(test_cases)

    print(f"æ— åæ€å‡†ç¡®ç‡ï¼š{acc_without:.2%}")
    print(f"æœ‰åæ€å‡†ç¡®ç‡ï¼š{acc_with:.2%}")
    print(f"æå‡å¹…åº¦ï¼š{(acc_with - acc_without):.2%}")
```

### 6.2 ä¸»è§‚ä»»åŠ¡è¯„ä¼°

å¯¹äºæ²¡æœ‰æ˜ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ï¼ˆå¦‚å›¾è¡¨ç¾è§‚åº¦ï¼‰ï¼š

```python
def evaluate_chart_quality():
    """
    ä½¿ç”¨è¯„åˆ†é‡è¡¨è¯„ä¼°å›¾è¡¨
    """
    rubric = """
    è¯·å¯¹å›¾è¡¨è¿›è¡Œ1-5åˆ†è¯„åˆ†ï¼š
    1. æ˜¯å¦æœ‰æ¸…æ™°çš„æ ‡é¢˜ï¼Ÿ
    2. åæ ‡è½´æ˜¯å¦æœ‰æ ‡ç­¾ï¼Ÿ
    3. å›¾è¡¨ç±»å‹æ˜¯å¦åˆé€‚ï¼Ÿ
    4. æ•°å€¼èŒƒå›´æ˜¯å¦æ°å½“ï¼Ÿ
    5. æ•´ä½“ç¾è§‚åº¦ï¼Ÿ
    """

    # å¯¹æ¯”æœ‰åæ€å’Œæ— åæ€çš„å›¾è¡¨
    score_v1 = llm_judge("chart_v1.png", rubric)
    score_v2 = llm_judge("chart_v2.png", rubric)

    print(f"åæ€å‰å¾—åˆ†ï¼š{score_v1}")
    print(f"åæ€åå¾—åˆ†ï¼š{score_v2}")
    print(f"æå‡ï¼š{score_v2 - score_v1}")
```

---

## 7. åæ€æ¨¡å¼æœ€ä½³å®è·µ

### 7.1 ç¼–å†™åæ€æç¤ºçš„é»„é‡‘æ³•åˆ™

**æ³•åˆ™1ï¼šæ˜ç¡®æŒ‡ç¤ºåæ€åŠ¨ä½œ**

âŒ ä¸å¥½ï¼š
```
è¯·æ”¹è¿›è¿™æ®µä»£ç 
```

âœ… å¥½ï¼š
```
è¯·å®¡æŸ¥è¿™æ®µä»£ç ï¼Œæ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š
1. æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯ï¼Ÿ
2. é€»è¾‘æ˜¯å¦æ­£ç¡®ï¼Ÿ
3. æ˜¯å¦æœ‰æ›´é«˜æ•ˆçš„å†™æ³•ï¼Ÿ
```

**æ³•åˆ™2ï¼šå…·ä½“æŒ‡å®šæ£€æŸ¥æ ‡å‡†**

âŒ ä¸å¥½ï¼š
```
è®©è¿™å°é‚®ä»¶æ›´å¥½
```

âœ… å¥½ï¼š
```
è¯·æ£€æŸ¥é‚®ä»¶ï¼š
1. æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Ÿ
2. è¯­æ°”æ˜¯å¦ä¸“ä¸šç¤¼è²Œï¼Ÿ
3. æ˜¯å¦æœ‰æ‹¼å†™é”™è¯¯ï¼Ÿ
4. å­—æ•°æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…ï¼Ÿ
```

### 7.2 ä½•æ—¶ä½¿ç”¨åæ€ï¼Ÿ

| ä»»åŠ¡ç±»å‹ | åæ€æ•ˆæœ | æ¨èåº¦ |
|---------|---------|--------|
| ä»£ç ç¼–å†™ | â­â­â­â­â­ | å¼ºçƒˆæ¨è |
| æ–‡ç« å†™ä½œ | â­â­â­â­ | æ¨è |
| é‚®ä»¶æ’°å†™ | â­â­â­â­ | æ¨è |
| æ•°æ®åˆ†æ | â­â­â­â­ | æ¨è |
| ç¿»è¯‘ä»»åŠ¡ | â­â­â­ | å¯é€‰ |
| ç®€å•é—®ç­” | â­â­ | ä¸æ¨è |

### 7.3 åæ€çš„ä»£ä»·

| ç»´åº¦ | ä»£ä»· | æ˜¯å¦å€¼å¾— |
|------|------|---------|
| æ—¶é—´ | 2-3å€å»¶è¿Ÿ | âœ… è´¨é‡æå‡å€¼å¾— |
| æˆæœ¬ | 2-3å€ API è°ƒç”¨ | âœ… æ€§èƒ½æå‡å€¼å¾— |
| å¤æ‚åº¦ | éœ€è¦æ›´å¤šä»£ç  | âš ï¸ ç®€å•ä»»åŠ¡å¯ä¸åŠ  |

### 7.4 åæ€æœºåˆ¶çš„å…·ä½“ä»£ç å®ç°

**å†…éƒ¨åæ€å¾ªç¯å®ç°**ï¼š

```python
def reflection_loop(initial_output, max_iterations=3):
    """å†…éƒ¨åæ€æœºåˆ¶çš„å®ç°"""
    current_output = initial_output

    for i in range(max_iterations):
        # ç”Ÿæˆåæ€æç¤º
        reflection_prompt = f"""
        è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹è¾“å‡ºï¼Œæ‰¾å‡ºå…¶ä¸­çš„é—®é¢˜å¹¶æå‡ºæ”¹è¿›å»ºè®®ï¼š
        {current_output}

        å…³æ³¨ç‚¹ï¼š
        1. äº‹å®å‡†ç¡®æ€§
        2. é€»è¾‘ä¸€è‡´æ€§
        3. å®Œæ•´æ€§
        4. è¡¨è¾¾æ¸…æ™°åº¦

        è¯·æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
        """

        # è·å–åæ€åé¦ˆ
        reflection_feedback = llm_call(reflection_prompt)

        # åŸºäºåé¦ˆæ”¹è¿›è¾“å‡º
        improvement_prompt = f"""
        åŸºäºä»¥ä¸‹åæ€åé¦ˆï¼Œè¯·æ”¹è¿›åŸå§‹è¾“å‡ºï¼š

        åŸå§‹è¾“å‡ºï¼š{current_output}
        åæ€åé¦ˆï¼š{reflection_feedback}

        è¯·æä¾›æ”¹è¿›åçš„ç‰ˆæœ¬ã€‚
        """

        improved_output = llm_call(improvement_prompt)

        # æ£€æŸ¥æ˜¯å¦æ”¶æ•›ï¼ˆè¾“å‡ºä¸å†æ˜¾è‘—æ”¹å–„ï¼‰
        if calculate_similarity(current_output, improved_output) > 0.95:
            break

        current_output = improved_output

    return current_output
```

**å›¾è¡¨ç”Ÿæˆåæ€å·¥ä½œæµ**ï¼š

```python
class ChartGenerationWorkflow:
    def __init__(self):
        self.tools = {
            'data_analysis': self.analyze_data,
            'chart_generation': self.generate_chart,
            'quality_check': self.check_chart_quality
        }

    def generate_improved_chart(self, data, requirements):
        """å¸¦åæ€çš„å›¾è¡¨ç”Ÿæˆå·¥ä½œæµ"""

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆåˆå§‹å›¾è¡¨
        initial_chart = self.generate_chart(data, requirements)

        # ç¬¬äºŒæ­¥ï¼šè´¨é‡æ£€æŸ¥ä¸åæ€
        quality_feedback = self.reflect_on_chart(initial_chart, requirements)

        # ç¬¬ä¸‰æ­¥ï¼šåŸºäºåæ€æ”¹è¿›
        if quality_feedback['needs_improvement']:
            improved_chart = self.improve_chart(initial_chart, quality_feedback)
            return improved_chart

        return initial_chart

    def reflect_on_chart(self, chart, requirements):
        """å¯¹ç”Ÿæˆçš„å›¾è¡¨è¿›è¡Œåæ€è¯„ä¼°"""
        reflection_prompt = f"""
        ä½œä¸ºæ•°æ®å¯è§†åŒ–ä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å›¾è¡¨ï¼š

        å›¾è¡¨ä»£ç ï¼š{chart}
        éœ€æ±‚ï¼š{requirements}

        è¯·æ£€æŸ¥ï¼š
        1. å›¾è¡¨ç±»å‹æ˜¯å¦é€‚åˆæ•°æ®ç±»å‹
        2. é¢œè‰²ä½¿ç”¨æ˜¯å¦åˆç†
        3. æ ‡ç­¾å’Œæ ‡é¢˜æ˜¯å¦æ¸…æ™°
        4. æ˜¯å¦æœ‰æ•ˆä¼ è¾¾æ•°æ®æ´å¯Ÿ
        5. ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§

        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "needs_improvement": boolean,
            "issues": ["é—®é¢˜åˆ—è¡¨"],
            "suggestions": ["æ”¹è¿›å»ºè®®"]
        }}
        """

        return json.loads(llm_call(reflection_prompt))
```

### 7.5 SQLç”Ÿæˆæ”¹è¿›å®éªŒé…ç½®

**å®éªŒé…ç½®æ–‡ä»¶**ï¼š

```python
# config.py
DATABASE_SCHEMA = {
    'tables': {
        'customers': {
            'columns': ['customer_id', 'name', 'email', 'registration_date'],
            'relationships': ['orders']
        },
        'orders': {
            'columns': ['order_id', 'customer_id', 'product_id', 'order_date', 'quantity'],
            'relationships': ['customers', 'products']
        },
        'products': {
            'columns': ['product_id', 'name', 'category', 'price'],
            'relationships': ['orders']
        }
    }
}

TEST_QUERIES = [
    {
        "natural_language": "æ‰¾å‡ºè´­ä¹°äº†ç”µå­äº§å“çš„æ‰€æœ‰å®¢æˆ·",
        "expected_sql": "SELECT DISTINCT c.* FROM customers c JOIN orders o ON c.customer_id = o.customer_id JOIN products p ON o.product_id = p.product_id WHERE p.category = 'ç”µå­äº§å“'",
        "difficulty": "medium"
    },
    {
        "natural_language": "è®¡ç®—æ¯ä¸ªäº§å“ç±»åˆ«çš„æ€»é”€å”®é¢",
        "expected_sql": "SELECT p.category, SUM(p.price * o.quantity) as total_sales FROM products p JOIN orders o ON p.product_id = o.product_id GROUP BY p.category",
        "difficulty": "hard"
    }
]
```

**SQLåæ€æ”¹è¿›å·¥ä½œæµ**ï¼š

```python
class SQLReflectionWorkflow:
    def __init__(self):
        self.database_connection = DatabaseConnection()

    def generate_sql_with_reflection(self, natural_language_query):
        """å¸¦åæ€çš„SQLç”Ÿæˆå·¥ä½œæµ"""

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆåˆå§‹SQL
        initial_sql = self.generate_sql(natural_language_query)

        # ç¬¬äºŒæ­¥ï¼šSQLè¯­æ³•å’Œé€»è¾‘æ£€æŸ¥
        syntax_check = self.check_sql_syntax(initial_sql)
        logical_check = self.check_query_logic(initial_sql, natural_language_query)

        # ç¬¬ä¸‰æ­¥ï¼šåæ€ä¸æ”¹è¿›
        if syntax_check['has_issues'] or logical_check['has_issues']:
            reflection_feedback = {
                'syntax_issues': syntax_check['issues'],
                'logical_issues': logical_check['issues'],
                'original_intent': natural_language_query
            }

            improved_sql = self.improve_sql(initial_sql, reflection_feedback)
            return improved_sql

        return initial_sql

    def check_query_logic(self, sql_query, original_intent):
        """æ£€æŸ¥SQLæŸ¥è¯¢é€»è¾‘æ˜¯å¦ç¬¦åˆåŸå§‹æ„å›¾"""
        check_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹SQLæŸ¥è¯¢æ˜¯å¦å‡†ç¡®å®ç°äº†ç”¨æˆ·çš„åŸå§‹æ„å›¾ï¼š

        ç”¨æˆ·è¯·æ±‚ï¼š{original_intent}
        SQLæŸ¥è¯¢ï¼š{sql_query}

        æ•°æ®åº“æ¶æ„ï¼š{DATABASE_SCHEMA}

        è¯·æ£€æŸ¥ï¼š
        1. æ˜¯å¦é€‰æ‹©äº†æ­£ç¡®çš„è¡¨å’Œåˆ—
        2. JOINæ¡ä»¶æ˜¯å¦æ­£ç¡®
        3. WHEREæ¡ä»¶æ˜¯å¦å‡†ç¡®
        4. GROUP BYå’ŒORDER BYæ˜¯å¦å¿…è¦ä¸”æ­£ç¡®
        5. æ˜¯å¦é—æ¼äº†é‡è¦çš„è¿‡æ»¤æ¡ä»¶

        è¿”å›JSONæ ¼å¼è¯„ä¼°ç»“æœã€‚
        """

        return json.loads(llm_call(check_prompt))
```

### 7.6 è¯„ä¼°åæ€æ•ˆæœçš„æ–¹æ³•å’ŒæŒ‡æ ‡

**é‡åŒ–è¯„ä¼°æŒ‡æ ‡**ï¼š

```python
class ReflectionEvaluation:
    def __init__(self):
        self.metrics = {
            'accuracy_improvement': self.calculate_accuracy_gain,
            'quality_score': self.assess_output_quality,
            'convergence_rate': self.measure_convergence,
            'iteration_efficiency': self.calculate_iteration_efficiency
        }

    def evaluate_reflection_effectiveness(self, before_reflection, after_reflection, ground_truth=None):
        """è¯„ä¼°åæ€æ•ˆæœçš„æ ¸å¿ƒæ–¹æ³•"""

        results = {}

        # 1. å‡†ç¡®æ€§æ”¹è¿›
        if ground_truth:
            accuracy_before = self.calculate_accuracy(before_reflection, ground_truth)
            accuracy_after = self.calculate_accuracy(after_reflection, ground_truth)
            results['accuracy_improvement'] = accuracy_after - accuracy_before

        # 2. è´¨é‡è¯„åˆ†æ”¹è¿›
        quality_before = self.assess_quality(before_reflection)
        quality_after = self.assess_quality(after_reflection)
        results['quality_improvement'] = quality_after - quality_before

        # 3. ä¸€è‡´æ€§æ£€æŸ¥
        results['consistency_score'] = self.check_consistency(after_reflection)

        # 4. å®Œæ•´æ€§è¯„ä¼°
        results['completeness_score'] = self.assess_completeness(after_reflection)

        return results

    def assess_quality(self, output):
        """ç»¼åˆè´¨é‡è¯„ä¼°"""
        quality_prompt = f"""
        è¯·è¯„ä¼°ä»¥ä¸‹è¾“å‡ºçš„è´¨é‡ï¼ˆ1-10åˆ†ï¼‰ï¼š

        è¾“å‡ºå†…å®¹ï¼š{output}

        è¯„ä¼°ç»´åº¦ï¼š
        1. äº‹å®å‡†ç¡®æ€§ï¼ˆ2.5åˆ†ï¼‰
        2. é€»è¾‘ä¸€è‡´æ€§ï¼ˆ2.5åˆ†ï¼‰
        3. è¡¨è¾¾æ¸…æ™°åº¦ï¼ˆ2.5åˆ†ï¼‰
        4. å†…å®¹å®Œæ•´æ€§ï¼ˆ2.5åˆ†ï¼‰

        è¯·æä¾›è¯¦ç»†è¯„åˆ†å’Œæ”¹è¿›å»ºè®®ã€‚
        """

        return float(llm_call(quality_prompt).split('æ€»åˆ†ï¼š')[1].split('/')[0])
```

**åæ€æ•ˆæœå¯¹æ¯”å®éªŒ**ï¼š

```python
def run_reflection_comparison(test_cases):
    """è¿è¡Œåæ€æ•ˆæœå¯¹æ¯”å®éªŒ"""
    results = {
        'with_reflection': [],
        'without_reflection': [],
        'improvement_rate': 0
    }

    for case in test_cases:
        # æ— åæ€ç‰ˆæœ¬
        output_no_reflection = direct_generation(case['input'])

        # æœ‰åæ€ç‰ˆæœ¬
        output_with_reflection = reflection_loop(case['input'])

        # è¯„ä¼°ä¸¤ä¸ªç‰ˆæœ¬
        score_no_reflection = evaluate_output(output_no_reflection, case['expected'])
        score_with_reflection = evaluate_output(output_with_reflection, case['expected'])

        results['without_reflection'].append(score_no_reflection)
        results['with_reflection'].append(score_with_reflection)

    # è®¡ç®—æ”¹è¿›ç‡
    improvement_rates = [
        (with_ref - no_ref) / no_ref * 100
        for with_ref, no_ref in zip(results['with_reflection'], results['without_reflection'])
    ]
    results['improvement_rate'] = sum(improvement_rates) / len(improvement_rates)

    return results
```

### 7.7 å¤–éƒ¨åé¦ˆé›†æˆçš„å…·ä½“å®ç°

**äººç±»åé¦ˆé›†æˆç³»ç»Ÿ**ï¼š

```python
class HumanFeedbackIntegration:
    def __init__(self):
        self.feedback_buffer = []
        self.feedback_weights = {}

    def integrate_human_feedback(self, ai_output, human_feedback):
        """é›†æˆäººç±»åé¦ˆæ”¹è¿›AIè¾“å‡º"""

        # åˆ†æåé¦ˆç±»å‹
        feedback_type = self.classify_feedback(human_feedback)

        if feedback_type == 'correction':
            # ç›´æ¥çº æ­£å‹åé¦ˆ
            improved_output = self.apply_correction(ai_output, human_feedback)
        elif feedback_type == 'suggestion':
            # å»ºè®®å‹åé¦ˆ
            improved_output = self.apply_suggestions(ai_output, human_feedback)
        elif feedback_type == 'preference':
            # åå¥½å‹åé¦ˆ
            improved_output = self.adapt_to_preferences(ai_output, human_feedback)
        else:
            improved_output = ai_output

        # æ›´æ–°åé¦ˆæƒé‡
        self.update_feedback_weights(human_feedback, feedback_type)

        return improved_output

    def classify_feedback(self, feedback):
        """åˆ†ç±»åé¦ˆç±»å‹"""
        classification_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹äººç±»åé¦ˆçš„ç±»å‹ï¼š

        åé¦ˆå†…å®¹ï¼š{feedback}

        åˆ†ç±»æ ‡å‡†ï¼š
        1. correction: æ˜ç¡®æŒ‡å‡ºå…·ä½“é”™è¯¯å¹¶æä¾›æ­£ç¡®ä¿¡æ¯
        2. suggestion: æä¾›æ”¹è¿›å»ºè®®ä½†ä¸å¼ºåˆ¶
        3. preference: è¡¨è¾¾ä¸ªäººåå¥½æˆ–é£æ ¼è¦æ±‚
        4. unclear: åé¦ˆä¸æ˜ç¡®æˆ–æ¨¡ç³Š

        è¯·è¿”å›åˆ†ç±»ç»“æœã€‚
        """

        return llm_call(classification_prompt).strip()
```

**å¤šè½®å¯¹è¯åæ€æœºåˆ¶**ï¼š

```python
def multi_turn_reflection(initial_query, conversation_history):
    """å¤šè½®å¯¹è¯ä¸­çš„åæ€æœºåˆ¶"""

    # åˆ†æå¯¹è¯å†å²
    history_analysis = analyze_conversation_history(conversation_history)

    # åŸºäºå†å²æ”¹è¿›å›åº”
    reflection_prompt = f"""
    åŸºäºä»¥ä¸‹å¯¹è¯å†å²åˆ†æï¼Œè¯·æ”¹è¿›å¯¹å½“å‰æŸ¥è¯¢çš„å›åº”ï¼š

    åˆå§‹æŸ¥è¯¢ï¼š{initial_query}
    å¯¹è¯å†å²ï¼š{conversation_history}
    å†å²åˆ†æï¼š{history_analysis}

    åæ€è¦ç‚¹ï¼š
    1. ä¹‹å‰å›åº”ä¸­çš„ä¸è¶³
    2. ç”¨æˆ·åé¦ˆçš„æ¨¡å¼
    3. éœ€è¦ç‰¹åˆ«å…³æ³¨çš„æ–¹é¢

    è¯·æä¾›æ”¹è¿›åçš„å›åº”ã€‚
    """

    return llm_call(reflection_prompt)
```

### 7.8 å®éªŒé…ç½®å®Œæ•´ä»£ç 

**å›¾è¡¨ç”Ÿæˆå®éªŒé…ç½®**ï¼š

```python
# chart_config.py
CHART_REQUIREMENTS = {
    'data_types': ['numerical', 'categorical', 'time_series'],
    'chart_types': ['bar', 'line', 'scatter', 'pie', 'histogram'],
    'quality_criteria': {
        'clarity': 'å›¾è¡¨æ˜¯å¦æ¸…æ™°æ˜“æ‡‚',
        'accuracy': 'æ•°æ®è¡¨ç¤ºæ˜¯å¦å‡†ç¡®',
        'aesthetics': 'è§†è§‰ç¾è§‚åº¦',
        'informativeness': 'ä¿¡æ¯ä¼ è¾¾æ•ˆæœ'
    }
}

EVALUATION_METRICS = {
    'technical_correctness': 0.4,  # æŠ€æœ¯æ­£ç¡®æ€§æƒé‡
    'visual_clarity': 0.3,          # è§†è§‰æ¸…æ™°åº¦æƒé‡
    'information_value': 0.3        # ä¿¡æ¯ä»·å€¼æƒé‡
}
```

**SQLè¯„ä¼°åŸºå‡†**ï¼š

```python
# sql_evaluation_benchmark.py
SQL_EVALUATION_DATASET = [
    {
        "query_id": "sql_001",
        "natural_language": "æ˜¾ç¤ºæ‰€æœ‰è®¢å•æ•°é‡å¤§äº5çš„äº§å“",
        "difficulty": "easy",
        "required_tables": ["products", "orders"],
        "expected_elements": ["GROUP BY", "HAVING", "SUM"]
    },
    {
        "query_id": "sql_002",
        "natural_language": "æ‰¾å‡ºæ¯ä¸ªå®¢æˆ·çš„å¹³å‡è®¢å•é‡‘é¢ï¼Œå¹¶æŒ‰é‡‘é¢é™åºæ’åˆ—",
        "difficulty": "medium",
        "required_tables": ["customers", "orders", "products"],
        "expected_elements": ["JOIN", "AVG", "GROUP BY", "ORDER BY"]
    }
]
```

### 7.9 å…³é”®æ´å¯Ÿå’Œæœ€ä½³å®è·µ

**åæ€æœºåˆ¶è®¾è®¡åŸåˆ™**ï¼š
1. **æ˜ç¡®åæ€ç›®æ ‡**ï¼šæ¯æ¬¡åæ€éƒ½è¦æœ‰å…·ä½“çš„æ”¹è¿›ç›®æ ‡
2. **ç»“æ„åŒ–åé¦ˆ**ï¼šä½¿ç”¨æ ‡å‡†åŒ–æ ¼å¼æ”¶é›†å’Œåˆ†æåé¦ˆ
3. **è¿­ä»£æ”¶æ•›**ï¼šè®¾ç½®åˆç†çš„è¿­ä»£æ¬¡æ•°ï¼Œé¿å…æ— é™å¾ªç¯
4. **æ•ˆæœé‡åŒ–**ï¼šå»ºç«‹å¯æµ‹é‡çš„æ”¹è¿›æŒ‡æ ‡

**å¸¸è§é™·é˜±å’Œè§£å†³æ–¹æ¡ˆ**ï¼š

```python
# é™·é˜±1ï¼šè¿‡åº¦åæ€å¯¼è‡´æ€§èƒ½ä¸‹é™
def avoid_over_reflection(output, iteration_count):
    if iteration_count > 3:
        # å¼ºåˆ¶ç»ˆæ­¢ï¼Œé¿å…è¿‡åº¦ä¼˜åŒ–
        return output, True
    return output, False

# é™·é˜±2ï¼šåæ€æ–¹å‘åç¦»
def keep_reflection_focused(original_goal, current_reflection):
    focus_check_prompt = f"""
    è¯·æ£€æŸ¥ä»¥ä¸‹åæ€æ˜¯å¦ä»ç„¶é’ˆå¯¹åŸå§‹ç›®æ ‡ï¼š

    åŸå§‹ç›®æ ‡ï¼š{original_goal}
    å½“å‰åæ€ï¼š{current_reflection}

    å¦‚æœåæ€åç¦»äº†åŸå§‹ç›®æ ‡ï¼Œè¯·é‡æ–°èšç„¦ã€‚
    """
    return llm_call(focus_check_prompt)
```

---

## æœ¬ç« å°ç»“

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **åæ€æ¨¡å¼çš„æœ¬è´¨**
   - ç”Ÿæˆ â†’ å®¡æŸ¥ â†’ æ”¹è¿›
   - æ¨¡æ‹Ÿäººç±»çš„è‡ªæˆ‘ä¿®æ­£è¿‡ç¨‹

2. **ä¸‰ä¸ªå±‚æ¬¡**
   - åŸºç¡€åæ€ï¼šåŒä¸€æ¨¡å‹è‡ªçœ
   - åŒæ¨¡å‹åæ€ï¼šä¸“é—¨æ¨¡å‹å®¡æŸ¥
   - å¤–éƒ¨åé¦ˆï¼šçœŸå®æ‰§è¡Œç»“æœ

3. **å¤–éƒ¨åé¦ˆçš„é‡è¦æ€§**
   - æ‰“ç ´ä¿¡æ¯å­¤å²›
   - è§£å†³æ¨¡å‹å›ºæœ‰ç¼ºé™·
   - å®ç°è´¨çš„é£è·ƒ

4. **è¯„ä¼°åæ€æ•ˆæœ**
   - å®¢è§‚ä»»åŠ¡ï¼šç”¨çœŸå®ç­”æ¡ˆå¯¹æ¯”
   - ä¸»è§‚ä»»åŠ¡ï¼šç”¨è¯„åˆ†é‡è¡¨
   - å¿…é¡»è¯„ä¼°ï¼Œå¦åˆ™æ— æ³•çŸ¥é“æ˜¯å¦å€¼å¾—

### å®è·µå»ºè®®

1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆå®ç°åŸºç¡€åæ€
2. **é€æ­¥æ·»åŠ **ï¼šæ ¹æ®éœ€è¦æ·»åŠ å¤–éƒ¨åé¦ˆ
3. **æŒç»­è¯„ä¼°**ï¼šç”¨æ•°æ®é©±åŠ¨æ”¹è¿›
4. **æ³¨æ„æˆæœ¬**ï¼šåæ€ä¼šå¢åŠ å»¶è¿Ÿå’Œæˆæœ¬

### ä¸‹ä¸€æ­¥å­¦ä¹ 

- ç¬¬3ç« ï¼šå­¦ä¹ å·¥å…·ä½¿ç”¨ï¼Œæ‰©å±• AI èƒ½åŠ›
- ç¬¬4ç« ï¼šæŒæ¡è¯„ä¼°å’Œé”™è¯¯åˆ†ææ–¹æ³•
- ç¬¬5ç« ï¼šæ„å»ºé«˜åº¦è‡ªæ²»çš„ Agent

---

## 8. å¦‚ä½•å°†åæ€é›†æˆåˆ°å®Œæ•´ Agent

åŸºäºç¬¬1ç« å’Œç¬¬2ç« æ‰€å­¦ï¼Œä»¥ä¸‹æ˜¯æ„å»ºå¸¦åæ€åŠŸèƒ½çš„å®Œæ•´ Agent çš„å®è·µæŒ‡å—ï¼š

### 8.1 åæ€æ¨¡å¼çš„é€‰æ‹©æ¡†æ¶

```python
# æ ¹æ®ä»»åŠ¡ç‰¹æ€§é€‰æ‹©åæ€æ¨¡å¼
def select_reflection_pattern(task_characteristics):
    """
    ä»»åŠ¡ç‰¹æ€§åŒ…æ‹¬ï¼š
    - complexity: å¤æ‚åº¦ï¼ˆ1-5ï¼‰
    - has_ground_truth: æ˜¯å¦æœ‰æ ‡å‡†ç­”æ¡ˆ
    - requires_execution: æ˜¯å¦éœ€è¦æ‰§è¡ŒéªŒè¯
    - quality_threshold: è´¨é‡è¦æ±‚é˜ˆå€¼
    """

    if task_characteristics["complexity"] <= 2:
        # ç®€å•ä»»åŠ¡ï¼šåŸºç¡€åæ€
        return "basic_reflection"

    elif task_characteristics["has_ground_truth"]:
        # æœ‰æ ‡å‡†ç­”æ¡ˆï¼šå¤–éƒ¨åé¦ˆåæ€
        return "external_feedback_reflection"

    elif task_characteristics["requires_execution"]:
        # éœ€è¦æ‰§è¡ŒéªŒè¯ï¼šæ‰§è¡Œåé¦ˆåæ€
        return "execution_feedback_reflection"

    elif task_characteristics["quality_threshold"] > 0.8:
        # é«˜è´¨é‡è¦æ±‚ï¼šå¤šè½®åæ€
        return "multi_round_reflection"

    else:
        # é»˜è®¤ï¼šåŸºç¡€åæ€
        return "basic_reflection"
```

### 8.2 å°†åæ€é›†æˆåˆ°ç¬¬1ç« çš„å®¢æˆ·é‚®ä»¶ Agent

```python
# æ‰©å±•ç¬¬1ç« çš„å®¢æˆ·é‚®ä»¶ Agentï¼Œæ·»åŠ åæ€åŠŸèƒ½
class ReflectiveCustomerServiceAgent:
    def __init__(self):
        self.workflow_steps = [
            "extract_info",
            "query_database",
            "classify_problem",
            "generate_response",
            "reflect_on_response",  # æ–°å¢åæ€æ­¥éª¤
            "improve_response",     # æ–°å¢æ”¹è¿›æ­¥éª¤
            "send_email"
        ]

    def reflect_on_response(self, draft_response, customer_info, problem_type):
        """
        åæ€ç”Ÿæˆçš„å›å¤
        """
        reflection_prompt = f"""
        è¯·è¯„ä¼°ä»¥ä¸‹å®¢æœå›å¤çš„è´¨é‡ï¼š

        å®¢æˆ·ä¿¡æ¯ï¼š{customer_info}
        é—®é¢˜ç±»å‹ï¼š{problem_type}
        å›å¤è‰ç¨¿ï¼š{draft_response}

        è¯„ä¼°ç»´åº¦ï¼š
        1. å‡†ç¡®æ€§ï¼šå›å¤æ˜¯å¦è§£å†³äº†å®¢æˆ·é—®é¢˜ï¼Ÿ
        2. ä¸“ä¸šæ€§ï¼šè¯­æ°”æ˜¯å¦ä¸“ä¸šç¤¼è²Œï¼Ÿ
        3. å®Œæ•´æ€§ï¼šæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Ÿ
        4. æ¸…æ™°åº¦ï¼šè¡¨è¾¾æ˜¯å¦æ¸…æ™°æ˜“æ‡‚ï¼Ÿ

        è¯·æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
        """

        return self.llm_call(reflection_prompt)

    def improve_response(self, draft_response, reflection_feedback):
        """
        æ ¹æ®åæ€æ”¹è¿›å›å¤
        """
        improvement_prompt = f"""
        åŸå§‹å›å¤ï¼š{draft_response}
        åæ€åé¦ˆï¼š{reflection_feedback}

        è¯·æ ¹æ®åé¦ˆç”Ÿæˆæ”¹è¿›åçš„å›å¤ã€‚
        """

        return self.llm_call(improvement_prompt)

    def enhanced_workflow(self, email_text):
        """
        å¢å¼ºç‰ˆå·¥ä½œæµï¼ˆå¸¦åæ€ï¼‰
        """
        # åŸæœ‰æ­¥éª¤
        info = self.extract_key_info(email_text)
        order = self.query_order(info["order_id"])
        problem_type = self.classify_problem(info, order)
        draft = self.generate_response(info, order, problem_type)

        # æ–°å¢åæ€æ­¥éª¤
        reflection = self.reflect_on_response(draft, info, problem_type)
        improved = self.improve_response(draft, reflection)

        # è´¨é‡æ£€æŸ¥
        quality_score = self.check_response_quality(improved)

        if quality_score < 0.8:
            # å¦‚æœè´¨é‡ä»ä¸è¾¾æ ‡ï¼Œå¯ä»¥å†æ¬¡åæ€
            second_reflection = self.reflect_on_response(improved, info, problem_type)
            final_response = self.improve_response(improved, second_reflection)
        else:
            final_response = improved

        # å‘é€é‚®ä»¶
        self.send_email(order["customer"], final_response)

        return final_response
```

### 8.3 åæ€ä¸å…¶ä»–æ¨¡å¼çš„ç»“åˆ

```python
# åæ€ + å·¥å…·ä½¿ç”¨æ¨¡å¼
class ReflectiveToolUsingAgent:
    def __init__(self):
        self.tools = {
            "web_search": self.web_search,
            "database_query": self.database_query,
            "code_execution": self.execute_code
        }

    def reflective_tool_selection(self, task_description):
        """
        å¸¦åæ€çš„å·¥å…·é€‰æ‹©
        """
        # ç¬¬1æ­¥ï¼šåˆæ­¥é€‰æ‹©å·¥å…·
        initial_selection = self.select_tools(task_description)

        # ç¬¬2æ­¥ï¼šåæ€å·¥å…·é€‰æ‹©
        reflection = self.reflect_on_tool_selection(initial_selection, task_description)

        # ç¬¬3æ­¥ï¼šæ”¹è¿›é€‰æ‹©
        final_selection = self.improve_tool_selection(initial_selection, reflection)

        return final_selection

    def reflect_on_tool_selection(self, tool_selection, task_description):
        """
        åæ€å·¥å…·é€‰æ‹©çš„åˆç†æ€§
        """
        reflection_prompt = f"""
        ä»»åŠ¡ï¼š{task_description}
        é€‰æ‹©çš„å·¥å…·ï¼š{tool_selection}

        è¯·è¯„ä¼°ï¼š
        1. å·¥å…·æ˜¯å¦è¶³å¤Ÿå®Œæˆä»»åŠ¡ï¼Ÿ
        2. æ˜¯å¦æœ‰æ›´å¥½çš„å·¥å…·ç»„åˆï¼Ÿ
        3. å·¥å…·è°ƒç”¨é¡ºåºæ˜¯å¦åˆç†ï¼Ÿ
        4. æ˜¯å¦æœ‰å†—ä½™å·¥å…·ï¼Ÿ
        """

        return self.llm_call(reflection_prompt)

# åæ€ + è§„åˆ’æ¨¡å¼
class ReflectivePlanningAgent:
    def __init__(self):
        self.max_reflection_iterations = 3

    def reflective_planning(self, goal):
        """
        å¸¦åæ€çš„ä»»åŠ¡è§„åˆ’
        """
        plan = None

        for i in range(self.max_reflection_iterations):
            if plan is None:
                # ç¬¬1è½®ï¼šç”Ÿæˆåˆå§‹è®¡åˆ’
                plan = self.generate_plan(goal)
            else:
                # åç»­è½®ï¼šåæ€å¹¶æ”¹è¿›è®¡åˆ’
                reflection = self.reflect_on_plan(plan, goal)
                plan = self.improve_plan(plan, reflection)

            # æ£€æŸ¥è®¡åˆ’è´¨é‡
            plan_score = self.evaluate_plan(plan, goal)

            if plan_score > 0.9:
                # è®¡åˆ’è´¨é‡è¶³å¤Ÿé«˜ï¼Œåœæ­¢è¿­ä»£
                break

        return plan
```

### 8.4 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

```python
# åæ€æ€§èƒ½ä¼˜åŒ–
class OptimizedReflectionAgent:
    def __init__(self):
        self.cache = {}  # ç¼“å­˜åæ€ç»“æœ
        self.quality_threshold = 0.8  # è´¨é‡é˜ˆå€¼

    def optimized_reflection(self, output, task_type):
        """
        ä¼˜åŒ–çš„åæ€æµç¨‹
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{task_type}:{hash(output)}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        # æ£€æŸ¥è¾“å‡ºè´¨é‡ï¼ˆå¿«é€Ÿè¯„ä¼°ï¼‰
        quick_score = self.quick_quality_check(output)

        if quick_score > self.quality_threshold:
            # è´¨é‡è¶³å¤Ÿé«˜ï¼Œè·³è¿‡è¯¦ç»†åæ€
            return output

        # æ‰§è¡Œè¯¦ç»†åæ€
        reflection = self.detailed_reflection(output, task_type)
        improved = self.improve_based_on_reflection(output, reflection)

        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = improved

        return improved

    def quick_quality_check(self, output):
        """
        å¿«é€Ÿè´¨é‡æ£€æŸ¥ï¼ˆå‡å°‘å»¶è¿Ÿï¼‰
        """
        # ä½¿ç”¨å¯å‘å¼è§„åˆ™æˆ–ç®€å•æ¨¡å‹
        checks = [
            self.check_length(output),
            self.check_keywords(output),
            self.check_format(output)
        ]

        return sum(checks) / len(checks)
```

### 8.5 å®Œæ•´ Agent æ¨¡æ¿ï¼šå¸¦åæ€çš„å®¢æˆ·æœåŠ¡ç³»ç»Ÿ

```python
# reflective_customer_agent.py
import os
from typing import Dict, Any
from dataclasses import dataclass

@dataclass
class ReflectionConfig:
    """åæ€é…ç½®"""
    enabled: bool = True
    max_iterations: int = 2
    quality_threshold: float = 0.8
    use_cache: bool = True
    reflection_type: str = "basic"  # basic, external_feedback, multi_round

class ReflectiveCustomerAgent:
    """å¸¦åæ€åŠŸèƒ½çš„å®¢æˆ·æœåŠ¡ Agent"""

    def __init__(self, config: ReflectionConfig):
        self.config = config
        self.reflection_cache = {}

    def process_customer_email(self, email_text: str) -> str:
        """å¤„ç†å®¢æˆ·é‚®ä»¶ï¼ˆå¸¦åæ€ï¼‰"""

        # æ­¥éª¤1ï¼šæå–ä¿¡æ¯
        customer_info = self.extract_customer_info(email_text)

        # æ­¥éª¤2ï¼šæŸ¥è¯¢æ•°æ®
        order_details = self.query_order_details(customer_info.order_id)

        # æ­¥éª¤3ï¼šåˆ†æé—®é¢˜
        problem_analysis = self.analyze_problem(customer_info, order_details)

        # æ­¥éª¤4ï¼šç”Ÿæˆå›å¤
        draft_response = self.generate_response(
            customer_info,
            order_details,
            problem_analysis
        )

        # æ­¥éª¤5ï¼šåæ€ä¸æ”¹è¿›ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config.enabled:
            final_response = self.reflective_improvement(
                draft_response,
                customer_info,
                order_details,
                problem_analysis
            )
        else:
            final_response = draft_response

        # æ­¥éª¤6ï¼šå‘é€é‚®ä»¶
        self.send_email(customer_info.email, final_response)

        return final_response

    def reflective_improvement(self, draft_response: str, **context) -> str:
        """åæ€æ”¹è¿›æµç¨‹"""

        current_response = draft_response

        for iteration in range(self.config.max_iterations):
            # åæ€
            reflection = self.reflect_on_response(current_response, **context)

            # æ”¹è¿›
            improved_response = self.improve_response(
                current_response,
                reflection,
                **context
            )

            # è´¨é‡æ£€æŸ¥
            quality_score = self.evaluate_response_quality(improved_response)

            if quality_score >= self.config.quality_threshold:
                # è´¨é‡è¾¾æ ‡ï¼Œåœæ­¢è¿­ä»£
                return improved_response

            current_response = improved_response

        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿”å›å½“å‰æœ€ä½³
        return current_response

    def reflect_on_response(self, response: str, **context) -> str:
        """åæ€å›å¤è´¨é‡"""

        # æ£€æŸ¥ç¼“å­˜
        if self.config.use_cache:
            cache_key = self._generate_cache_key(response, context)
            if cache_key in self.reflection_cache:
                return self.reflection_cache[cache_key]

        # æ ¹æ®åæ€ç±»å‹é€‰æ‹©ä¸åŒçš„åæ€ç­–ç•¥
        if self.config.reflection_type == "basic":
            reflection = self._basic_reflection(response, context)
        elif self.config.reflection_type == "external_feedback":
            reflection = self._external_feedback_reflection(response, context)
        elif self.config.reflection_type == "multi_round":
            reflection = self._multi_round_reflection(response, context)
        else:
            reflection = self._basic_reflection(response, context)

        # ç¼“å­˜ç»“æœ
        if self.config.use_cache:
            self.reflection_cache[cache_key] = reflection

        return reflection

    def _basic_reflection(self, response: str, context: Dict[str, Any]) -> str:
        """åŸºç¡€åæ€"""
        prompt = f"""
        ä½œä¸ºå®¢æœè´¨é‡ä¸“å®¶ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å›å¤ï¼š

        å®¢æˆ·ä¿¡æ¯ï¼š{context.get('customer_info', {})}
        è®¢å•è¯¦æƒ…ï¼š{context.get('order_details', {})}
        é—®é¢˜åˆ†æï¼š{context.get('problem_analysis', {})}

        å›å¤å†…å®¹ï¼š{response}

        è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼š
        1. å‡†ç¡®æ€§ï¼ˆæ˜¯å¦è§£å†³äº†å®¢æˆ·é—®é¢˜ï¼‰
        2. ä¸“ä¸šæ€§ï¼ˆè¯­æ°”æ˜¯å¦æ°å½“ï¼‰
        3. å®Œæ•´æ€§ï¼ˆæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼‰
        4. æ¸…æ™°åº¦ï¼ˆè¡¨è¾¾æ˜¯å¦æ˜“æ‡‚ï¼‰

        æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
        """

        return self._call_llm(prompt)

    def _external_feedback_reflection(self, response: str, context: Dict[str, Any]) -> str:
        """å¤–éƒ¨åé¦ˆåæ€"""
        # æ¨¡æ‹Ÿå¤–éƒ¨åé¦ˆï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½æ¥è‡ªç”¨æˆ·è¯„åˆ†ã€A/Bæµ‹è¯•ç­‰ï¼‰
        external_feedback = self._simulate_external_feedback(response, context)

        prompt = f"""
        åŸºäºä»¥ä¸‹å¤–éƒ¨åé¦ˆï¼Œè¯·åˆ†æå›å¤çš„é—®é¢˜ï¼š

        å›å¤å†…å®¹ï¼š{response}
        å¤–éƒ¨åé¦ˆï¼š{external_feedback}

        è¯·åˆ†æï¼š
        1. åé¦ˆæŒ‡å‡ºçš„å…·ä½“é—®é¢˜
        2. é—®é¢˜çš„æ ¹æœ¬åŸå› 
        3. æ”¹è¿›å»ºè®®
        """

        return self._call_llm(prompt)

    def _multi_round_reflection(self, response: str, context: Dict[str, Any]) -> str:
        """å¤šè½®åæ€"""
        # ç¬¬ä¸€è½®ï¼šåŸºç¡€åæ€
        round1 = self._basic_reflection(response, context)

        # ç¬¬äºŒè½®ï¼šåŸºäºç¬¬ä¸€è½®åæ€çš„æ·±åº¦åæ€
        prompt = f"""
        ç¬¬ä¸€è½®åæ€ï¼š{round1}

        è¯·è¿›è¡Œç¬¬äºŒè½®æ·±åº¦åæ€ï¼š
        1. ç¬¬ä¸€è½®åæ€æ˜¯å¦å…¨é¢ï¼Ÿ
        2. æ˜¯å¦æœ‰é—æ¼çš„é‡è¦é—®é¢˜ï¼Ÿ
        3. æ”¹è¿›å»ºè®®æ˜¯å¦å…·ä½“å¯è¡Œï¼Ÿ
        4. æ˜¯å¦æœ‰æ›´å¥½çš„æ”¹è¿›æ–¹æ¡ˆï¼Ÿ
        """

        return self._call_llm(prompt)

    def improve_response(self, response: str, reflection: str, **context) -> str:
        """æ ¹æ®åæ€æ”¹è¿›å›å¤"""
        prompt = f"""
        åŸå§‹å›å¤ï¼š{response}
        åæ€åé¦ˆï¼š{reflection}

        ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
        {context}

        è¯·æ ¹æ®åæ€åé¦ˆç”Ÿæˆæ”¹è¿›åçš„å›å¤ã€‚
        """

        return self._call_llm(prompt)

    def evaluate_response_quality(self, response: str) -> float:
        """è¯„ä¼°å›å¤è´¨é‡ï¼ˆ0-1ï¼‰"""
        # ç®€åŒ–çš„è´¨é‡è¯„ä¼°
        checks = [
            self._check_length(response),
            self._check_politeness(response),
            self._check_completeness(response),
            self._check_clarity(response)
        ]

        return sum(checks) / len(checks)

    def _generate_cache_key(self, response: str, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        content = f"{response}:{str(context)}"
        return hashlib.md5(content.encode()).hexdigest()

    # å…¶ä»–è¾…åŠ©æ–¹æ³•...
    def extract_customer_info(self, email_text: str): pass
    def query_order_details(self, order_id: str): pass
    def analyze_problem(self, customer_info, order_details): pass
    def generate_response(self, customer_info, order_details, problem_analysis): pass
    def send_email(self, to: str, content: str): pass
    def _call_llm(self, prompt: str): pass
    def _simulate_external_feedback(self, response: str, context: Dict[str, Any]): pass
    def _check_length(self, response: str): pass
    def _check_politeness(self, response: str): pass
    def _check_completeness(self, response: str): pass
    def _check_clarity(self, response: str): pass

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®åæ€åŠŸèƒ½
    config = ReflectionConfig(
        enabled=True,
        max_iterations=2,
        quality_threshold=0.85,
        use_cache=True,
        reflection_type="multi_round"
    )

    # åˆ›å»º Agent
    agent = ReflectiveCustomerAgent(config)

    # å¤„ç†é‚®ä»¶
    test_email = "æˆ‘çš„è®¢å• #8847 æœ‰é—®é¢˜ï¼Œæ”¶åˆ°é”™è¯¯å•†å“"
    response = agent.process_customer_email(test_email)

    print("æœ€ç»ˆå›å¤ï¼š")
    print(response)
```

### 8.6 éƒ¨ç½²å’Œç›‘æ§åæ€ Agent

```python
# ç›‘æ§åæ€ Agent çš„æ€§èƒ½
class ReflectionMonitor:
    def __init__(self):
        self.metrics = {
            "reflection_count": 0,
            "improvement_rate": 0.0,
            "avg_iterations": 0.0,
            "cache_hit_rate": 0.0
        }

    def track_reflection_performance(self, agent_output, reflection_used, iterations, cache_hit):
        """è·Ÿè¸ªåæ€æ€§èƒ½"""
        self.metrics["reflection_count"] += 1

        # è®¡ç®—æ”¹è¿›ç‡ï¼ˆå¦‚æœæœ‰åŸºå‡†ï¼‰
        if hasattr(self, "baseline_performance"):
            improvement = self.calculate_improvement(agent_output)
            self.metrics["improvement_rate"] = (
                self.metrics["improvement_rate"] * 0.9 + improvement * 0.1
            )

        # æ›´æ–°å¹³å‡è¿­ä»£æ¬¡æ•°
        self.metrics["avg_iterations"] = (
            self.metrics["avg_iterations"] * 0.9 + iterations * 0.1
        )

        # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
        self.metrics["cache_hit_rate"] = (
            self.metrics["cache_hit_rate"] * 0.9 + (1.0 if cache_hit else 0.0) * 0.1
        )

        return self.metrics
```

### 8.7 å¿«é€Ÿé›†æˆæŒ‡å—

```python
# 3æ­¥å°†åæ€é›†æˆåˆ°ç°æœ‰ Agent
def integrate_reflection_3_steps(existing_agent):
    """
    æ­¥éª¤1ï¼šè¯†åˆ«éœ€è¦åæ€çš„å…³é”®æ­¥éª¤
    æ­¥éª¤2ï¼šæ·»åŠ åæ€å‡½æ•°
    æ­¥éª¤3ï¼šä¿®æ”¹å·¥ä½œæµè°ƒç”¨åæ€
    """

    # æ­¥éª¤1ï¼šè¯†åˆ«å…³é”®æ­¥éª¤
    critical_steps = identify_critical_steps(existing_agent)

    # æ­¥éª¤2ï¼šä¸ºæ¯ä¸ªå…³é”®æ­¥éª¤æ·»åŠ åæ€å‡½æ•°
    for step in critical_steps:
        reflection_func = create_reflection_function(step)
        existing_agent.add_reflection_function(step, reflection_func)

    # æ­¥éª¤3ï¼šä¿®æ”¹å·¥ä½œæµ
    existing_agent.modify_workflow_to_include_reflection()

    return existing_agent
```

**æ­å–œä½ å®Œæˆç¬¬2ç« å­¦ä¹ ï¼** ğŸ‰

ä½ å·²ç»æŒæ¡äº†åæ€æ¨¡å¼çš„æ ¸å¿ƒåŸç†å’Œå®ç°æ–¹æ³•ï¼Œå¯ä»¥æ„å»ºè‡ªæˆ‘æ”¹è¿›çš„ AI ç³»ç»Ÿäº†ã€‚

**è®°ä½**ï¼šå¤–éƒ¨åé¦ˆæ˜¯æ€§èƒ½è·ƒè¿çš„å…³é”®ï¼Œè¯„ä¼°æ˜¯æŒç»­æ”¹è¿›çš„åŸºç¡€ã€‚

**ç°åœ¨ä½ å¯ä»¥**ï¼š
1. å°†åæ€æ¨¡å¼é›†æˆåˆ°ç¬¬1ç« æ„å»ºçš„ Agent ä¸­
2. æ ¹æ®ä»»åŠ¡ç‰¹æ€§é€‰æ‹©åˆé€‚çš„åæ€ç­–ç•¥
3. ä½¿ç”¨ç¬¬8èŠ‚çš„æ¨¡æ¿æ„å»ºå¸¦åæ€åŠŸèƒ½çš„å®Œæ•´ Agent
4. ç›‘æ§å’Œä¼˜åŒ–åæ€ Agent çš„æ€§èƒ½
